{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advadj67/hw3_M11221004/blob/main/HW03_YoloV8_Colab_0517.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3ebe4f7",
      "metadata": {
        "id": "b3ebe4f7",
        "outputId": "85049c0f-a7d5-4044-af1e-6c502d7b19ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.16)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "fatal: destination path 'hw3_M11221004' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!git clone https://github.com/advadj67/hw3_M11221004.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d283b530",
      "metadata": {
        "id": "d283b530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3ff05a51-7814-4aaa-d14f-aac3bb0dd2a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#將.xml轉成Yolo所需 .txt檔案\\nimport os\\nimport xml.etree.ElementTree as ET\\n\\ndef convert_coordinates(size, box):\\n    # 轉換坐標\\n    dw = 1.0 / size[0]\\n    dh = 1.0 / size[1]\\n    x = (box[0] + box[1]) / 2.0\\n    y = (box[2] + box[3]) / 2.0\\n    w = box[1] - box[0]\\n    h = box[3] - box[2]\\n    x = x * dw\\n    w = w * dw\\n    y = y * dh\\n    h = h * dh\\n    return (x, y, w, h)\\n\\ndef convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\\n    # 解析XML並轉換為YOLO格式\\n    tree = ET.parse(xml_path)\\n    root = tree.getroot()\\n\\n    size = root.find(\\'size\\')\\n    w = int(size.find(\\'width\\').text)\\n    h = int(size.find(\\'height\\').text)\\n\\n    for output_folder in output_folders:\\n        folder_name = os.path.basename(output_folder)\\n        output_dir = os.path.join(output_root, folder_name)\\n        if not os.path.exists(output_dir):\\n            os.makedirs(output_dir)\\n\\n        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + \\'.txt\\')\\n        with open(output_file_path, \\'w\\') as f:\\n            for obj in root.findall(\\'object\\'):\\n                cls = obj.find(\\'name\\').text\\n                if cls not in class_dict:\\n                    continue\\n                cls_id = class_dict[cls]\\n                xml_box = obj.find(\\'bndbox\\')\\n                box = (float(xml_box.find(\\'xmin\\').text), float(xml_box.find(\\'xmax\\').text),\\n                       float(xml_box.find(\\'ymin\\').text), float(xml_box.find(\\'ymax\\').text))\\n                bb = convert_coordinates((w,h), box)\\n                f.write(f\"{cls_id} {\\' \\'.join([str(a) for a in bb])}\\n\")\\n\\n# 資料夾列表\\nfolders = [\"訓練集_xml\", \"驗證集_xml\", \"測試集_xml\"]\\no_folders = [\"train\", \"val\", \"test\"]\\n\\n# 分類字典，將類別名映射到整數標籤\\nclass_dict = {\"container\": 0}\\n\\n# 輸出根資料夾路徑\\noutput_root = \"E:\\\\Downloads\\\\貨櫃資料集\\\\labels\"\\n\\n# 如果輸出根資料夾不存在，則創建\\nif not os.path.exists(output_root):\\n    os.makedirs(output_root)\\n\\n# 迴圈處理每個資料夾\\nfor folder, o_folder in zip(folders, o_folders):\\n    folder_path = os.path.join(\"E:\\\\Downloads\\\\貨櫃資料集\", folder)  # 資料夾路徑\\n    xml_files = [f for f in os.listdir(folder_path) if f.endswith(\\'.xml\\')]  # 獲取所有XML檔案\\n    output_folders = [os.path.join(output_root, o_folder)]  # 輸出資料夾路徑\\n    for xml_file in xml_files:\\n        xml_path = os.path.join(folder_path, xml_file)  # XML檔案路徑\\n        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\\n\\nprint(\"labels轉換完成!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''\n",
        "#將.xml轉成Yolo所需 .txt檔案\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    # 轉換坐標\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    x = (box[0] + box[1]) / 2.0\n",
        "    y = (box[2] + box[3]) / 2.0\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "def convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\n",
        "    # 解析XML並轉換為YOLO格式\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for output_folder in output_folders:\n",
        "        folder_name = os.path.basename(output_folder)\n",
        "        output_dir = os.path.join(output_root, folder_name)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + '.txt')\n",
        "        with open(output_file_path, 'w') as f:\n",
        "            for obj in root.findall('object'):\n",
        "                cls = obj.find('name').text\n",
        "                if cls not in class_dict:\n",
        "                    continue\n",
        "                cls_id = class_dict[cls]\n",
        "                xml_box = obj.find('bndbox')\n",
        "                box = (float(xml_box.find('xmin').text), float(xml_box.find('xmax').text),\n",
        "                       float(xml_box.find('ymin').text), float(xml_box.find('ymax').text))\n",
        "                bb = convert_coordinates((w,h), box)\n",
        "                f.write(f\"{cls_id} {' '.join([str(a) for a in bb])}\\n\")\n",
        "\n",
        "# 資料夾列表\n",
        "folders = [\"訓練集_xml\", \"驗證集_xml\", \"測試集_xml\"]\n",
        "o_folders = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# 分類字典，將類別名映射到整數標籤\n",
        "class_dict = {\"container\": 0}\n",
        "\n",
        "# 輸出根資料夾路徑\n",
        "output_root = \"E:\\Downloads\\貨櫃資料集\\labels\"\n",
        "\n",
        "# 如果輸出根資料夾不存在，則創建\n",
        "if not os.path.exists(output_root):\n",
        "    os.makedirs(output_root)\n",
        "\n",
        "# 迴圈處理每個資料夾\n",
        "for folder, o_folder in zip(folders, o_folders):\n",
        "    folder_path = os.path.join(\"E:\\Downloads\\貨櫃資料集\", folder)  # 資料夾路徑\n",
        "    xml_files = [f for f in os.listdir(folder_path) if f.endswith('.xml')]  # 獲取所有XML檔案\n",
        "    output_folders = [os.path.join(output_root, o_folder)]  # 輸出資料夾路徑\n",
        "    for xml_file in xml_files:\n",
        "        xml_path = os.path.join(folder_path, xml_file)  # XML檔案路徑\n",
        "        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\n",
        "\n",
        "print(\"labels轉換完成!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91dad266",
      "metadata": {
        "id": "91dad266",
        "outputId": "0b5ff8ef-8f65-4d05-bb13-ff3ea3efec73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom PIL import Image\\n\\n# 資料夾列表\\nfolder_path = \"E:/Downloads/貨櫃資料集/\"\\nfolders = [folder_path + \"訓練集\", folder_path + \"驗證集\", folder_path + \"測試集\"]\\n\\noutput_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\\n\\n\\n# 創建輸出資料夾\\nfor output_folder in output_folders:\\n    os.makedirs(output_folder, exist_ok=True)\\n\\n# 轉換函數\\ndef resize_images(folder, output_folder):\\n    # 獲取資料夾中所有圖片的檔案名稱\\n    files = os.listdir(folder)\\n\\n    # 迴圈處理每張圖片\\n    for file in files:\\n        # 檔案路徑\\n        file_path = os.path.join(folder, file)\\n\\n        # 如果是檔案\\n        if os.path.isfile(file_path):\\n            # 打開圖片\\n            img = Image.open(file_path)\\n\\n            # 重新調整大小\\n            resized_img = img.resize((416, 416))\\n\\n            # 另存新圖片\\n            resized_img.save(os.path.join(output_folder, file))\\n\\n# 對每個資料夾和對應的輸出資料夾調用resize_images函數\\nfor folder, output_folder in zip(folders, output_folders):\\n    resize_images(folder, output_folder)\\n\\nprint(\"images轉換完成!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "from PIL import Image\n",
        "\n",
        "# 資料夾列表\n",
        "folder_path = \"E:/Downloads/貨櫃資料集/\"\n",
        "folders = [folder_path + \"訓練集\", folder_path + \"驗證集\", folder_path + \"測試集\"]\n",
        "\n",
        "output_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\n",
        "\n",
        "\n",
        "# 創建輸出資料夾\n",
        "for output_folder in output_folders:\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 轉換函數\n",
        "def resize_images(folder, output_folder):\n",
        "    # 獲取資料夾中所有圖片的檔案名稱\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    # 迴圈處理每張圖片\n",
        "    for file in files:\n",
        "        # 檔案路徑\n",
        "        file_path = os.path.join(folder, file)\n",
        "\n",
        "        # 如果是檔案\n",
        "        if os.path.isfile(file_path):\n",
        "            # 打開圖片\n",
        "            img = Image.open(file_path)\n",
        "\n",
        "            # 重新調整大小\n",
        "            resized_img = img.resize((416, 416))\n",
        "\n",
        "            # 另存新圖片\n",
        "            resized_img.save(os.path.join(output_folder, file))\n",
        "\n",
        "# 對每個資料夾和對應的輸出資料夾調用resize_images函數\n",
        "for folder, output_folder in zip(folders, output_folders):\n",
        "    resize_images(folder, output_folder)\n",
        "\n",
        "print(\"images轉換完成!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#修改bounding box座標\n",
        "\n",
        "def resize_bounding_boxes(label_file_path, original_size, new_size):\n",
        "    # 讀取原始標籤文件\n",
        "    with open(label_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 計算大小比例\n",
        "    width_ratio = new_size[0] / original_size[0]\n",
        "    height_ratio = new_size[1] / original_size[1]\n",
        "\n",
        "    # 對每個 bounding box 進行調整\n",
        "    for i, line in enumerate(lines):\n",
        "        parts = line.strip().split()\n",
        "        # 解析原始 bounding box 坐標\n",
        "        x_center = float(parts[1])\n",
        "        y_center = float(parts[2])\n",
        "        width = float(parts[3])\n",
        "        height = float(parts[4])\n",
        "        # 調整 bounding box 坐標\n",
        "        x_center *= width_ratio\n",
        "        y_center *= height_ratio\n",
        "        width *= width_ratio\n",
        "        height *= height_ratio\n",
        "        # 更新標籤文件中的 bounding box 坐標\n",
        "        lines[i] = f\"{parts[0]} {x_center} {y_center} {width} {height}\\n\"\n",
        "\n",
        "    # 將更新後的內容寫回標籤文件\n",
        "    with open(label_file_path, 'w') as f:\n",
        "        f.writelines(lines)\n",
        "\n",
        "# 設置原始影像大小和新影像大小\n",
        "original_size = (1920, 1080)\n",
        "new_size = (416, 416)\n",
        "\n",
        "# 設置資料集目錄路徑\n",
        "dataset_dir = \"/content/hw3_M11221004/貨櫃資料集/labels\"\n",
        "subfolders = ['train', 'val', 'test']\n",
        "\n",
        "# 迴圈遍歷每個子資料夾中的標籤文件\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(dataset_dir, subfolder)\n",
        "    label_files = [f for f in os.listdir(subfolder_path) if f.endswith('.txt')]\n",
        "    for label_file in label_files:\n",
        "        label_file_path = os.path.join(subfolder_path, label_file)\n",
        "        # 調整 bounding box 坐標\n",
        "        resize_bounding_boxes(label_file_path, original_size, new_size)\n",
        "'''"
      ],
      "metadata": {
        "id": "b-g7qu9-e0K4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "dfa5d120-f853-482e-9a55-c8e1a3e336e7"
      },
      "id": "b-g7qu9-e0K4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#修改bounding box座標\\n\\ndef resize_bounding_boxes(label_file_path, original_size, new_size):\\n    # 讀取原始標籤文件\\n    with open(label_file_path, \\'r\\') as f:\\n        lines = f.readlines()\\n\\n    # 計算大小比例\\n    width_ratio = new_size[0] / original_size[0]\\n    height_ratio = new_size[1] / original_size[1]\\n\\n    # 對每個 bounding box 進行調整\\n    for i, line in enumerate(lines):\\n        parts = line.strip().split()\\n        # 解析原始 bounding box 坐標\\n        x_center = float(parts[1])\\n        y_center = float(parts[2])\\n        width = float(parts[3])\\n        height = float(parts[4])\\n        # 調整 bounding box 坐標\\n        x_center *= width_ratio\\n        y_center *= height_ratio\\n        width *= width_ratio\\n        height *= height_ratio\\n        # 更新標籤文件中的 bounding box 坐標\\n        lines[i] = f\"{parts[0]} {x_center} {y_center} {width} {height}\\n\"\\n\\n    # 將更新後的內容寫回標籤文件\\n    with open(label_file_path, \\'w\\') as f:\\n        f.writelines(lines)\\n\\n# 設置原始影像大小和新影像大小\\noriginal_size = (1920, 1080)\\nnew_size = (416, 416)\\n\\n# 設置資料集目錄路徑\\ndataset_dir = \"/content/hw3_M11221004/貨櫃資料集/labels\"\\nsubfolders = [\\'train\\', \\'val\\', \\'test\\']\\n\\n# 迴圈遍歷每個子資料夾中的標籤文件\\nfor subfolder in subfolders:\\n    subfolder_path = os.path.join(dataset_dir, subfolder)\\n    label_files = [f for f in os.listdir(subfolder_path) if f.endswith(\\'.txt\\')]\\n    for label_file in label_files:\\n        label_file_path = os.path.join(subfolder_path, label_file)\\n        # 調整 bounding box 坐標\\n        resize_bounding_boxes(label_file_path, original_size, new_size)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 要刪除的資料夾路徑\n",
        "folder_path = '/content/runs/detect'\n",
        "\n",
        "# 使用 shutil.rmtree() 函數刪除資料夾\n",
        "shutil.rmtree(folder_path)\n"
      ],
      "metadata": {
        "id": "8aAqTuJky7FH"
      },
      "id": "8aAqTuJky7FH",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/hw3_M11221004/貨櫃資料集/data.yaml', epochs=10, batch=8, imgsz=416)\n",
        "\n",
        "model.val()  # It'll automatically evaluate the data you trained."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBYGJ6DUR9bK",
        "outputId": "7549d074-a52c-4845-ec9d-3537566d1ab2",
        "collapsed": true
      },
      "id": "jBYGJ6DUR9bK",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n",
            "Ultralytics YOLOv8.2.16 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/hw3_M11221004/貨櫃資料集/data.yaml, epochs=10, time=None, patience=100, batch=8, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/train.cache... 2125 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2125/2125 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/val.cache... 536 images, 0 backgrounds, 0 corrupt: 100%|██████████| 536/536 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.927G      1.157      1.838      1.037          5        416: 100%|██████████| 266/266 [00:40<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:04<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.998      0.998      0.995      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.786G     0.8178     0.7685     0.8941          5        416: 100%|██████████| 266/266 [00:39<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:04<00:00,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.993      0.999      0.995      0.783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.774G     0.7645     0.5792      0.883          4        416: 100%|██████████| 266/266 [00:41<00:00,  6.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1      0.998      0.995      0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.774G     0.7364     0.4888     0.8737          4        416: 100%|██████████| 266/266 [00:37<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.998          1      0.995      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.774G     0.6875     0.4387     0.8663          4        416: 100%|██████████| 266/266 [00:39<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.999      0.998      0.995      0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.774G     0.6749     0.4139     0.8612          5        416: 100%|██████████| 266/266 [00:37<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.776G      0.652     0.3864     0.8584          4        416: 100%|██████████| 266/266 [00:38<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00, 10.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.776G     0.6188      0.362      0.847          5        416: 100%|██████████| 266/266 [00:36<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.776G     0.5777     0.3333     0.8306          5        416: 100%|██████████| 266/266 [00:38<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.776G     0.5569      0.314     0.8278          4        416: 100%|██████████| 266/266 [00:38<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.123 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.16 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.872\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Ultralytics YOLOv8.2.16 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/val.cache... 536 images, 0 backgrounds, 0 corrupt: 100%|██████████| 536/536 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:04<00:00, 13.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.872\n",
            "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train42\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ddc54d59810>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.87653,     0.87667,     0.94292,     0.96279,      0.9699,      0.9742,      0.9768,     0.97923,     0.98027,     0.98082,     0.98258,     0.98344,     0.98509,     0.98595,      0.9873,     0.98793,     0.98912,     0.98937,     0.98962,     0.98985,     0.98987,     0.98989,     0.98992,\n",
              "            0.98994,     0.98996,     0.98998,     0.99001,     0.99003,     0.99005,     0.99008,      0.9901,     0.99012,     0.99015,     0.99017,     0.99019,     0.99022,     0.99024,     0.99026,     0.99029,     0.99031,     0.99033,     0.99035,     0.99038,      0.9904,     0.99042,     0.99045,\n",
              "            0.99047,     0.99049,     0.99052,     0.99054,     0.99056,     0.99059,     0.99061,     0.99063,     0.99065,     0.99068,      0.9907,     0.99072,     0.99075,     0.99079,     0.99086,     0.99093,       0.991,     0.99107,     0.99114,     0.99121,     0.99128,     0.99135,     0.99142,\n",
              "            0.99149,     0.99156,     0.99163,     0.99169,     0.99174,     0.99179,     0.99185,      0.9919,     0.99195,       0.992,     0.99205,      0.9921,     0.99215,     0.99221,     0.99226,     0.99231,     0.99236,     0.99241,     0.99246,     0.99251,     0.99256,     0.99273,     0.99303,\n",
              "            0.99332,     0.99353,     0.99357,      0.9936,     0.99364,     0.99368,     0.99372,     0.99376,      0.9938,     0.99384,     0.99388,     0.99392,     0.99396,       0.994,     0.99403,     0.99407,     0.99411,     0.99415,     0.99419,     0.99423,     0.99427,     0.99431,     0.99435,\n",
              "            0.99439,     0.99442,     0.99446,     0.99449,     0.99453,     0.99456,      0.9946,     0.99463,     0.99467,      0.9947,     0.99474,     0.99477,      0.9948,     0.99484,     0.99487,     0.99491,     0.99494,     0.99498,     0.99501,     0.99505,     0.99508,     0.99511,     0.99515,\n",
              "            0.99518,     0.99522,     0.99525,     0.99529,     0.99532,     0.99536,     0.99542,     0.99549,     0.99555,     0.99562,     0.99569,     0.99576,     0.99582,     0.99589,     0.99596,     0.99603,     0.99609,     0.99616,     0.99623,      0.9963,     0.99638,     0.99646,     0.99655,\n",
              "            0.99663,     0.99672,      0.9968,     0.99688,     0.99697,     0.99705,     0.99713,     0.99723,     0.99749,     0.99774,     0.99799,     0.99814,     0.99816,     0.99818,     0.99819,     0.99821,     0.99822,     0.99824,     0.99825,     0.99827,     0.99829,      0.9983,     0.99832,\n",
              "            0.99833,     0.99835,     0.99836,     0.99838,      0.9984,     0.99841,     0.99843,     0.99844,     0.99846,     0.99847,     0.99849,     0.99851,     0.99852,     0.99854,     0.99855,     0.99857,     0.99859,      0.9986,     0.99862,     0.99863,     0.99865,     0.99866,     0.99868,\n",
              "             0.9987,     0.99871,     0.99873,     0.99874,     0.99876,     0.99877,     0.99879,     0.99881,     0.99882,     0.99884,     0.99885,     0.99887,     0.99888,      0.9989,     0.99892,     0.99893,     0.99895,     0.99896,     0.99898,     0.99899,     0.99901,     0.99903,     0.99904,\n",
              "            0.99906,     0.99907,     0.99907,     0.99907,     0.99907,     0.99907,     0.99908,     0.99908,     0.99908,     0.99908,     0.99908,     0.99908,     0.99909,     0.99909,     0.99909,     0.99909,     0.99909,     0.99909,     0.99909,      0.9991,      0.9991,      0.9991,      0.9991,\n",
              "             0.9991,      0.9991,      0.9991,     0.99911,     0.99911,     0.99911,     0.99911,     0.99911,     0.99911,     0.99912,     0.99912,     0.99912,     0.99912,     0.99912,     0.99912,     0.99912,     0.99913,     0.99913,     0.99913,     0.99913,     0.99913,     0.99913,     0.99914,\n",
              "            0.99914,     0.99914,     0.99914,     0.99914,     0.99914,     0.99914,     0.99915,     0.99915,     0.99915,     0.99915,     0.99915,     0.99915,     0.99915,     0.99916,     0.99916,     0.99916,     0.99916,     0.99916,     0.99916,     0.99917,     0.99917,     0.99917,     0.99917,\n",
              "            0.99917,     0.99917,     0.99917,     0.99918,     0.99918,     0.99918,     0.99918,     0.99918,     0.99918,     0.99919,     0.99919,     0.99919,     0.99919,     0.99919,     0.99919,     0.99919,      0.9992,      0.9992,      0.9992,      0.9992,      0.9992,      0.9992,      0.9992,\n",
              "            0.99921,     0.99921,     0.99921,     0.99921,     0.99921,     0.99921,     0.99922,     0.99922,     0.99922,     0.99922,     0.99922,     0.99922,     0.99922,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99923,     0.99924,     0.99924,     0.99924,     0.99924,\n",
              "            0.99924,     0.99924,     0.99924,     0.99925,     0.99925,     0.99925,     0.99925,     0.99925,     0.99925,     0.99925,     0.99926,     0.99926,     0.99926,     0.99926,     0.99926,     0.99926,     0.99927,     0.99927,     0.99927,     0.99927,     0.99927,     0.99927,     0.99927,\n",
              "            0.99928,     0.99928,     0.99928,     0.99928,     0.99928,     0.99928,     0.99929,     0.99929,     0.99929,     0.99929,     0.99929,     0.99929,     0.99929,      0.9993,      0.9993,      0.9993,      0.9993,      0.9993,      0.9993,      0.9993,     0.99931,     0.99931,     0.99931,\n",
              "            0.99931,     0.99931,     0.99931,     0.99932,     0.99932,     0.99932,     0.99932,     0.99932,     0.99932,     0.99932,     0.99933,     0.99933,     0.99933,     0.99933,     0.99933,     0.99933,     0.99934,     0.99934,     0.99934,     0.99934,     0.99934,     0.99934,     0.99934,\n",
              "            0.99935,     0.99935,     0.99935,     0.99935,     0.99935,     0.99935,     0.99935,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99937,     0.99937,     0.99937,     0.99937,     0.99937,     0.99937,     0.99937,     0.99938,     0.99938,     0.99938,\n",
              "            0.99938,     0.99938,     0.99938,     0.99939,     0.99939,     0.99939,     0.99939,     0.99939,     0.99939,     0.99939,      0.9994,      0.9994,      0.9994,      0.9994,      0.9994,      0.9994,      0.9994,     0.99941,     0.99941,     0.99941,     0.99941,     0.99941,     0.99941,\n",
              "            0.99942,     0.99942,     0.99942,     0.99942,     0.99942,     0.99942,     0.99942,     0.99943,     0.99943,     0.99943,     0.99943,     0.99943,     0.99943,     0.99944,     0.99944,     0.99944,     0.99944,     0.99944,     0.99944,     0.99944,     0.99945,     0.99945,     0.99945,\n",
              "            0.99945,     0.99945,     0.99945,     0.99945,     0.99946,     0.99946,     0.99946,     0.99946,     0.99946,     0.99946,     0.99947,     0.99947,     0.99947,     0.99947,     0.99947,     0.99947,     0.99947,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
              "            0.99949,     0.99949,     0.99949,     0.99949,     0.99949,     0.99949,     0.99949,      0.9995,      0.9995,      0.9995,      0.9995,      0.9995,      0.9995,      0.9995,     0.99951,     0.99951,     0.99951,     0.99951,     0.99951,     0.99951,     0.99952,     0.99952,     0.99952,\n",
              "            0.99952,     0.99952,     0.99952,     0.99952,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99954,     0.99954,     0.99954,     0.99954,     0.99954,     0.99954,     0.99954,     0.99955,     0.99955,     0.99955,     0.99955,     0.99955,     0.99955,\n",
              "            0.99955,     0.99956,     0.99956,     0.99956,     0.99956,     0.99956,     0.99956,     0.99957,     0.99957,     0.99957,     0.99957,     0.99957,     0.99957,     0.99957,     0.99958,     0.99958,     0.99958,     0.99958,     0.99958,     0.99958,     0.99959,     0.99959,     0.99959,\n",
              "            0.99959,     0.99959,     0.99959,     0.99959,      0.9996,      0.9996,      0.9996,      0.9996,      0.9996,      0.9996,      0.9996,     0.99961,     0.99961,     0.99961,     0.99961,     0.99961,     0.99961,     0.99962,     0.99962,     0.99962,     0.99962,     0.99962,     0.99962,\n",
              "            0.99962,     0.99963,     0.99963,     0.99963,     0.99963,     0.99963,     0.99963,     0.99964,     0.99964,     0.99964,     0.99964,     0.99964,     0.99964,     0.99964,     0.99965,     0.99965,     0.99965,     0.99965,     0.99965,     0.99965,     0.99965,     0.99966,     0.99966,\n",
              "            0.99966,     0.99966,     0.99966,     0.99966,     0.99967,     0.99967,     0.99967,     0.99967,     0.99967,     0.99967,     0.99967,     0.99968,     0.99968,     0.99968,     0.99968,     0.99968,     0.99968,     0.99969,     0.99969,     0.99969,     0.99969,     0.99969,     0.99969,\n",
              "            0.99969,      0.9997,      0.9997,      0.9997,      0.9997,      0.9997,      0.9997,      0.9997,     0.99971,     0.99971,     0.99971,     0.99971,     0.99971,     0.99971,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99973,     0.99973,\n",
              "            0.99973,     0.99973,     0.99973,     0.99973,     0.99974,     0.99974,     0.99974,     0.99974,     0.99974,     0.99974,     0.99974,     0.99975,     0.99975,     0.99975,     0.99975,     0.99975,     0.99975,     0.99975,     0.99976,     0.99976,     0.99976,     0.99976,     0.99976,\n",
              "            0.99976,     0.99977,     0.99977,     0.99977,     0.99977,     0.99977,     0.99977,     0.99977,     0.99978,     0.99978,     0.99978,     0.99978,     0.99978,     0.99978,     0.99979,     0.99979,     0.99979,     0.99979,     0.99979,     0.99979,     0.99979,      0.9998,      0.9998,\n",
              "             0.9998,      0.9998,      0.9998,      0.9998,      0.9998,     0.99981,     0.99981,     0.99981,     0.99981,     0.99981,     0.99981,     0.99982,     0.99982,     0.99982,     0.99982,     0.99982,     0.99982,     0.99982,     0.99983,     0.99983,     0.99983,     0.99983,     0.99983,\n",
              "            0.99983,     0.99984,     0.99984,     0.99984,     0.99984,     0.99984,     0.99984,     0.99984,     0.99985,     0.99985,     0.99985,     0.99985,     0.99985,     0.99985,     0.99985,     0.99986,     0.99986,     0.99986,     0.99986,     0.99986,     0.99986,     0.99987,     0.99987,\n",
              "            0.99987,     0.99987,     0.99987,     0.99987,     0.99987,     0.99988,     0.99988,     0.99988,     0.99988,     0.99988,     0.99988,     0.99989,     0.99989,     0.99989,     0.99989,     0.99989,     0.99989,     0.99989,      0.9999,      0.9999,      0.9999,      0.9999,      0.9999,\n",
              "             0.9999,      0.9999,     0.99991,     0.99991,     0.99991,     0.99991,     0.99991,     0.99991,     0.99992,     0.99992,     0.99992,     0.99992,     0.99992,     0.99992,     0.99992,     0.99993,     0.99993,     0.99993,     0.99993,     0.99993,     0.99993,     0.99994,     0.99994,\n",
              "            0.99994,     0.99994,     0.99994,     0.99994,     0.99994,     0.99995,     0.99995,     0.99995,     0.99995,     0.99995,     0.99995,     0.99995,     0.99996,     0.99996,     0.99996,     0.99996,     0.99996,     0.99996,     0.99997,     0.99997,     0.99997,     0.99997,     0.99997,\n",
              "            0.99997,     0.99997,     0.99998,     0.99998,     0.99998,     0.99998,     0.99998,     0.99998,     0.99998,     0.99999,     0.99999,     0.99999,     0.99999,     0.99999,     0.99999,           1,           1,           1,     0.99998,     0.99976,     0.99953,     0.99931,     0.99908,\n",
              "            0.99882,     0.99855,     0.99829,     0.99712,     0.99624,     0.99594,     0.99564,     0.99535,     0.99367,     0.99317,      0.9928,     0.99221,      0.9898,     0.98908,     0.98748,     0.98674,     0.98637,       0.986,     0.98421,     0.98242,     0.98075,     0.98016,     0.97699,\n",
              "            0.97495,      0.9691,     0.96454,     0.95514,     0.95277,     0.95024,     0.94606,     0.93738,     0.93511,     0.93342,     0.92424,      0.9177,     0.90812,     0.90209,     0.89352,     0.88569,     0.88126,     0.87521,     0.86469,     0.85495,     0.84835,     0.83753,     0.82697,\n",
              "            0.81636,     0.80945,     0.79931,      0.7929,     0.78708,     0.77432,     0.76236,     0.74585,     0.73309,     0.71414,     0.69014,     0.66641,     0.63787,     0.62577,     0.61266,      0.5827,     0.56446,     0.54799,     0.51583,      0.4904,     0.46817,     0.43081,     0.40197,\n",
              "            0.38548,     0.35578,     0.33478,     0.31039,     0.28762,     0.26034,      0.2356,     0.21471,     0.20444,      0.1833,     0.17398,      0.1568,     0.13771,      0.1249,     0.11344,    0.098828,    0.080805,    0.071768,     0.05389,    0.047385,    0.038122,    0.028394,    0.021965,\n",
              "           0.018822,     0.01687,     0.01506,    0.011885,    0.010331,   0.0093006,   0.0082691,   0.0071899,   0.0059125,   0.0046335,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.7802,     0.78042,     0.89201,     0.92824,     0.94156,      0.9497,     0.95465,     0.95931,     0.96131,     0.96236,     0.96576,     0.96741,     0.97062,      0.9723,     0.97493,     0.97615,     0.97848,     0.97897,     0.97946,      0.9799,     0.97994,     0.97999,     0.98003,\n",
              "            0.98008,     0.98012,     0.98017,     0.98021,     0.98026,      0.9803,     0.98035,     0.98039,     0.98044,     0.98049,     0.98053,     0.98058,     0.98062,     0.98067,     0.98071,     0.98076,      0.9808,     0.98085,     0.98089,     0.98094,     0.98098,     0.98103,     0.98107,\n",
              "            0.98112,     0.98117,     0.98121,     0.98126,      0.9813,     0.98135,     0.98139,     0.98144,     0.98148,     0.98153,     0.98157,     0.98162,     0.98166,     0.98176,     0.98189,     0.98203,     0.98217,      0.9823,     0.98244,     0.98258,     0.98271,     0.98285,     0.98299,\n",
              "            0.98312,     0.98326,      0.9834,     0.98352,     0.98362,     0.98372,     0.98382,     0.98393,     0.98403,     0.98413,     0.98423,     0.98433,     0.98443,     0.98453,     0.98463,     0.98473,     0.98484,     0.98494,     0.98504,     0.98514,     0.98524,     0.98556,     0.98615,\n",
              "            0.98674,     0.98714,     0.98721,     0.98729,     0.98737,     0.98745,     0.98752,      0.9876,     0.98768,     0.98775,     0.98783,     0.98791,     0.98799,     0.98806,     0.98814,     0.98822,     0.98829,     0.98837,     0.98845,     0.98853,      0.9886,     0.98868,     0.98876,\n",
              "            0.98883,     0.98891,     0.98898,     0.98905,     0.98912,     0.98919,     0.98925,     0.98932,     0.98939,     0.98946,     0.98953,     0.98959,     0.98966,     0.98973,      0.9898,     0.98987,     0.98994,        0.99,     0.99007,     0.99014,     0.99021,     0.99028,     0.99034,\n",
              "            0.99041,     0.99048,     0.99055,     0.99062,     0.99069,     0.99075,     0.99088,     0.99102,     0.99115,     0.99128,     0.99142,     0.99155,     0.99168,     0.99182,     0.99195,     0.99208,     0.99221,     0.99235,     0.99248,     0.99262,     0.99279,     0.99295,     0.99312,\n",
              "            0.99329,     0.99345,     0.99362,     0.99378,     0.99395,     0.99412,     0.99428,     0.99448,     0.99499,     0.99549,       0.996,      0.9963,     0.99633,     0.99636,     0.99639,     0.99642,     0.99645,     0.99648,     0.99652,     0.99655,     0.99658,     0.99661,     0.99664,\n",
              "            0.99667,      0.9967,     0.99674,     0.99677,      0.9968,     0.99683,     0.99686,     0.99689,     0.99692,     0.99695,     0.99699,     0.99702,     0.99705,     0.99708,     0.99711,     0.99714,     0.99717,     0.99721,     0.99724,     0.99727,      0.9973,     0.99733,     0.99736,\n",
              "            0.99739,     0.99742,     0.99746,     0.99749,     0.99752,     0.99755,     0.99758,     0.99761,     0.99764,     0.99768,     0.99771,     0.99774,     0.99777,      0.9978,     0.99783,     0.99786,      0.9979,     0.99793,     0.99796,     0.99799,     0.99802,     0.99805,     0.99808,\n",
              "            0.99811,     0.99814,     0.99814,     0.99814,     0.99815,     0.99815,     0.99815,     0.99816,     0.99816,     0.99816,     0.99817,     0.99817,     0.99817,     0.99817,     0.99818,     0.99818,     0.99818,     0.99819,     0.99819,     0.99819,      0.9982,      0.9982,      0.9982,\n",
              "            0.99821,     0.99821,     0.99821,     0.99821,     0.99822,     0.99822,     0.99822,     0.99823,     0.99823,     0.99823,     0.99824,     0.99824,     0.99824,     0.99824,     0.99825,     0.99825,     0.99825,     0.99826,     0.99826,     0.99826,     0.99827,     0.99827,     0.99827,\n",
              "            0.99827,     0.99828,     0.99828,     0.99828,     0.99829,     0.99829,     0.99829,      0.9983,      0.9983,      0.9983,     0.99831,     0.99831,     0.99831,     0.99831,     0.99832,     0.99832,     0.99832,     0.99833,     0.99833,     0.99833,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99835,     0.99835,     0.99835,     0.99836,     0.99836,     0.99836,     0.99837,     0.99837,     0.99837,     0.99837,     0.99838,     0.99838,     0.99838,     0.99839,     0.99839,     0.99839,      0.9984,      0.9984,      0.9984,      0.9984,     0.99841,     0.99841,\n",
              "            0.99841,     0.99842,     0.99842,     0.99842,     0.99843,     0.99843,     0.99843,     0.99844,     0.99844,     0.99844,     0.99844,     0.99845,     0.99845,     0.99845,     0.99846,     0.99846,     0.99846,     0.99847,     0.99847,     0.99847,     0.99847,     0.99848,     0.99848,\n",
              "            0.99848,     0.99849,     0.99849,     0.99849,      0.9985,      0.9985,      0.9985,      0.9985,     0.99851,     0.99851,     0.99851,     0.99852,     0.99852,     0.99852,     0.99853,     0.99853,     0.99853,     0.99854,     0.99854,     0.99854,     0.99854,     0.99855,     0.99855,\n",
              "            0.99855,     0.99856,     0.99856,     0.99856,     0.99857,     0.99857,     0.99857,     0.99857,     0.99858,     0.99858,     0.99858,     0.99859,     0.99859,     0.99859,      0.9986,      0.9986,      0.9986,      0.9986,     0.99861,     0.99861,     0.99861,     0.99862,     0.99862,\n",
              "            0.99862,     0.99863,     0.99863,     0.99863,     0.99864,     0.99864,     0.99864,     0.99864,     0.99865,     0.99865,     0.99865,     0.99866,     0.99866,     0.99866,     0.99867,     0.99867,     0.99867,     0.99867,     0.99868,     0.99868,     0.99868,     0.99869,     0.99869,\n",
              "            0.99869,      0.9987,      0.9987,      0.9987,      0.9987,     0.99871,     0.99871,     0.99871,     0.99872,     0.99872,     0.99872,     0.99873,     0.99873,     0.99873,     0.99873,     0.99874,     0.99874,     0.99874,     0.99875,     0.99875,     0.99875,     0.99876,     0.99876,\n",
              "            0.99876,     0.99877,     0.99877,     0.99877,     0.99877,     0.99878,     0.99878,     0.99878,     0.99879,     0.99879,     0.99879,      0.9988,      0.9988,      0.9988,      0.9988,     0.99881,     0.99881,     0.99881,     0.99882,     0.99882,     0.99882,     0.99883,     0.99883,\n",
              "            0.99883,     0.99883,     0.99884,     0.99884,     0.99884,     0.99885,     0.99885,     0.99885,     0.99886,     0.99886,     0.99886,     0.99887,     0.99887,     0.99887,     0.99887,     0.99888,     0.99888,     0.99888,     0.99889,     0.99889,     0.99889,      0.9989,      0.9989,\n",
              "             0.9989,      0.9989,     0.99891,     0.99891,     0.99891,     0.99892,     0.99892,     0.99892,     0.99893,     0.99893,     0.99893,     0.99893,     0.99894,     0.99894,     0.99894,     0.99895,     0.99895,     0.99895,     0.99896,     0.99896,     0.99896,     0.99896,     0.99897,\n",
              "            0.99897,     0.99897,     0.99898,     0.99898,     0.99898,     0.99899,     0.99899,     0.99899,       0.999,       0.999,       0.999,       0.999,     0.99901,     0.99901,     0.99901,     0.99902,     0.99902,     0.99902,     0.99903,     0.99903,     0.99903,     0.99903,     0.99904,\n",
              "            0.99904,     0.99904,     0.99905,     0.99905,     0.99905,     0.99906,     0.99906,     0.99906,     0.99906,     0.99907,     0.99907,     0.99907,     0.99908,     0.99908,     0.99908,     0.99909,     0.99909,     0.99909,      0.9991,      0.9991,      0.9991,      0.9991,     0.99911,\n",
              "            0.99911,     0.99911,     0.99912,     0.99912,     0.99912,     0.99913,     0.99913,     0.99913,     0.99913,     0.99914,     0.99914,     0.99914,     0.99915,     0.99915,     0.99915,     0.99916,     0.99916,     0.99916,     0.99916,     0.99917,     0.99917,     0.99917,     0.99918,\n",
              "            0.99918,     0.99918,     0.99919,     0.99919,     0.99919,      0.9992,      0.9992,      0.9992,      0.9992,     0.99921,     0.99921,     0.99921,     0.99922,     0.99922,     0.99922,     0.99923,     0.99923,     0.99923,     0.99923,     0.99924,     0.99924,     0.99924,     0.99925,\n",
              "            0.99925,     0.99925,     0.99926,     0.99926,     0.99926,     0.99926,     0.99927,     0.99927,     0.99927,     0.99928,     0.99928,     0.99928,     0.99929,     0.99929,     0.99929,     0.99929,      0.9993,      0.9993,      0.9993,     0.99931,     0.99931,     0.99931,     0.99932,\n",
              "            0.99932,     0.99932,     0.99933,     0.99933,     0.99933,     0.99933,     0.99934,     0.99934,     0.99934,     0.99935,     0.99935,     0.99935,     0.99936,     0.99936,     0.99936,     0.99936,     0.99937,     0.99937,     0.99937,     0.99938,     0.99938,     0.99938,     0.99939,\n",
              "            0.99939,     0.99939,     0.99939,      0.9994,      0.9994,      0.9994,     0.99941,     0.99941,     0.99941,     0.99942,     0.99942,     0.99942,     0.99943,     0.99943,     0.99943,     0.99943,     0.99944,     0.99944,     0.99944,     0.99945,     0.99945,     0.99945,     0.99946,\n",
              "            0.99946,     0.99946,     0.99946,     0.99947,     0.99947,     0.99947,     0.99948,     0.99948,     0.99948,     0.99949,     0.99949,     0.99949,     0.99949,      0.9995,      0.9995,      0.9995,     0.99951,     0.99951,     0.99951,     0.99952,     0.99952,     0.99952,     0.99952,\n",
              "            0.99953,     0.99953,     0.99953,     0.99954,     0.99954,     0.99954,     0.99955,     0.99955,     0.99955,     0.99956,     0.99956,     0.99956,     0.99956,     0.99957,     0.99957,     0.99957,     0.99958,     0.99958,     0.99958,     0.99959,     0.99959,     0.99959,     0.99959,\n",
              "             0.9996,      0.9996,      0.9996,     0.99961,     0.99961,     0.99961,     0.99962,     0.99962,     0.99962,     0.99962,     0.99963,     0.99963,     0.99963,     0.99964,     0.99964,     0.99964,     0.99965,     0.99965,     0.99965,     0.99966,     0.99966,     0.99966,     0.99966,\n",
              "            0.99967,     0.99967,     0.99967,     0.99968,     0.99968,     0.99968,     0.99969,     0.99969,     0.99969,     0.99969,      0.9997,      0.9997,      0.9997,     0.99971,     0.99971,     0.99971,     0.99972,     0.99972,     0.99972,     0.99972,     0.99973,     0.99973,     0.99973,\n",
              "            0.99974,     0.99974,     0.99974,     0.99975,     0.99975,     0.99975,     0.99976,     0.99976,     0.99976,     0.99976,     0.99977,     0.99977,     0.99977,     0.99978,     0.99978,     0.99978,     0.99979,     0.99979,     0.99979,     0.99979,      0.9998,      0.9998,      0.9998,\n",
              "            0.99981,     0.99981,     0.99981,     0.99982,     0.99982,     0.99982,     0.99982,     0.99983,     0.99983,     0.99983,     0.99984,     0.99984,     0.99984,     0.99985,     0.99985,     0.99985,     0.99985,     0.99986,     0.99986,     0.99986,     0.99987,     0.99987,     0.99987,\n",
              "            0.99988,     0.99988,     0.99988,     0.99989,     0.99989,     0.99989,     0.99989,      0.9999,      0.9999,      0.9999,     0.99991,     0.99991,     0.99991,     0.99992,     0.99992,     0.99992,     0.99992,     0.99993,     0.99993,     0.99993,     0.99994,     0.99994,     0.99994,\n",
              "            0.99995,     0.99995,     0.99995,     0.99995,     0.99996,     0.99996,     0.99996,     0.99997,     0.99997,     0.99997,     0.99998,     0.99998,     0.99998,     0.99999,     0.99999,     0.99999,     0.99999,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99996,     0.99951,     0.99906,     0.99861,     0.99816,\n",
              "            0.99764,     0.99711,     0.99659,     0.99425,     0.99251,     0.99192,     0.99133,     0.99074,     0.98743,     0.98644,      0.9857,     0.98454,     0.97981,      0.9784,     0.97526,     0.97383,     0.97311,     0.97239,     0.96891,     0.96544,     0.96222,     0.96109,     0.95502,\n",
              "            0.95113,     0.94006,     0.93151,     0.91414,      0.9098,     0.90519,     0.89765,     0.88213,     0.87813,     0.87515,     0.85916,     0.84792,      0.8317,     0.82164,     0.80753,     0.79484,     0.78773,     0.77811,     0.76163,     0.74664,     0.73665,     0.72048,     0.70498,\n",
              "             0.6897,      0.6799,     0.66571,     0.65686,     0.64891,     0.63175,     0.61598,      0.5947,     0.57864,     0.55538,     0.52688,     0.49972,     0.46829,     0.45537,     0.44161,     0.41113,      0.3932,      0.3774,     0.34755,     0.32485,     0.30563,     0.27454,     0.25154,\n",
              "            0.23876,     0.21639,     0.20104,     0.18371,     0.16796,     0.14965,     0.13353,     0.12026,     0.11386,      0.1009,    0.095279,     0.08507,    0.073944,    0.066608,    0.060129,    0.051983,    0.042103,    0.037219,    0.027691,    0.024267,    0.019431,    0.014402,    0.011104,\n",
              "          0.0095002,   0.0085069,    0.007587,   0.0059782,   0.0051923,    0.004672,   0.0041517,   0.0036079,    0.002965,   0.0023221,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.884323346175266\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.87203])\n",
              "names: {0: 'container number'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9998488885570622, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8720259401947399, 'fitness': 0.884323346175266}\n",
              "save_dir: PosixPath('runs/detect/train42')\n",
              "speed: {'preprocess': 0.23966716296637236, 'inference': 2.7487624937029027, 'loss': 0.001875767067297181, 'postprocess': 1.6913676439826169}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#使用最佳模型在測試集上預測\"貨櫃號碼\"\n",
        "\n",
        "# Define path to the image file\n",
        "source = '/content/hw3_M11221004/貨櫃資料集/測試集/image_0001.jpg'\n",
        "\n",
        "# Run inference on the source\n",
        "results = model(source)  # list of Results objects\n",
        "\n",
        "# 顯示物件類別\n",
        "print(results[0].boxes.cls)\n",
        "print()\n",
        "\n",
        "# 顯示物件座標\n",
        "print(results[0].boxes.xyxy)\n",
        "\n",
        "\n",
        "\n",
        "#顯示預測框在圖片上\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# results = model.predict(source=\"0\")\n",
        "# 整個目錄\n",
        "# results = model.predict(source=\"folder\", show=True)\n",
        "\n",
        "# from PIL\n",
        "im1 = Image.open(source)\n",
        "# save=True：存檔\n",
        "results = model.predict(source=im1, save=True)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "p9EAcZqhwqmj",
        "outputId": "9ff1c32e-efa5-4c8f-a9ce-56a53ddd1071"
      },
      "id": "p9EAcZqhwqmj",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#使用最佳模型在測試集上預測\"貨櫃號碼\"\\n\\n# Define path to the image file\\nsource = \\'/content/hw3_M11221004/貨櫃資料集/測試集/image_0001.jpg\\'\\n\\n# Run inference on the source\\nresults = model(source)  # list of Results objects\\n\\n# 顯示物件類別\\nprint(results[0].boxes.cls)\\nprint()\\n\\n# 顯示物件座標\\nprint(results[0].boxes.xyxy)\\n\\n\\n\\n#顯示預測框在圖片上\\n\\nfrom PIL import Image\\nimport cv2\\n\\n# results = model.predict(source=\"0\")\\n# 整個目錄\\n# results = model.predict(source=\"folder\", show=True)\\n\\n# from PIL\\nim1 = Image.open(source)\\n# save=True：存檔\\nresults = model.predict(source=im1, save=True)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#預測並合併兩個預測框框\n",
        "\n",
        "import torch\n",
        "\n",
        "def merge_adjacent_boxes(boxes, iou_threshold=0.5):\n",
        "    merged_boxes = []\n",
        "    boxes = boxes.cpu().numpy()  # 將框框轉換為NumPy陣列\n",
        "\n",
        "    for box in boxes:\n",
        "        # 初始化一個合併後的框框\n",
        "        merged_box = box\n",
        "        for merged_box_index, merged_box_tmp in enumerate(merged_boxes):\n",
        "            # 計算兩個框框的IoU\n",
        "            iou = calculate_iou(merged_box_tmp, box)\n",
        "\n",
        "            # 如果IoU大於閾值，將兩個框框合併成一個\n",
        "            if iou > iou_threshold:\n",
        "                x1 = min(merged_box[0], merged_box_tmp[0])\n",
        "                y1 = min(merged_box[1], merged_box_tmp[1])\n",
        "                x2 = max(merged_box[2], merged_box_tmp[2])\n",
        "                y2 = max(merged_box[3], merged_box_tmp[3])\n",
        "                merged_box = [x1, y1, x2, y2]\n",
        "                merged_boxes[merged_box_index] = merged_box\n",
        "                break\n",
        "        else:\n",
        "            # 如果沒有與現有的框框重疊，將新的框框添加到合併框框列表中\n",
        "            merged_boxes.append(box)\n",
        "\n",
        "    return torch.tensor(merged_boxes)  # 將合併後的框框轉換回PyTorch Tensor\n",
        "\n",
        "# 計算兩個框框的IoU\n",
        "def calculate_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
        "    area1 = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    area2 = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "\n",
        "    iou = intersection / float(area1 + area2 - intersection)\n",
        "    return iou\n",
        "\n",
        "\n",
        "\n",
        "source = '/content/hw3_M11221004/貨櫃資料集/訓練集/image_0001.jpg'\n",
        "\n",
        "# Run inference on the source\n",
        "results = model(source)  # list of Results objects\n",
        "\n",
        "# 顯示物件類別\n",
        "print(results[0].boxes.cls)\n",
        "print()\n",
        "\n",
        "# 顯示物件座標\n",
        "print(results[0].boxes.xyxy)\n",
        "\n",
        "# 合併相鄰的框框\n",
        "merged_boxes = merge_adjacent_boxes(results[0].boxes.xyxy)\n",
        "\n",
        "#顯示預測框在圖片上\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# 從PIL開啟圖片\n",
        "im1 = Image.open(source)\n",
        "\n",
        "# 將合併後的框框繪製在圖片上\n",
        "draw = ImageDraw.Draw(im1)\n",
        "for box in merged_boxes:\n",
        "    draw.rectangle(box.tolist(), outline=\"red\")\n",
        "\n",
        "# 顯示圖片\n",
        "im1.show()\n",
        "\n",
        "# 將圖片存檔\n",
        "im1.save(\"output.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42AWPfuIBpJX",
        "outputId": "54ed2b83-e85f-46a6-a18e-f71cdaeeb79b"
      },
      "id": "42AWPfuIBpJX",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/hw3_M11221004/貨櫃資料集/訓練集/image_0001.jpg: 256x416 1 container number, 39.3ms\n",
            "Speed: 1.9ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 416)\n",
            "tensor([0.], device='cuda:0')\n",
            "\n",
            "tensor([[812.0754,  28.2798, 980.2220, 130.3839]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#壓縮成資料夾下載，前面是檔名.zip，後面是要被壓縮的東西\n",
        "!zip -r /content/runs1.zip /content/runs\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/runs1.zip\")"
      ],
      "metadata": {
        "id": "pttsIpiJtFwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "475fd1c2-c5aa-4d8b-f1c7-4457bb74cedb"
      },
      "id": "pttsIpiJtFwc",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/runs/ (stored 0%)\n",
            "updating: content/runs/detect/ (stored 0%)\n",
            "updating: content/runs/detect/train2/ (stored 0%)\n",
            "updating: content/runs/detect/train2/confusion_matrix.png (deflated 37%)\n",
            "updating: content/runs/detect/train2/val_batch1_labels.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/val_batch0_pred.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/P_curve.png (deflated 26%)\n",
            "updating: content/runs/detect/train2/PR_curve.png (deflated 29%)\n",
            "updating: content/runs/detect/train2/val_batch0_labels.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/F1_curve.png (deflated 19%)\n",
            "updating: content/runs/detect/train2/val_batch2_labels.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/R_curve.png (deflated 20%)\n",
            "updating: content/runs/detect/train2/val_batch2_pred.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/val_batch1_pred.jpg (deflated 10%)\n",
            "updating: content/runs/detect/train2/confusion_matrix_normalized.png (deflated 36%)\n",
            "updating: content/runs/detect/train3/ (stored 0%)\n",
            "updating: content/runs/detect/train3/image_0001.jpg (deflated 0%)\n",
            "updating: content/runs/detect/train/ (stored 0%)\n",
            "updating: content/runs/detect/train/args.yaml (deflated 50%)\n",
            "updating: content/runs/detect/train/confusion_matrix.png (deflated 37%)\n",
            "updating: content/runs/detect/train/val_batch1_labels.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/results.png (deflated 8%)\n",
            "updating: content/runs/detect/train/val_batch0_pred.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/P_curve.png (deflated 26%)\n",
            "updating: content/runs/detect/train/results.csv (deflated 83%)\n",
            "updating: content/runs/detect/train/train_batch0.jpg (deflated 16%)\n",
            "updating: content/runs/detect/train/PR_curve.png (deflated 29%)\n",
            "updating: content/runs/detect/train/train_batch1.jpg (deflated 8%)\n",
            "updating: content/runs/detect/train/val_batch0_labels.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/train_batch2.jpg (deflated 6%)\n",
            "updating: content/runs/detect/train/F1_curve.png (deflated 19%)\n",
            "updating: content/runs/detect/train/val_batch2_labels.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/R_curve.png (deflated 20%)\n",
            "updating: content/runs/detect/train/events.out.tfevents.1715871465.bac0d4d2d06a.17791.0 (deflated 93%)\n",
            "updating: content/runs/detect/train/val_batch2_pred.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/labels.jpg (deflated 41%)\n",
            "updating: content/runs/detect/train/val_batch1_pred.jpg (deflated 9%)\n",
            "updating: content/runs/detect/train/labels_correlogram.jpg (deflated 43%)\n",
            "updating: content/runs/detect/train/confusion_matrix_normalized.png (deflated 36%)\n",
            "updating: content/runs/detect/train/weights/ (stored 0%)\n",
            "updating: content/runs/detect/train/weights/last.pt (deflated 10%)\n",
            "updating: content/runs/detect/train/weights/best.pt (deflated 10%)\n",
            "  adding: content/runs/detect/predict/ (stored 0%)\n",
            "  adding: content/runs/detect/predict/image_0001.jpg (deflated 0%)\n",
            "  adding: content/runs/detect/train4/ (stored 0%)\n",
            "  adding: content/runs/detect/train4/args.yaml (deflated 50%)\n",
            "  adding: content/runs/detect/train4/confusion_matrix.png (deflated 37%)\n",
            "  adding: content/runs/detect/train4/val_batch1_labels.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/results.png (deflated 8%)\n",
            "  adding: content/runs/detect/train4/val_batch0_pred.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/P_curve.png (deflated 26%)\n",
            "  adding: content/runs/detect/train4/results.csv (deflated 83%)\n",
            "  adding: content/runs/detect/train4/events.out.tfevents.1715875610.bac0d4d2d06a.17791.1 (deflated 93%)\n",
            "  adding: content/runs/detect/train4/train_batch0.jpg (deflated 16%)\n",
            "  adding: content/runs/detect/train4/PR_curve.png (deflated 29%)\n",
            "  adding: content/runs/detect/train4/train_batch1.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/train4/val_batch0_labels.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/train_batch2.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train4/F1_curve.png (deflated 19%)\n",
            "  adding: content/runs/detect/train4/val_batch2_labels.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/R_curve.png (deflated 20%)\n",
            "  adding: content/runs/detect/train4/val_batch2_pred.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/labels.jpg (deflated 41%)\n",
            "  adding: content/runs/detect/train4/val_batch1_pred.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/train4/labels_correlogram.jpg (deflated 43%)\n",
            "  adding: content/runs/detect/train4/confusion_matrix_normalized.png (deflated 36%)\n",
            "  adding: content/runs/detect/train4/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train4/weights/last.pt (deflated 10%)\n",
            "  adding: content/runs/detect/train4/weights/best.pt (deflated 10%)\n",
            "  adding: content/runs/detect/train42/ (stored 0%)\n",
            "  adding: content/runs/detect/train42/confusion_matrix.png (deflated 37%)\n",
            "  adding: content/runs/detect/train42/val_batch1_labels.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/val_batch0_pred.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/P_curve.png (deflated 26%)\n",
            "  adding: content/runs/detect/train42/PR_curve.png (deflated 29%)\n",
            "  adding: content/runs/detect/train42/val_batch0_labels.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/F1_curve.png (deflated 19%)\n",
            "  adding: content/runs/detect/train42/val_batch2_labels.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/R_curve.png (deflated 20%)\n",
            "  adding: content/runs/detect/train42/val_batch2_pred.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/val_batch1_pred.jpg (deflated 10%)\n",
            "  adding: content/runs/detect/train42/confusion_matrix_normalized.png (deflated 36%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1dcc4ae-0e8f-4d85-ab7b-f04e5b50ac0b\", \"runs1.zip\", 36207585)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文字辨識OCR"
      ],
      "metadata": {
        "id": "9tIqw9wjUjOh"
      },
      "id": "9tIqw9wjUjOh"
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!sudo apt-get install libtesseract-dev\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "4rucANDBSvfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81351c2e-51b9-4001-f4da-5559eb2e2b2d"
      },
      "id": "4rucANDBSvfc",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 定義裁切並進行文字辨識的函數\n",
        "def crop_and_recognize(image, bounding_box):\n",
        "    # 裁剪框框的區域\n",
        "    x1, y1, x2, y2 = map(int, bounding_box)\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "    cv2_imshow(cropped_image)\n",
        "    # 將裁剪後的圖片轉換為灰階\n",
        "    gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 使用大津法計算閾值\n",
        "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # 反轉二值化圖片，將背景設置為白色，文字設置為黑色\n",
        "    inverted_image = cv2.bitwise_not(binary_image)\n",
        "\n",
        "    # 設置文字辨識引擎（使用Tesseract OCR）\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "    # 進行文字辨識\n",
        "    text = pytesseract.image_to_string(inverted_image)\n",
        "\n",
        "    # 顯示裁切後的圖片\n",
        "    cv2_imshow(inverted_image)\n",
        "\n",
        "    # 顯示辨識的結果\n",
        "    print(\"Text in box:\", text)\n",
        "\n",
        "# 要處理的圖片路徑\n",
        "image_path = \"output.jpg\"\n",
        "\n",
        "# 讀取圖片\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# 單個框框的座標\n",
        "bounding_box = merged_boxes[0].tolist()\n",
        "\n",
        "# 裁切並進行文字辨識\n",
        "crop_and_recognize(image, bounding_box)\n"
      ],
      "metadata": {
        "id": "CkfidtV5Xof0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "789261c9-5ba9-4705-ed36-02de81668a08"
      },
      "id": "CkfidtV5Xof0",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=168x102>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=168x102>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAABmCAAAAAB6woWsAAADPklEQVR4nO1a2XLFIAiFTv//l+lDoiKCWzBLxzPTNjfX4AkiixSAwAFEBEAAPtK0CdBLMsI6lgAAP16CVpIEAPjBxRN4wU2jq/EZor9PE6iBm+WribINil1EzzcjPH9WkGqATqJI3BNanmClR28B2czXnP9iVfNd/5SyuvAZ97SJeuPVfjQA4RNED8f06qUPgQbgHRoN/vvgRZAiDvPyC4nyCICBQvFNCoPnRRZ20vUUUYyh1o4RyAYICghSi+GKAONXuehqUhKEUDZjEoYy6mKpp3CLEOToErouD5REsRh4sKLifgt0ykIAih/ylKdIf0hPiLDc9crAyRyAP9ZdmUmLjZAa1S0F45ceiQtxFsQMrLyZHtH9KImLWXrqcxkjOSJbhkYpokhH9nsIw2+I597NfQMMR6a7U9akG0WjSD6Eciff/QTAaaOZKXdqNDjRcf7zBzFiLkmUR9rLGBVm6AEBjBCabDjlCeMKnTAf7hgFlWLpeXB+AMEfknSMpY1aTGkd/x65qh9l+r+2/Y3I3UbMy+ylr8w6q9K+l8VcuJxKJdrYrfrEjdRUnd0ap6AW681YOgiXcGaneSWn6xPWJEjLYp4RoCSKh62YEtc6LgyGSpCM9uAylJQMZfeAmXVi9ysSm6pZ3NlSMUulq9RjVkK10YRxS/C1lPWBJEoYnBjFrJDl0cj/9INEJpUxNm6Lx3WNCiJF9KV2DkeVT4MgVgdzIkl0WS/XsPbIuYNAv6iVRF99SMaxiXpjE/XGJuqNTdQbm6g3PkO00RXJj4Nl/nvnf0PoGg2FQ17pyW7BrQc/KtGY2kfE7JTyUfeh3RATZQOxLtOd0DSaUTDKm9sxtetdDtAGMd4L1erZG6BoFB/cMjb+i8OHmS7MEpjnozk6DWChnZht8ITsAOcx/bZtlEpeT2ywz2wm7cS5drBY9K3vQl2jpPAyma59Bc09TfYu1lpuRaNviUkH9F5o+IXx6P1x1uXS10wN6ULb8BrspbfOth/SbT3WE2/BZB9uh6PDX+uerDP81IfmHOrdpaXVs7n0aiL/wprp+QRU4LtJyVuxiXpjE/XGJuqNTdQbm6g3NlFvbKLe+A7R16XyBv4AUs/h7QO1D80AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text in box:  \n",
            "\n",
            "‘SEKU | 6011351\n",
            "4561\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **缺乏：**\n",
        "\n",
        "\n",
        "1. mAP、Recall、Precision和F1-score\n",
        "2. 準確率績效公式: 辨識正確筆數/測試資料筆數\n",
        "3. 車牌偵測及文字辨識\n",
        "4. 影片的\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uZEWd2OclOjO"
      },
      "id": "uZEWd2OclOjO"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}