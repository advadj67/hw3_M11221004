{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advadj67/hw3_M11221004/blob/main/HW03_YoloV8_Colab_%E6%96%B0%E6%B8%AC%E8%A9%A6%E9%9B%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b3ebe4f7",
      "metadata": {
        "id": "b3ebe4f7",
        "outputId": "0bb78218-644b-4ab4-a67f-7b5bf56224ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.19-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.19\n",
            "Cloning into 'hw3_M11221004'...\n",
            "remote: Enumerating objects: 13686, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 13686 (delta 48), reused 80 (delta 39), pack-reused 13594\u001b[K\n",
            "Receiving objects: 100% (13686/13686), 1.69 GiB | 43.66 MiB/s, done.\n",
            "Resolving deltas: 100% (3453/3453), done.\n",
            "Updating files: 100% (13714/13714), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!git clone https://github.com/advadj67/hw3_M11221004.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d283b530",
      "metadata": {
        "id": "d283b530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0d06a8dc-6b3a-45d7-b7e2-4089adbb3182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#將.xml轉成Yolo所需 .txt檔案\\nimport os\\nimport xml.etree.ElementTree as ET\\n\\ndef convert_coordinates(size, box):\\n    # 轉換坐標\\n    dw = 1.0 / size[0]\\n    dh = 1.0 / size[1]\\n    x = (box[0] + box[1]) / 2.0\\n    y = (box[2] + box[3]) / 2.0\\n    w = box[1] - box[0]\\n    h = box[3] - box[2]\\n    x = x * dw\\n    w = w * dw\\n    y = y * dh\\n    h = h * dh\\n    return (x, y, w, h)\\n\\ndef convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\\n    # 解析XML並轉換為YOLO格式\\n    tree = ET.parse(xml_path)\\n    root = tree.getroot()\\n\\n    size = root.find(\\'size\\')\\n    w = int(size.find(\\'width\\').text)\\n    h = int(size.find(\\'height\\').text)\\n\\n    for output_folder in output_folders:\\n        folder_name = os.path.basename(output_folder)\\n        output_dir = os.path.join(output_root, folder_name)\\n        if not os.path.exists(output_dir):\\n            os.makedirs(output_dir)\\n\\n        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + \\'.txt\\')\\n        with open(output_file_path, \\'w\\') as f:\\n            for obj in root.findall(\\'object\\'):\\n                cls = obj.find(\\'name\\').text\\n                if cls not in class_dict:\\n                    continue\\n                cls_id = class_dict[cls]\\n                xml_box = obj.find(\\'bndbox\\')\\n                box = (float(xml_box.find(\\'xmin\\').text), float(xml_box.find(\\'xmax\\').text),\\n                       float(xml_box.find(\\'ymin\\').text), float(xml_box.find(\\'ymax\\').text))\\n                bb = convert_coordinates((w,h), box)\\n                f.write(f\"{cls_id} {\\' \\'.join([str(a) for a in bb])}\\n\")\\n\\n# 資料夾列表\\nfolders = [\"訓練集_xml\", \"驗證集_xml\", \"測試集_xml\"]\\no_folders = [\"train\", \"val\", \"test\"]\\n\\n# 分類字典，將類別名映射到整數標籤\\nclass_dict = {\"container\": 0}\\n\\n# 輸出根資料夾路徑\\noutput_root = \"E:\\\\Downloads\\\\貨櫃資料集\\\\labels\"\\n\\n# 如果輸出根資料夾不存在，則創建\\nif not os.path.exists(output_root):\\n    os.makedirs(output_root)\\n\\n# 迴圈處理每個資料夾\\nfor folder, o_folder in zip(folders, o_folders):\\n    folder_path = os.path.join(\"E:\\\\Downloads\\\\貨櫃資料集\", folder)  # 資料夾路徑\\n    xml_files = [f for f in os.listdir(folder_path) if f.endswith(\\'.xml\\')]  # 獲取所有XML檔案\\n    output_folders = [os.path.join(output_root, o_folder)]  # 輸出資料夾路徑\\n    for xml_file in xml_files:\\n        xml_path = os.path.join(folder_path, xml_file)  # XML檔案路徑\\n        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\\n\\nprint(\"labels轉換完成!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "'''\n",
        "#將.xml轉成Yolo所需 .txt檔案\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    # 轉換坐標\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    x = (box[0] + box[1]) / 2.0\n",
        "    y = (box[2] + box[3]) / 2.0\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "def convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\n",
        "    # 解析XML並轉換為YOLO格式\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for output_folder in output_folders:\n",
        "        folder_name = os.path.basename(output_folder)\n",
        "        output_dir = os.path.join(output_root, folder_name)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + '.txt')\n",
        "        with open(output_file_path, 'w') as f:\n",
        "            for obj in root.findall('object'):\n",
        "                cls = obj.find('name').text\n",
        "                if cls not in class_dict:\n",
        "                    continue\n",
        "                cls_id = class_dict[cls]\n",
        "                xml_box = obj.find('bndbox')\n",
        "                box = (float(xml_box.find('xmin').text), float(xml_box.find('xmax').text),\n",
        "                       float(xml_box.find('ymin').text), float(xml_box.find('ymax').text))\n",
        "                bb = convert_coordinates((w,h), box)\n",
        "                f.write(f\"{cls_id} {' '.join([str(a) for a in bb])}\\n\")\n",
        "\n",
        "# 資料夾列表\n",
        "folders = [\"訓練集_xml\", \"驗證集_xml\", \"測試集_xml\"]\n",
        "o_folders = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# 分類字典，將類別名映射到整數標籤\n",
        "class_dict = {\"container\": 0}\n",
        "\n",
        "# 輸出根資料夾路徑\n",
        "output_root = \"E:\\Downloads\\貨櫃資料集\\labels\"\n",
        "\n",
        "# 如果輸出根資料夾不存在，則創建\n",
        "if not os.path.exists(output_root):\n",
        "    os.makedirs(output_root)\n",
        "\n",
        "# 迴圈處理每個資料夾\n",
        "for folder, o_folder in zip(folders, o_folders):\n",
        "    folder_path = os.path.join(\"E:\\Downloads\\貨櫃資料集\", folder)  # 資料夾路徑\n",
        "    xml_files = [f for f in os.listdir(folder_path) if f.endswith('.xml')]  # 獲取所有XML檔案\n",
        "    output_folders = [os.path.join(output_root, o_folder)]  # 輸出資料夾路徑\n",
        "    for xml_file in xml_files:\n",
        "        xml_path = os.path.join(folder_path, xml_file)  # XML檔案路徑\n",
        "        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\n",
        "\n",
        "print(\"labels轉換完成!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "91dad266",
      "metadata": {
        "id": "91dad266",
        "outputId": "bd68aa82-cd93-4215-dcc7-8fdae5eedb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom PIL import Image\\n\\n# 資料夾列表\\nfolder_path = \"E:/Downloads/貨櫃資料集/\"\\nfolders = [folder_path + \"訓練集\", folder_path + \"驗證集\", folder_path + \"測試集\"]\\n\\noutput_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\\n\\n\\n# 創建輸出資料夾\\nfor output_folder in output_folders:\\n    os.makedirs(output_folder, exist_ok=True)\\n\\n# 轉換函數\\ndef resize_images(folder, output_folder):\\n    # 獲取資料夾中所有圖片的檔案名稱\\n    files = os.listdir(folder)\\n\\n    # 迴圈處理每張圖片\\n    for file in files:\\n        # 檔案路徑\\n        file_path = os.path.join(folder, file)\\n\\n        # 如果是檔案\\n        if os.path.isfile(file_path):\\n            # 打開圖片\\n            img = Image.open(file_path)\\n\\n            # 重新調整大小\\n            resized_img = img.resize((416, 416))\\n\\n            # 另存新圖片\\n            resized_img.save(os.path.join(output_folder, file))\\n\\n# 對每個資料夾和對應的輸出資料夾調用resize_images函數\\nfor folder, output_folder in zip(folders, output_folders):\\n    resize_images(folder, output_folder)\\n\\nprint(\"images轉換完成!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "from PIL import Image\n",
        "\n",
        "# 資料夾列表\n",
        "folder_path = \"E:/Downloads/貨櫃資料集/\"\n",
        "folders = [folder_path + \"訓練集\", folder_path + \"驗證集\", folder_path + \"測試集\"]\n",
        "\n",
        "output_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\n",
        "\n",
        "\n",
        "# 創建輸出資料夾\n",
        "for output_folder in output_folders:\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 轉換函數\n",
        "def resize_images(folder, output_folder):\n",
        "    # 獲取資料夾中所有圖片的檔案名稱\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    # 迴圈處理每張圖片\n",
        "    for file in files:\n",
        "        # 檔案路徑\n",
        "        file_path = os.path.join(folder, file)\n",
        "\n",
        "        # 如果是檔案\n",
        "        if os.path.isfile(file_path):\n",
        "            # 打開圖片\n",
        "            img = Image.open(file_path)\n",
        "\n",
        "            # 重新調整大小\n",
        "            resized_img = img.resize((416, 416))\n",
        "\n",
        "            # 另存新圖片\n",
        "            resized_img.save(os.path.join(output_folder, file))\n",
        "\n",
        "# 對每個資料夾和對應的輸出資料夾調用resize_images函數\n",
        "for folder, output_folder in zip(folders, output_folders):\n",
        "    resize_images(folder, output_folder)\n",
        "\n",
        "print(\"images轉換完成!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/hw3_M11221004/貨櫃資料集/data.yaml', epochs=20, batch=8, imgsz=(416,416))\n",
        "\n",
        "model.val()  # It'll automatically evaluate the data you trained."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBYGJ6DUR9bK",
        "outputId": "6da41464-0ad3-4f16-f9de-62b6bfa377da",
        "collapsed": true
      },
      "id": "jBYGJ6DUR9bK",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 81.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.19 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/hw3_M11221004/貨櫃資料集/data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=(416, 416), save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 20.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ updating to 'imgsz=416'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/train... 2125 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2125/2125 [00:01<00:00, 1848.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/hw3_M11221004/貨櫃資料集/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/val... 536 images, 0 backgrounds, 0 corrupt: 100%|██████████| 536/536 [00:00<00:00, 1062.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/hw3_M11221004/貨櫃資料集/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/266 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       1/20     0.715G        1.2      1.783      1.038          5        416: 100%|██████████| 266/266 [00:41<00:00,  6.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:07<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.997      0.993      0.995      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20     0.652G     0.8641     0.7806     0.9145          3        416: 100%|██████████| 266/266 [00:39<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.978      0.983      0.994      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      0.65G     0.8141     0.6101      0.902          8        416: 100%|██████████| 266/266 [00:38<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1      0.998      0.995      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20     0.646G     0.8006      0.542     0.8998          7        416: 100%|██████████| 266/266 [00:37<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1      0.998      0.995      0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20     0.646G     0.7475     0.4866     0.8849          6        416: 100%|██████████| 266/266 [00:38<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20     0.654G     0.7141     0.4649     0.8816          6        416: 100%|██████████| 266/266 [00:37<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.999          1      0.995      0.852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20     0.665G     0.7058      0.436     0.8768          5        416: 100%|██████████| 266/266 [00:38<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20     0.663G      0.706     0.4249     0.8799          8        416: 100%|██████████| 266/266 [00:37<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20     0.665G     0.6834      0.411     0.8713          5        416: 100%|██████████| 266/266 [00:38<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995       0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20     0.642G     0.6606     0.3944     0.8635          3        416: 100%|██████████| 266/266 [00:38<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20     0.663G     0.6402      0.364     0.8623          5        416: 100%|██████████| 266/266 [00:37<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:06<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20     0.665G     0.6146     0.3503     0.8566          5        416: 100%|██████████| 266/266 [00:37<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20     0.663G     0.6117     0.3402     0.8626          4        416: 100%|██████████| 266/266 [00:36<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      0.64G     0.5852     0.3305     0.8528          5        416: 100%|██████████| 266/266 [00:36<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20     0.663G     0.5858     0.3217     0.8515          5        416: 100%|██████████| 266/266 [00:36<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20     0.665G     0.5679     0.3061     0.8403          4        416: 100%|██████████| 266/266 [00:36<00:00,  7.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:06<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20     0.663G     0.5559     0.2982      0.847          4        416: 100%|██████████| 266/266 [00:36<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:04<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20     0.642G     0.5363     0.2894     0.8339          5        416: 100%|██████████| 266/266 [00:36<00:00,  7.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20     0.663G     0.5268     0.2818     0.8359          4        416: 100%|██████████| 266/266 [00:36<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:03<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20     0.665G     0.5188     0.2714     0.8337          3        416: 100%|██████████| 266/266 [00:36<00:00,  7.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.240 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.19 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:04<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.874\n",
            "Speed: 0.1ms preprocess, 2.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics YOLOv8.2.19 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/貨櫃資料集/labels/val.cache... 536 images, 0 backgrounds, 0 corrupt: 100%|██████████| 536/536 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:07<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.872\n",
            "Speed: 0.2ms preprocess, 4.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79dc34ff1120>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.89782,     0.89782,     0.95106,     0.96286,     0.97638,     0.98421,     0.98509,     0.98666,     0.98916,     0.98958,     0.99017,     0.99107,     0.99187,     0.99245,     0.99273,     0.99291,     0.99309,     0.99327,     0.99345,     0.99367,     0.99389,     0.99412,     0.99435,\n",
              "            0.99449,     0.99458,     0.99467,     0.99476,     0.99485,     0.99494,     0.99503,     0.99512,     0.99521,      0.9953,     0.99576,      0.9964,     0.99659,     0.99679,     0.99698,     0.99718,     0.99722,     0.99723,     0.99724,     0.99724,     0.99725,     0.99726,     0.99727,\n",
              "            0.99728,     0.99729,      0.9973,     0.99731,     0.99732,     0.99733,     0.99734,     0.99735,     0.99736,     0.99737,     0.99737,     0.99738,     0.99739,      0.9974,     0.99741,     0.99742,     0.99743,     0.99744,     0.99745,     0.99746,     0.99747,     0.99748,     0.99749,\n",
              "            0.99749,      0.9975,     0.99751,     0.99752,     0.99753,     0.99754,     0.99755,     0.99756,     0.99757,     0.99758,     0.99759,      0.9976,     0.99761,     0.99761,     0.99762,     0.99763,     0.99764,     0.99765,     0.99766,     0.99767,     0.99768,     0.99769,      0.9977,\n",
              "            0.99771,     0.99772,     0.99773,     0.99773,     0.99774,     0.99775,     0.99776,     0.99777,     0.99778,     0.99779,      0.9978,     0.99781,     0.99782,     0.99783,     0.99784,     0.99785,     0.99785,     0.99786,     0.99787,     0.99788,     0.99789,      0.9979,     0.99791,\n",
              "            0.99792,     0.99793,     0.99794,     0.99795,     0.99796,     0.99797,     0.99797,     0.99798,     0.99799,       0.998,     0.99801,     0.99802,     0.99803,     0.99804,     0.99805,     0.99806,     0.99807,     0.99808,     0.99809,     0.99809,      0.9981,     0.99811,     0.99812,\n",
              "            0.99813,     0.99814,     0.99814,     0.99815,     0.99815,     0.99815,     0.99816,     0.99816,     0.99816,     0.99817,     0.99817,     0.99817,     0.99818,     0.99818,     0.99819,     0.99819,     0.99819,      0.9982,      0.9982,      0.9982,     0.99821,     0.99821,     0.99821,\n",
              "            0.99822,     0.99822,     0.99822,     0.99823,     0.99823,     0.99823,     0.99824,     0.99824,     0.99825,     0.99825,     0.99825,     0.99826,     0.99826,     0.99826,     0.99827,     0.99827,     0.99827,     0.99828,     0.99828,     0.99828,     0.99829,     0.99829,     0.99829,\n",
              "             0.9983,      0.9983,     0.99831,     0.99831,     0.99831,     0.99832,     0.99832,     0.99832,     0.99833,     0.99833,     0.99833,     0.99834,     0.99834,     0.99834,     0.99835,     0.99835,     0.99836,     0.99836,     0.99836,     0.99837,     0.99837,     0.99837,     0.99838,\n",
              "            0.99838,     0.99838,     0.99839,     0.99839,     0.99839,      0.9984,      0.9984,      0.9984,     0.99841,     0.99841,     0.99842,     0.99842,     0.99842,     0.99843,     0.99843,     0.99843,     0.99844,     0.99844,     0.99844,     0.99845,     0.99845,     0.99845,     0.99846,\n",
              "            0.99846,     0.99847,     0.99847,     0.99847,     0.99848,     0.99848,     0.99848,     0.99849,     0.99849,     0.99849,      0.9985,      0.9985,      0.9985,     0.99851,     0.99851,     0.99851,     0.99852,     0.99852,     0.99853,     0.99853,     0.99853,     0.99854,     0.99854,\n",
              "            0.99854,     0.99855,     0.99855,     0.99855,     0.99856,     0.99856,     0.99856,     0.99857,     0.99857,     0.99858,     0.99858,     0.99858,     0.99859,     0.99859,     0.99859,      0.9986,      0.9986,      0.9986,     0.99861,     0.99861,     0.99861,     0.99862,     0.99862,\n",
              "            0.99862,     0.99863,     0.99863,     0.99864,     0.99864,     0.99864,     0.99865,     0.99865,     0.99865,     0.99866,     0.99866,     0.99866,     0.99867,     0.99867,     0.99867,     0.99868,     0.99868,     0.99868,     0.99869,     0.99869,      0.9987,      0.9987,      0.9987,\n",
              "            0.99871,     0.99871,     0.99871,     0.99872,     0.99872,     0.99872,     0.99873,     0.99873,     0.99873,     0.99874,     0.99874,     0.99875,     0.99875,     0.99875,     0.99876,     0.99876,     0.99876,     0.99877,     0.99877,     0.99877,     0.99878,     0.99878,     0.99878,\n",
              "            0.99879,     0.99879,     0.99879,      0.9988,      0.9988,     0.99881,     0.99881,     0.99881,     0.99882,     0.99882,     0.99882,     0.99883,     0.99883,     0.99883,     0.99884,     0.99884,     0.99884,     0.99885,     0.99885,     0.99886,     0.99886,     0.99886,     0.99887,\n",
              "            0.99887,     0.99887,     0.99888,     0.99888,     0.99888,     0.99889,     0.99889,     0.99889,      0.9989,      0.9989,      0.9989,     0.99891,     0.99891,     0.99892,     0.99892,     0.99892,     0.99893,     0.99893,     0.99893,     0.99894,     0.99894,     0.99894,     0.99895,\n",
              "            0.99895,     0.99895,     0.99896,     0.99896,     0.99896,     0.99897,     0.99897,     0.99898,     0.99898,     0.99898,     0.99899,     0.99899,     0.99899,       0.999,       0.999,       0.999,     0.99901,     0.99901,     0.99901,     0.99902,     0.99902,     0.99903,     0.99903,\n",
              "            0.99903,     0.99904,     0.99904,     0.99904,     0.99905,     0.99905,     0.99905,     0.99906,     0.99906,     0.99906,     0.99907,     0.99907,     0.99908,     0.99908,     0.99908,     0.99909,     0.99909,      0.9991,      0.9991,      0.9991,     0.99911,     0.99911,     0.99912,\n",
              "            0.99912,     0.99912,     0.99913,     0.99913,     0.99913,     0.99914,     0.99914,     0.99915,     0.99915,     0.99915,     0.99916,     0.99916,     0.99917,     0.99917,     0.99917,     0.99918,     0.99918,     0.99919,     0.99919,     0.99919,      0.9992,      0.9992,     0.99921,\n",
              "            0.99921,     0.99921,     0.99922,     0.99922,     0.99923,     0.99923,     0.99923,     0.99924,     0.99924,     0.99925,     0.99925,     0.99925,     0.99926,     0.99926,     0.99927,     0.99927,     0.99927,     0.99928,     0.99928,     0.99929,     0.99929,     0.99929,      0.9993,\n",
              "             0.9993,     0.99931,     0.99931,     0.99931,     0.99932,     0.99932,     0.99932,     0.99933,     0.99933,     0.99934,     0.99934,     0.99934,     0.99935,     0.99935,     0.99936,     0.99936,     0.99936,     0.99937,     0.99937,     0.99938,     0.99938,     0.99938,     0.99939,\n",
              "            0.99939,      0.9994,      0.9994,      0.9994,     0.99941,     0.99941,     0.99942,     0.99942,     0.99942,     0.99943,     0.99943,     0.99944,     0.99944,     0.99944,     0.99945,     0.99945,     0.99946,     0.99946,     0.99946,     0.99947,     0.99947,     0.99948,     0.99948,\n",
              "            0.99948,     0.99949,     0.99949,      0.9995,      0.9995,      0.9995,     0.99951,     0.99951,     0.99952,     0.99952,     0.99952,     0.99953,     0.99953,     0.99953,     0.99954,     0.99954,     0.99955,     0.99955,     0.99955,     0.99956,     0.99956,     0.99957,     0.99957,\n",
              "            0.99957,     0.99958,     0.99958,     0.99959,     0.99959,     0.99959,      0.9996,      0.9996,     0.99961,     0.99961,     0.99961,     0.99962,     0.99962,     0.99963,     0.99963,     0.99963,     0.99964,     0.99964,     0.99965,     0.99965,     0.99965,     0.99966,     0.99966,\n",
              "            0.99967,     0.99967,     0.99967,     0.99968,     0.99968,     0.99969,     0.99969,     0.99969,      0.9997,      0.9997,      0.9997,     0.99971,     0.99971,     0.99972,     0.99972,     0.99972,     0.99973,     0.99973,     0.99974,     0.99974,     0.99974,     0.99975,     0.99975,\n",
              "            0.99976,     0.99976,     0.99976,     0.99977,     0.99977,     0.99978,     0.99978,     0.99978,     0.99979,     0.99979,      0.9998,      0.9998,      0.9998,     0.99981,     0.99981,     0.99982,     0.99982,     0.99982,     0.99983,     0.99983,     0.99984,     0.99984,     0.99984,\n",
              "            0.99985,     0.99985,     0.99986,     0.99986,     0.99986,     0.99987,     0.99987,     0.99988,     0.99988,     0.99988,     0.99989,     0.99989,     0.99989,      0.9999,      0.9999,     0.99991,     0.99991,     0.99991,     0.99992,     0.99992,     0.99993,     0.99993,     0.99993,\n",
              "            0.99994,     0.99994,     0.99995,     0.99995,     0.99995,     0.99996,     0.99996,     0.99997,     0.99997,     0.99997,     0.99998,     0.99998,     0.99999,     0.99999,     0.99999,           1,     0.99997,     0.99989,     0.99982,     0.99975,     0.99967,      0.9996,     0.99953,\n",
              "            0.99945,     0.99938,     0.99931,     0.99923,     0.99916,     0.99908,     0.99904,       0.999,     0.99897,     0.99893,      0.9989,     0.99886,     0.99883,     0.99879,     0.99876,     0.99872,     0.99869,     0.99865,     0.99862,     0.99858,     0.99855,     0.99851,     0.99848,\n",
              "            0.99844,     0.99841,     0.99837,     0.99834,      0.9983,     0.99827,     0.99823,      0.9982,     0.99816,     0.99813,     0.99811,      0.9981,     0.99808,     0.99807,     0.99805,     0.99803,     0.99802,       0.998,     0.99799,     0.99797,     0.99795,     0.99794,     0.99792,\n",
              "            0.99791,     0.99789,     0.99787,     0.99786,     0.99784,     0.99783,     0.99781,     0.99779,     0.99778,     0.99776,     0.99775,     0.99773,     0.99771,      0.9977,     0.99768,     0.99767,     0.99765,     0.99763,     0.99762,      0.9976,     0.99759,     0.99757,     0.99755,\n",
              "            0.99754,     0.99752,     0.99751,     0.99749,     0.99747,     0.99746,     0.99744,     0.99743,     0.99741,     0.99739,     0.99738,     0.99736,     0.99735,     0.99733,     0.99731,      0.9973,     0.99728,     0.99727,     0.99725,     0.99723,     0.99722,      0.9972,     0.99718,\n",
              "            0.99715,     0.99711,     0.99708,     0.99705,     0.99702,     0.99698,     0.99695,     0.99692,     0.99689,     0.99685,     0.99682,     0.99679,     0.99676,     0.99672,     0.99669,     0.99666,     0.99662,     0.99659,     0.99656,     0.99653,     0.99649,     0.99646,     0.99643,\n",
              "             0.9964,     0.99636,     0.99633,      0.9963,     0.99627,     0.99623,     0.99619,     0.99615,     0.99611,     0.99607,     0.99603,       0.996,     0.99596,     0.99592,     0.99588,     0.99584,      0.9958,     0.99576,     0.99572,     0.99569,     0.99565,     0.99561,     0.99557,\n",
              "            0.99553,     0.99549,     0.99545,     0.99541,     0.99538,     0.99534,     0.99493,     0.99333,     0.99308,     0.99283,     0.99258,     0.99244,     0.99237,     0.99231,     0.99224,     0.99217,     0.99211,     0.99204,     0.99197,     0.99191,     0.99184,     0.99177,      0.9917,\n",
              "            0.99164,     0.99157,     0.99043,     0.99009,     0.98976,      0.9896,     0.98955,     0.98949,     0.98944,     0.98938,     0.98933,     0.98928,     0.98922,     0.98917,     0.98912,     0.98906,     0.98901,     0.98896,      0.9889,     0.98885,      0.9888,     0.98874,     0.98869,\n",
              "            0.98765,     0.98757,     0.98748,      0.9874,     0.98731,     0.98722,     0.98714,     0.98705,     0.98696,     0.98688,     0.98679,     0.98571,     0.98537,     0.98502,     0.98362,     0.98179,     0.98101,     0.97972,      0.9794,     0.97909,      0.9774,     0.97616,     0.97479,\n",
              "            0.97294,     0.97224,     0.97151,     0.96848,     0.96747,      0.9649,     0.96253,     0.95754,     0.95148,     0.94761,      0.9434,     0.93917,     0.93279,      0.9295,     0.92607,     0.91796,     0.91176,      0.9048,     0.90153,     0.89214,     0.88458,     0.87829,     0.86904,\n",
              "            0.86611,     0.85742,     0.85112,      0.8449,     0.83122,     0.81574,     0.80707,     0.79845,      0.7697,     0.75013,     0.73635,     0.72391,      0.6985,     0.68512,     0.65611,      0.6285,     0.59479,     0.55341,     0.51767,     0.47652,     0.45164,     0.41019,     0.38225,\n",
              "            0.34789,     0.31323,       0.296,     0.25602,     0.23421,     0.21426,     0.17767,     0.15024,     0.12896,     0.11851,     0.10827,    0.090737,    0.081332,     0.07359,    0.062732,     0.05346,    0.042292,    0.039769,    0.038449,    0.037128,    0.034011,    0.031002,     0.02761,\n",
              "            0.02229,    0.018979,    0.011606,   0.0073925,   0.0069215,   0.0064502,   0.0059787,    0.005507,   0.0050351,   0.0045629,   0.0040906,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.81459,     0.81459,     0.90668,     0.92838,     0.95385,      0.9689,     0.97061,     0.97366,     0.97855,     0.97938,     0.98054,     0.98229,     0.98388,     0.98502,     0.98557,     0.98592,     0.98628,     0.98664,     0.98699,     0.98741,     0.98786,     0.98831,     0.98876,\n",
              "            0.98904,     0.98922,      0.9894,     0.98957,     0.98975,     0.98993,     0.99011,     0.99028,     0.99046,     0.99064,     0.99155,     0.99282,     0.99321,      0.9936,     0.99399,     0.99438,     0.99445,     0.99447,     0.99449,      0.9945,     0.99452,     0.99454,     0.99456,\n",
              "            0.99458,      0.9946,     0.99462,     0.99463,     0.99465,     0.99467,     0.99469,     0.99471,     0.99473,     0.99474,     0.99476,     0.99478,      0.9948,     0.99482,     0.99484,     0.99485,     0.99487,     0.99489,     0.99491,     0.99493,     0.99495,     0.99496,     0.99498,\n",
              "              0.995,     0.99502,     0.99504,     0.99506,     0.99507,     0.99509,     0.99511,     0.99513,     0.99515,     0.99517,     0.99519,      0.9952,     0.99522,     0.99524,     0.99526,     0.99528,      0.9953,     0.99531,     0.99533,     0.99535,     0.99537,     0.99539,     0.99541,\n",
              "            0.99542,     0.99544,     0.99546,     0.99548,      0.9955,     0.99552,     0.99553,     0.99555,     0.99557,     0.99559,     0.99561,     0.99563,     0.99564,     0.99566,     0.99568,      0.9957,     0.99572,     0.99574,     0.99576,     0.99577,     0.99579,     0.99581,     0.99583,\n",
              "            0.99585,     0.99587,     0.99588,      0.9959,     0.99592,     0.99594,     0.99596,     0.99598,     0.99599,     0.99601,     0.99603,     0.99605,     0.99607,     0.99609,      0.9961,     0.99612,     0.99614,     0.99616,     0.99618,      0.9962,     0.99621,     0.99623,     0.99625,\n",
              "            0.99627,     0.99628,     0.99629,      0.9963,     0.99631,     0.99631,     0.99632,     0.99633,     0.99633,     0.99634,     0.99635,     0.99636,     0.99636,     0.99637,     0.99638,     0.99638,     0.99639,      0.9964,      0.9964,     0.99641,     0.99642,     0.99643,     0.99643,\n",
              "            0.99644,     0.99645,     0.99645,     0.99646,     0.99647,     0.99648,     0.99648,     0.99649,      0.9965,      0.9965,     0.99651,     0.99652,     0.99653,     0.99653,     0.99654,     0.99655,     0.99655,     0.99656,     0.99657,     0.99657,     0.99658,     0.99659,      0.9966,\n",
              "             0.9966,     0.99661,     0.99662,     0.99662,     0.99663,     0.99664,     0.99665,     0.99665,     0.99666,     0.99667,     0.99667,     0.99668,     0.99669,     0.99669,      0.9967,     0.99671,     0.99672,     0.99672,     0.99673,     0.99674,     0.99674,     0.99675,     0.99676,\n",
              "            0.99677,     0.99677,     0.99678,     0.99679,     0.99679,      0.9968,     0.99681,     0.99681,     0.99682,     0.99683,     0.99684,     0.99684,     0.99685,     0.99686,     0.99686,     0.99687,     0.99688,     0.99689,     0.99689,      0.9969,     0.99691,     0.99691,     0.99692,\n",
              "            0.99693,     0.99694,     0.99694,     0.99695,     0.99696,     0.99696,     0.99697,     0.99698,     0.99698,     0.99699,       0.997,     0.99701,     0.99701,     0.99702,     0.99703,     0.99703,     0.99704,     0.99705,     0.99706,     0.99706,     0.99707,     0.99708,     0.99708,\n",
              "            0.99709,      0.9971,      0.9971,     0.99711,     0.99712,     0.99713,     0.99713,     0.99714,     0.99715,     0.99715,     0.99716,     0.99717,     0.99718,     0.99718,     0.99719,      0.9972,      0.9972,     0.99721,     0.99722,     0.99722,     0.99723,     0.99724,     0.99725,\n",
              "            0.99725,     0.99726,     0.99727,     0.99727,     0.99728,     0.99729,      0.9973,      0.9973,     0.99731,     0.99732,     0.99732,     0.99733,     0.99734,     0.99735,     0.99735,     0.99736,     0.99737,     0.99737,     0.99738,     0.99739,     0.99739,      0.9974,     0.99741,\n",
              "            0.99742,     0.99742,     0.99743,     0.99744,     0.99744,     0.99745,     0.99746,     0.99747,     0.99747,     0.99748,     0.99749,     0.99749,      0.9975,     0.99751,     0.99751,     0.99752,     0.99753,     0.99754,     0.99754,     0.99755,     0.99756,     0.99756,     0.99757,\n",
              "            0.99758,     0.99759,     0.99759,      0.9976,     0.99761,     0.99761,     0.99762,     0.99763,     0.99763,     0.99764,     0.99765,     0.99766,     0.99766,     0.99767,     0.99768,     0.99768,     0.99769,      0.9977,     0.99771,     0.99771,     0.99772,     0.99773,     0.99773,\n",
              "            0.99774,     0.99775,     0.99776,     0.99776,     0.99777,     0.99778,     0.99778,     0.99779,      0.9978,      0.9978,     0.99781,     0.99782,     0.99783,     0.99783,     0.99784,     0.99785,     0.99785,     0.99786,     0.99787,     0.99788,     0.99788,     0.99789,      0.9979,\n",
              "             0.9979,     0.99791,     0.99792,     0.99792,     0.99793,     0.99794,     0.99795,     0.99795,     0.99796,     0.99797,     0.99797,     0.99798,     0.99799,       0.998,       0.998,     0.99801,     0.99802,     0.99802,     0.99803,     0.99804,     0.99804,     0.99805,     0.99806,\n",
              "            0.99807,     0.99807,     0.99808,     0.99809,     0.99809,      0.9981,     0.99811,     0.99812,     0.99812,     0.99813,     0.99814,     0.99814,     0.99815,     0.99816,     0.99817,     0.99818,     0.99818,     0.99819,      0.9982,     0.99821,     0.99822,     0.99822,     0.99823,\n",
              "            0.99824,     0.99825,     0.99826,     0.99826,     0.99827,     0.99828,     0.99829,     0.99829,      0.9983,     0.99831,     0.99832,     0.99833,     0.99833,     0.99834,     0.99835,     0.99836,     0.99837,     0.99837,     0.99838,     0.99839,      0.9984,     0.99841,     0.99841,\n",
              "            0.99842,     0.99843,     0.99844,     0.99845,     0.99845,     0.99846,     0.99847,     0.99848,     0.99848,     0.99849,      0.9985,     0.99851,     0.99852,     0.99852,     0.99853,     0.99854,     0.99855,     0.99856,     0.99856,     0.99857,     0.99858,     0.99859,      0.9986,\n",
              "             0.9986,     0.99861,     0.99862,     0.99863,     0.99864,     0.99864,     0.99865,     0.99866,     0.99867,     0.99867,     0.99868,     0.99869,      0.9987,     0.99871,     0.99871,     0.99872,     0.99873,     0.99874,     0.99875,     0.99875,     0.99876,     0.99877,     0.99878,\n",
              "            0.99879,     0.99879,      0.9988,     0.99881,     0.99882,     0.99882,     0.99883,     0.99884,     0.99885,     0.99886,     0.99886,     0.99887,     0.99888,     0.99889,      0.9989,      0.9989,     0.99891,     0.99892,     0.99893,     0.99894,     0.99894,     0.99895,     0.99896,\n",
              "            0.99897,     0.99898,     0.99898,     0.99899,       0.999,     0.99901,     0.99901,     0.99902,     0.99903,     0.99904,     0.99905,     0.99905,     0.99906,     0.99907,     0.99908,     0.99909,     0.99909,      0.9991,     0.99911,     0.99912,     0.99913,     0.99913,     0.99914,\n",
              "            0.99915,     0.99916,     0.99916,     0.99917,     0.99918,     0.99919,      0.9992,      0.9992,     0.99921,     0.99922,     0.99923,     0.99924,     0.99924,     0.99925,     0.99926,     0.99927,     0.99928,     0.99928,     0.99929,      0.9993,     0.99931,     0.99932,     0.99932,\n",
              "            0.99933,     0.99934,     0.99935,     0.99935,     0.99936,     0.99937,     0.99938,     0.99939,     0.99939,      0.9994,     0.99941,     0.99942,     0.99943,     0.99943,     0.99944,     0.99945,     0.99946,     0.99947,     0.99947,     0.99948,     0.99949,      0.9995,     0.99951,\n",
              "            0.99951,     0.99952,     0.99953,     0.99954,     0.99954,     0.99955,     0.99956,     0.99957,     0.99958,     0.99958,     0.99959,      0.9996,     0.99961,     0.99962,     0.99962,     0.99963,     0.99964,     0.99965,     0.99966,     0.99966,     0.99967,     0.99968,     0.99969,\n",
              "            0.99969,      0.9997,     0.99971,     0.99972,     0.99973,     0.99973,     0.99974,     0.99975,     0.99976,     0.99977,     0.99977,     0.99978,     0.99979,      0.9998,     0.99981,     0.99981,     0.99982,     0.99983,     0.99984,     0.99985,     0.99985,     0.99986,     0.99987,\n",
              "            0.99988,     0.99988,     0.99989,      0.9999,     0.99991,     0.99992,     0.99992,     0.99993,     0.99994,     0.99995,     0.99996,     0.99996,     0.99997,     0.99998,     0.99999,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99994,     0.99979,     0.99964,     0.99949,     0.99935,      0.9992,     0.99905,\n",
              "            0.99891,     0.99876,     0.99861,     0.99846,     0.99832,     0.99817,     0.99808,     0.99801,     0.99794,     0.99787,      0.9978,     0.99773,     0.99766,     0.99759,     0.99752,     0.99745,     0.99738,     0.99731,     0.99724,     0.99717,      0.9971,     0.99703,     0.99696,\n",
              "            0.99689,     0.99682,     0.99675,     0.99668,     0.99661,     0.99654,     0.99647,      0.9964,     0.99633,     0.99627,     0.99623,      0.9962,     0.99617,     0.99614,     0.99611,     0.99608,     0.99604,     0.99601,     0.99598,     0.99595,     0.99592,     0.99588,     0.99585,\n",
              "            0.99582,     0.99579,     0.99576,     0.99573,     0.99569,     0.99566,     0.99563,      0.9956,     0.99557,     0.99553,      0.9955,     0.99547,     0.99544,     0.99541,     0.99538,     0.99534,     0.99531,     0.99528,     0.99525,     0.99522,     0.99518,     0.99515,     0.99512,\n",
              "            0.99509,     0.99506,     0.99503,     0.99499,     0.99496,     0.99493,      0.9949,     0.99487,     0.99483,      0.9948,     0.99477,     0.99474,     0.99471,     0.99468,     0.99464,     0.99461,     0.99458,     0.99455,     0.99452,     0.99448,     0.99445,     0.99442,     0.99437,\n",
              "            0.99431,     0.99425,     0.99418,     0.99412,     0.99405,     0.99399,     0.99392,     0.99386,     0.99379,     0.99373,     0.99366,      0.9936,     0.99353,     0.99347,      0.9934,     0.99334,     0.99327,     0.99321,     0.99314,     0.99308,     0.99301,     0.99295,     0.99288,\n",
              "            0.99282,     0.99275,     0.99269,     0.99262,     0.99256,     0.99249,     0.99241,     0.99233,     0.99225,     0.99218,      0.9921,     0.99202,     0.99195,     0.99187,     0.99179,     0.99172,     0.99164,     0.99156,     0.99149,     0.99141,     0.99133,     0.99125,     0.99118,\n",
              "             0.9911,     0.99102,     0.99095,     0.99087,     0.99079,     0.99072,     0.98991,     0.98675,     0.98626,     0.98577,     0.98527,       0.985,     0.98486,     0.98473,      0.9846,     0.98447,     0.98434,      0.9842,     0.98407,     0.98394,     0.98381,     0.98368,     0.98354,\n",
              "            0.98341,     0.98328,     0.98104,     0.98038,     0.97972,     0.97941,     0.97931,      0.9792,      0.9791,     0.97899,     0.97889,     0.97878,     0.97868,     0.97857,     0.97847,     0.97836,     0.97826,     0.97816,     0.97805,     0.97795,     0.97784,     0.97774,     0.97763,\n",
              "            0.97561,     0.97544,     0.97527,      0.9751,     0.97494,     0.97477,      0.9746,     0.97443,     0.97426,     0.97409,     0.97392,     0.97183,     0.97116,     0.97049,     0.96776,     0.96423,     0.96272,     0.96024,     0.95964,     0.95904,      0.9558,     0.95343,     0.95082,\n",
              "            0.94731,     0.94598,      0.9446,     0.93888,     0.93699,     0.93218,     0.92776,     0.91854,     0.90745,     0.90043,     0.89286,     0.88531,     0.87405,     0.86828,     0.86232,     0.84837,     0.83783,     0.82616,     0.82072,     0.80528,     0.79304,     0.78299,     0.76842,\n",
              "            0.76383,     0.75042,     0.74082,     0.73144,     0.71119,     0.68882,     0.67654,     0.66452,     0.62562,     0.60016,     0.58271,     0.56729,     0.53669,     0.52105,     0.48822,     0.45825,     0.42328,     0.38256,     0.34923,     0.31279,     0.29169,     0.25801,     0.23628,\n",
              "            0.21058,      0.1857,     0.17371,      0.1468,     0.13264,     0.11998,    0.097499,    0.081219,    0.068924,    0.062987,    0.057234,    0.047525,     0.04239,    0.038201,    0.032382,    0.027464,    0.021603,    0.020288,    0.019602,    0.018915,      0.0173,    0.015745,    0.013998,\n",
              "           0.011271,   0.0095803,   0.0058371,     0.00371,   0.0034728,   0.0032355,   0.0029983,   0.0027611,   0.0025239,   0.0022867,   0.0020495,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.8843484617858368\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.87205])\n",
              "names: {0: 'container number'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9996395541173523, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8720538464287075, 'fitness': 0.8843484617858368}\n",
              "save_dir: PosixPath('runs/detect/train2')\n",
              "speed: {'preprocess': 0.22094196348047968, 'inference': 4.340280347795629, 'loss': 0.0020955035935586955, 'postprocess': 2.1041938618047915}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將預測框存成txt檔\n",
        "\n",
        "import os\n",
        "\n",
        "# 定義圖片檔案目錄路徑\n",
        "source_directory = '/content/hw3_M11221004/圖片準確率測試集'\n",
        "\n",
        "# 預測整個目錄\n",
        "results = model.predict(source=source_directory, save=True)\n",
        "\n",
        "# 轉換預測框格式\n",
        "pred_boxes_for_iou = []\n",
        "for result in results:\n",
        "    # 获取 Result 对象的路径属性\n",
        "    image_path = result.path\n",
        "    image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    if len(result.boxes) == 0:  # 如果沒有偵測到物件\n",
        "        pred_boxes_for_iou.append({'image_id': image_id, 'boxes': [{'class_index': 0, 'coordinates': [0, 0, 0, 0]}]})\n",
        "    else:\n",
        "        boxes = [{'class_index': int(box.cls.item()), 'coordinates': [box.xyxy[0], box.xyxy[1], box.xyxy[2], box.xyxy[3]] if len(box.xyxy) == 4 else [box.xyxy[0][0], box.xyxy[0][1], box.xyxy[0][2], box.xyxy[0][3]]} for box in result.boxes]\n",
        "        pred_boxes_for_iou.append({'image_id': image_id, 'boxes': boxes})\n",
        "\n",
        "\n",
        "# 将预测结果保存到 TXT 文件\n",
        "with open('pred_boxes_for_iou.txt', 'w') as txtfile:\n",
        "    for prediction in pred_boxes_for_iou:\n",
        "        image_id = prediction['image_id']\n",
        "        for box in prediction['boxes']:\n",
        "            class_index = box['class_index']\n",
        "            x_min, y_min, x_max, y_max = box['coordinates']\n",
        "            txtfile.write(f\"{image_id} {class_index} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
        "\n",
        "print(\"預測框已保存到文件中\")\n"
      ],
      "metadata": {
        "id": "Cv6cB8jj9GN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380a62f5-e094-4f3d-9de5-00cb502e1743"
      },
      "id": "Cv6cB8jj9GN6",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/35 /content/hw3_M11221004/圖片準確率測試集/FFAU2895947.jpg: 256x416 1 container number, 56.9ms\n",
            "image 2/35 /content/hw3_M11221004/圖片準確率測試集/MAGU5605323.jpg: 256x416 1 container number, 6.7ms\n",
            "image 3/35 /content/hw3_M11221004/圖片準確率測試集/SEKU5875349.jpg: 256x416 1 container number, 7.0ms\n",
            "image 4/35 /content/hw3_M11221004/圖片準確率測試集/SEKU5877491.jpg: 256x416 2 container numbers, 6.9ms\n",
            "image 5/35 /content/hw3_M11221004/圖片準確率測試集/SEKU6026686.jpg: 256x416 (no detections), 6.9ms\n",
            "image 6/35 /content/hw3_M11221004/圖片準確率測試集/TCNU6246126.jpg: 256x416 1 container number, 6.8ms\n",
            "image 7/35 /content/hw3_M11221004/圖片準確率測試集/TLLU4080736.jpg: 256x416 1 container number, 6.3ms\n",
            "image 8/35 /content/hw3_M11221004/圖片準確率測試集/TRHU8927462.jpg: 256x416 1 container number, 6.4ms\n",
            "image 9/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5017340.jpg: 256x416 1 container number, 6.7ms\n",
            "image 10/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5029819.jpg: 256x416 1 container number, 6.4ms\n",
            "image 11/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5042071.jpg: 256x416 1 container number, 6.5ms\n",
            "image 12/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5061615.jpg: 256x416 1 container number, 6.7ms\n",
            "image 13/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5099400.jpg: 256x416 1 container number, 9.1ms\n",
            "image 14/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5142300.jpg: 256x416 1 container number, 10.0ms\n",
            "image 15/35 /content/hw3_M11221004/圖片準確率測試集/TSSU5160351.jpg: 256x416 1 container number, 13.6ms\n",
            "image 16/35 /content/hw3_M11221004/圖片準確率測試集/WHLU5591798.jpg: 256x416 1 container number, 7.9ms\n",
            "image 17/35 /content/hw3_M11221004/圖片準確率測試集/WHLU5842825.jpg: 256x416 1 container number, 6.9ms\n",
            "image 18/35 /content/hw3_M11221004/圖片準確率測試集/WHSU2483178.jpg: 256x416 1 container number, 6.1ms\n",
            "image 19/35 /content/hw3_M11221004/圖片準確率測試集/WHSU2615314.jpg: 256x416 1 container number, 6.2ms\n",
            "image 20/35 /content/hw3_M11221004/圖片準確率測試集/WHSU2864765.jpg: 256x416 1 container number, 7.5ms\n",
            "image 21/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5295430.jpg: 256x416 1 container number, 7.5ms\n",
            "image 22/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5368199.jpg: 256x416 1 container number, 7.3ms\n",
            "image 23/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5563298.jpg: 256x416 1 container number, 6.8ms\n",
            "image 24/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5610492.jpg: 256x416 1 container number, 6.5ms\n",
            "image 25/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5628589.jpg: 256x416 1 container number, 6.7ms\n",
            "image 26/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5744465.jpg: 256x416 1 container number, 7.0ms\n",
            "image 27/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5991104.jpg: 256x416 1 container number, 6.0ms\n",
            "image 28/35 /content/hw3_M11221004/圖片準確率測試集/WHSU5998393.jpg: 256x416 1 container number, 6.2ms\n",
            "image 29/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6010260.jpg: 256x416 1 container number, 6.3ms\n",
            "image 30/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6040178.jpg: 256x416 1 container number, 12.1ms\n",
            "image 31/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6052306.jpg: 256x416 1 container number, 10.1ms\n",
            "image 32/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6167120.jpg: 256x416 1 container number, 7.9ms\n",
            "image 33/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6557387.jpg: 256x416 1 container number, 6.7ms\n",
            "image 34/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6651665.jpg: 256x416 1 container number, 6.4ms\n",
            "image 35/35 /content/hw3_M11221004/圖片準確率測試集/WHSU6856285.jpg: 256x416 2 container numbers, 7.3ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "預測框已保存到文件中\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將重複預測框使用NMS去除\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# 讀取預測框\n",
        "def read_prediction_boxes_from_txt(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    boxes_by_image = {}\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 6:\n",
        "            continue  # 忽略不完整的行\n",
        "        img_name = parts[0]\n",
        "        class_name = parts[1]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        if img_name not in boxes_by_image:\n",
        "            boxes_by_image[img_name] = []\n",
        "        boxes_by_image[img_name].append((class_name, x1, y1, x2, y2))\n",
        "    return boxes_by_image\n",
        "\n",
        "\n",
        "def save_boxes_to_txt_with_nms(boxes_by_image, file_path, iou_threshold=0.5):\n",
        "    print(\"Saving boxes to:\", file_path)  # 添加这行以打印保存的文件路径\n",
        "    with open(file_path, 'w') as f:\n",
        "        for img_name, img_boxes in boxes_by_image.items():\n",
        "            # 对每张图片的预测框进行NMS处理\n",
        "            nms_boxes = apply_nms(img_boxes, iou_threshold)\n",
        "            for box in nms_boxes:\n",
        "                img_class, x1, y1, x2, y2 = box\n",
        "                f.write(f\"{img_name} {img_class} {x1} {y1} {x2} {y2}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def apply_nms(boxes, iou_threshold):\n",
        "    if not boxes:\n",
        "        return []\n",
        "\n",
        "    # Sort boxes based on confidence scores (assuming confidence score is not present)\n",
        "    sorted_boxes = sorted(boxes, key=lambda x: x[1])  # Sort based on class_name\n",
        "\n",
        "    nms_boxes = []\n",
        "    while sorted_boxes:\n",
        "        current_box = sorted_boxes.pop(0)\n",
        "        nms_boxes.append(current_box)\n",
        "        # Remove other boxes with IoU greater than threshold with the current box\n",
        "        sorted_boxes = [box for box in sorted_boxes if calculate_iou(box, current_box) < iou_threshold]\n",
        "\n",
        "    print(\"NMS Boxes:\", nms_boxes)  # 添加这行以打印筛选后的框\n",
        "\n",
        "    return nms_boxes\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1[1], box1[2], box1[3], box1[4]\n",
        "    x3, y3, x4, y4 = box2[1], box2[2], box2[3], box2[4]\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    x_intersection1 = max(x1, x3)\n",
        "    y_intersection1 = max(y1, y3)\n",
        "    x_intersection2 = min(x2, x4)\n",
        "    y_intersection2 = min(y2, y4)\n",
        "\n",
        "    # Calculate intersection area\n",
        "    intersection_width = max(0, x_intersection2 - x_intersection1 + 1)\n",
        "    intersection_height = max(0, y_intersection2 - y_intersection1 + 1)\n",
        "    intersection_area = intersection_width * intersection_height\n",
        "\n",
        "    # Calculate area for each box\n",
        "    area_box1 = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    area_box2 = (x4 - x3 + 1) * (y4 - y3 + 1)\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection_area / float(area_box1 + area_box2 - intersection_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "# 讀取預測框\n",
        "boxes = read_prediction_boxes_from_txt('pred_boxes_for_iou.txt')\n",
        "# 將預測框進行NMS處理並保存到文件中\n",
        "save_boxes_to_txt_with_nms(boxes, 'nms_pred_boxes_for_iou.txt', iou_threshold=0.1)\n"
      ],
      "metadata": {
        "id": "qtwi-RwCNZjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24cb54d-6625-48eb-f29f-6ac71be131bd"
      },
      "id": "qtwi-RwCNZjv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving boxes to: nms_pred_boxes_for_iou.txt\n",
            "NMS Boxes: [('0', 809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812)]\n",
            "NMS Boxes: [('0', 873.1626586914062, 366.3352355957031, 1194.9390869140625, 513.7098999023438)]\n",
            "NMS Boxes: [('0', 815.1351318359375, 22.03270721435547, 976.1596069335938, 112.34261322021484)]\n",
            "NMS Boxes: [('0', 872.0701293945312, 102.8860855102539, 1081.037109375, 234.52272033691406)]\n",
            "NMS Boxes: [('0', 0.0, 0.0, 0.0, 0.0)]\n",
            "NMS Boxes: [('0', 799.1828002929688, 109.80933380126953, 1114.87548828125, 247.7976837158203)]\n",
            "NMS Boxes: [('0', 888.181640625, 321.4427185058594, 1181.986328125, 455.28314208984375)]\n",
            "NMS Boxes: [('0', 557.2132568359375, 68.03431701660156, 739.69970703125, 148.6082305908203)]\n",
            "NMS Boxes: [('0', 494.95428466796875, 99.1235122680664, 718.9732055664062, 197.6240692138672)]\n",
            "NMS Boxes: [('0', 454.249267578125, 18.463581085205078, 611.65087890625, 91.51872253417969)]\n",
            "NMS Boxes: [('0', 847.5410766601562, 15.187524795532227, 1027.642333984375, 113.15298461914062)]\n",
            "NMS Boxes: [('0', 493.5251159667969, 35.32341766357422, 646.107177734375, 112.31429290771484)]\n",
            "NMS Boxes: [('0', 618.1014404296875, 96.71002960205078, 875.7691650390625, 224.2683563232422)]\n",
            "NMS Boxes: [('0', 736.9159545898438, 258.1374816894531, 1149.952392578125, 439.09625244140625)]\n",
            "NMS Boxes: [('0', 550.4066162109375, 62.59148406982422, 736.8045043945312, 150.60739135742188)]\n",
            "NMS Boxes: [('0', 917.1697998046875, 274.5277099609375, 1171.8109130859375, 376.395263671875)]\n",
            "NMS Boxes: [('0', 913.8927001953125, 241.12359619140625, 1158.686279296875, 359.35205078125)]\n",
            "NMS Boxes: [('0', 965.2523193359375, 148.31394958496094, 1076.2281494140625, 212.6099853515625)]\n",
            "NMS Boxes: [('0', 875.1309814453125, 69.6878433227539, 1113.4210205078125, 179.50296020507812)]\n",
            "NMS Boxes: [('0', 868.640380859375, 371.1065368652344, 1172.1561279296875, 501.86468505859375)]\n",
            "NMS Boxes: [('0', 795.5057983398438, 81.56464385986328, 1081.2857666015625, 203.8123321533203)]\n",
            "NMS Boxes: [('0', 751.9009399414062, 99.50450897216797, 1053.5714111328125, 230.80950927734375)]\n",
            "NMS Boxes: [('0', 706.3908081054688, 265.4079895019531, 956.8006591796875, 375.4702453613281)]\n",
            "NMS Boxes: [('0', 951.4073486328125, 613.934326171875, 1537.2320556640625, 848.4097290039062)]\n",
            "NMS Boxes: [('0', 750.6513671875, 91.65377807617188, 1043.9061279296875, 221.6487274169922)]\n",
            "NMS Boxes: [('0', 945.4542236328125, 454.7745361328125, 1385.9649658203125, 640.6891479492188)]\n",
            "NMS Boxes: [('0', 509.62591552734375, 78.08295440673828, 723.62158203125, 170.82151794433594)]\n",
            "NMS Boxes: [('0', 550.8336791992188, 45.75040054321289, 726.7974243164062, 124.10578918457031)]\n",
            "NMS Boxes: [('0', 784.210693359375, 423.94403076171875, 1210.7906494140625, 599.2708129882812)]\n",
            "NMS Boxes: [('0', 565.2068481445312, 282.5029602050781, 825.3998413085938, 392.9221496582031)]\n",
            "NMS Boxes: [('0', 906.256591796875, 243.07191467285156, 1150.995849609375, 359.837646484375)]\n",
            "NMS Boxes: [('0', 688.3995971679688, 352.52264404296875, 1014.1488647460938, 499.03643798828125)]\n",
            "NMS Boxes: [('0', 550.02978515625, 9.468994140625, 707.154541015625, 79.60198211669922)]\n",
            "NMS Boxes: [('0', 758.2356567382812, 103.15608978271484, 1097.291748046875, 240.33180236816406)]\n",
            "NMS Boxes: [('0', 702.3404541015625, 254.8941192626953, 1160.6143798828125, 440.1466979980469)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查每個圖片是否只有一個預測框\n",
        "import os\n",
        "\n",
        "# 讀取預測框\n",
        "def read_prediction_boxes_from_txt(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 6:\n",
        "            continue  # 忽略不完整的行\n",
        "        img_name = parts[0]\n",
        "        score = float(parts[-1])\n",
        "        x1, y1, x2, y2 = map(float, parts[-5:-1])\n",
        "        boxes.append((img_name, x1, y1, x2, y2, score))\n",
        "    return boxes\n",
        "\n",
        "# 確保每個圖片只有一個預測框\n",
        "def ensure_single_prediction_per_image(prediction_boxes):\n",
        "    unique_image_names = set()\n",
        "    single_prediction_boxes = []\n",
        "    for box in prediction_boxes:\n",
        "        img_name = box[0]\n",
        "        if img_name not in unique_image_names:\n",
        "            single_prediction_boxes.append(box)\n",
        "            unique_image_names.add(img_name)\n",
        "    return single_prediction_boxes\n",
        "\n",
        "# 讀取預測框\n",
        "prediction_boxes = read_prediction_boxes_from_txt('nms_pred_boxes_for_iou.txt')\n",
        "\n",
        "# 確保每個圖片只有一個預測框\n",
        "single_prediction_boxes = ensure_single_prediction_per_image(prediction_boxes)\n",
        "\n",
        "# 打印結果\n",
        "print(f\"原始預測框數量: {len(prediction_boxes)}\")\n",
        "print(f\"確保每個圖片只有一個預測框後的預測框數量: {len(single_prediction_boxes)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O7B6-gHjCSV",
        "outputId": "dff3f261-a9f9-47cc-c611-14d237346816"
      },
      "id": "5O7B6-gHjCSV",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始預測框數量: 35\n",
            "確保每個圖片只有一個預測框後的預測框數量: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入真實框\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def get_image_resolution(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size  # 返回 (width, height)\n",
        "\n",
        "def read_true_boxes(labels_directory, images_directory):\n",
        "    true_boxes = {}\n",
        "    for label_file in os.listdir(labels_directory):\n",
        "        if label_file.endswith('.txt'):\n",
        "            image_id = os.path.splitext(label_file)[0]\n",
        "            image_path = os.path.join(images_directory, image_id + \".jpg\")  # 假設影像文件格式為.jpg\n",
        "\n",
        "            # 确保对应的影像文件存在\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image file {image_path} does not exist. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            with open(os.path.join(labels_directory, label_file), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            boxes = []\n",
        "            image_width, image_height = get_image_resolution(image_path)\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:  # 确保每行有5个部分\n",
        "                    class_index = int(parts[0])\n",
        "                    x_center = float(parts[1])\n",
        "                    y_center = float(parts[2])\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    # 计算左上角和右下角坐标\n",
        "                    x1 = int((x_center - width / 2) * image_width)\n",
        "                    y1 = int((y_center - height / 2) * image_height)\n",
        "                    x2 = int((x_center + width / 2) * image_width)\n",
        "                    y2 = int((y_center + height / 2) * image_height)\n",
        "                    boxes.append({'class_index': class_index, 'coordinates': [x1, y1, x2, y2]})\n",
        "            true_boxes[image_id] = boxes\n",
        "    return true_boxes\n",
        "\n",
        "# 真實框的資料夾路徑\n",
        "labels_directory = '/content/hw3_M11221004/貨櫃資料集/labels/test'\n",
        "# 影像的資料夾路徑\n",
        "images_directory = '/content/hw3_M11221004/貨櫃資料集/測試集'\n",
        "\n",
        "# 讀取真實框\n",
        "true_boxes = read_true_boxes(labels_directory, images_directory)\n",
        "\n",
        "# 將真實框轉換成易於計算 IoU 的格式\n",
        "true_boxes_for_iou = [{'image_id': image_id, 'boxes': boxes} for image_id, boxes in true_boxes.items()]\n",
        "\n",
        "# 按照影像序號排序真實框\n",
        "true_boxes_for_iou.sort(key=lambda x: int(x['image_id'].split('_')[-1]))\n",
        "\n",
        "# 將真實框保存到 TXT 文件\n",
        "output_path = '/content/true_boxes_for_iou.txt'  # 確保路徑正確\n",
        "with open(output_path, 'w') as txtfile:\n",
        "    for true_box in true_boxes_for_iou:\n",
        "        image_id = true_box['image_id']\n",
        "        for box in true_box['boxes']:\n",
        "            class_index = box['class_index']\n",
        "            x_min, y_min, x_max, y_max = box['coordinates']\n",
        "            txtfile.write(f\"{image_id} {class_index} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
        "\n",
        "print(\"真實框轉換完成\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ab-m4DuTjLd",
        "outputId": "90736d4b-a558-4fe9-dfd6-acfc637417c8"
      },
      "id": "6Ab-m4DuTjLd",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "真實框轉換完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 目視檢查真實框是否有對應到實際圖片\n",
        "'''\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def draw_boxes_on_image(image_path, boxes, output_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        for box in boxes:\n",
        "            class_index = box['class_index']\n",
        "            x1, y1, x2, y2 = box['coordinates']\n",
        "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
        "            draw.text((x1, y1), str(class_index), fill=\"red\")\n",
        "        img.save(output_path)\n",
        "\n",
        "# 真實框的文件路徑\n",
        "true_boxes_file = '/content/true_boxes_for_iou.txt'\n",
        "# 影像的資料夾路徑\n",
        "images_directory = '/content/hw3_M11221004/貨櫃資料集/測試集'\n",
        "# 繪製結果的資料夾路徑\n",
        "draw_directory = '/content/draw'\n",
        "\n",
        "# 確保繪製結果的資料夾存在\n",
        "os.makedirs(draw_directory, exist_ok=True)\n",
        "\n",
        "# 讀取真實框數據\n",
        "true_boxes = {}\n",
        "with open(true_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        image_id = parts[0]\n",
        "        class_index = int(parts[1])\n",
        "        x_min = int(parts[2])\n",
        "        y_min = int(parts[3])\n",
        "        x_max = int(parts[4])\n",
        "        y_max = int(parts[5])\n",
        "        box = {'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]}\n",
        "        if image_id not in true_boxes:\n",
        "            true_boxes[image_id] = []\n",
        "        true_boxes[image_id].append(box)\n",
        "\n",
        "# 繪製並保存影像\n",
        "for image_id, boxes in true_boxes.items():\n",
        "    image_path = os.path.join(images_directory, image_id + \".jpg\")\n",
        "    output_image_path = os.path.join(draw_directory, image_id + \".jpg\")\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Image file {image_path} does not exist. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    draw_boxes_on_image(image_path, boxes, output_image_path)\n",
        "\n",
        "print(\"所有影像已繪製並保存完成\")\n",
        "'''"
      ],
      "metadata": {
        "id": "0Y0XkCiHHdha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f09a69d9-0791-4b10-9b02-cdd65fc40d10"
      },
      "id": "0Y0XkCiHHdha",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom PIL import Image, ImageDraw\\n\\ndef draw_boxes_on_image(image_path, boxes, output_path):\\n    with Image.open(image_path) as img:\\n        draw = ImageDraw.Draw(img)\\n        for box in boxes:\\n            class_index = box[\\'class_index\\']\\n            x1, y1, x2, y2 = box[\\'coordinates\\']\\n            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\\n            draw.text((x1, y1), str(class_index), fill=\"red\")\\n        img.save(output_path)\\n\\n# 真實框的文件路徑\\ntrue_boxes_file = \\'/content/true_boxes_for_iou.txt\\'\\n# 影像的資料夾路徑\\nimages_directory = \\'/content/hw3_M11221004/貨櫃資料集/測試集\\'\\n# 繪製結果的資料夾路徑\\ndraw_directory = \\'/content/draw\\'\\n\\n# 確保繪製結果的資料夾存在\\nos.makedirs(draw_directory, exist_ok=True)\\n\\n# 讀取真實框數據\\ntrue_boxes = {}\\nwith open(true_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        image_id = parts[0]\\n        class_index = int(parts[1])\\n        x_min = int(parts[2])\\n        y_min = int(parts[3])\\n        x_max = int(parts[4])\\n        y_max = int(parts[5])\\n        box = {\\'class_index\\': class_index, \\'coordinates\\': [x_min, y_min, x_max, y_max]}\\n        if image_id not in true_boxes:\\n            true_boxes[image_id] = []\\n        true_boxes[image_id].append(box)\\n\\n# 繪製並保存影像\\nfor image_id, boxes in true_boxes.items():\\n    image_path = os.path.join(images_directory, image_id + \".jpg\")\\n    output_image_path = os.path.join(draw_directory, image_id + \".jpg\")\\n\\n    if not os.path.exists(image_path):\\n        print(f\"Image file {image_path} does not exist. Skipping.\")\\n        continue\\n\\n    draw_boxes_on_image(image_path, boxes, output_image_path)\\n\\nprint(\"所有影像已繪製並保存完成\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義讀取函數來讀取框的座標\n",
        "\n",
        "import os\n",
        "\n",
        "# 定義解析函數\n",
        "def read_boxes_from_txt(file_path):\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_id = parts[0]\n",
        "            class_index = int(float(parts[1]))  # 轉換為整數\n",
        "            x_min = float(parts[2])\n",
        "            y_min = float(parts[3])\n",
        "            x_max = float(parts[4])\n",
        "            y_max = float(parts[5])\n",
        "            boxes.append({'image_id': image_id, 'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]})\n",
        "    return boxes\n",
        "\n",
        "# 讀取真實框和預測框的文件路徑\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "# 讀取真實框和預測框\n",
        "true_boxes = read_boxes_from_txt(true_boxes_file)\n",
        "pred_boxes = read_boxes_from_txt(pred_boxes_file)\n",
        "\n",
        "# 列印第一個真實框和預測框來確認格式是否正確\n",
        "if true_boxes:\n",
        "    print(\"第一個真實框:\", true_boxes[0])\n",
        "if pred_boxes:\n",
        "    print(\"第一個預測框:\", pred_boxes[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaPr3UdmEKxC",
        "outputId": "ea683584-09c4-4f96-f340-aac35d484c07"
      },
      "id": "QaPr3UdmEKxC",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一個真實框: {'image_id': 'image_0001', 'class_index': 0, 'coordinates': [743.0, 114.0, 1110.0, 238.0]}\n",
            "第一個預測框: {'image_id': 'FFAU2895947', 'class_index': 0, 'coordinates': [809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算IoU 與 讀取真實框、預測框座標文件\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1_min, y1_min, x1_max, y1_max = box1\n",
        "    x2_min, y2_min, x2_max, y2_max = box2\n",
        "\n",
        "    inter_x_min = max(x1_min, x2_min)\n",
        "    inter_y_min = max(y1_min, y2_min)\n",
        "    inter_x_max = min(x1_max, x2_max)\n",
        "    inter_y_max = min(y1_max, y2_max)\n",
        "\n",
        "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
        "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area != 0 else 0\n",
        "\n",
        "\n",
        "# 讀取預測框和真實框的文件\n",
        "def read_boxes_from_txt(file_path):\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_id = parts[0]\n",
        "            class_index = int(float(parts[1]))  # 轉換為整數\n",
        "            x_min = float(parts[2])\n",
        "            y_min = float(parts[3])\n",
        "            x_max = float(parts[4])\n",
        "            y_max = float(parts[5])\n",
        "            boxes.append({'image_id': image_id, 'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]})\n",
        "    return boxes\n",
        "\n",
        "# 讀取真實框和預測框\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "true_boxes = read_boxes_from_txt(true_boxes_file)\n",
        "pred_boxes = read_boxes_from_txt(pred_boxes_file)\n",
        "\n",
        "# 打印一些样本数据进行检查\n",
        "print(\"Sample true boxes:\")\n",
        "for i in range(5):\n",
        "    print(true_boxes[i])\n",
        "\n",
        "print(\"\\nSample prediction boxes:\")\n",
        "for i in range(5):\n",
        "    print(pred_boxes[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zIk5uHh8Z3M",
        "outputId": "83d1a5da-fc30-4a88-e4ce-dbee96e11580"
      },
      "id": "5zIk5uHh8Z3M",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample true boxes:\n",
            "{'image_id': 'image_0001', 'class_index': 0, 'coordinates': [743.0, 114.0, 1110.0, 238.0]}\n",
            "{'image_id': 'image_0002', 'class_index': 0, 'coordinates': [739.0, 158.0, 1160.0, 302.0]}\n",
            "{'image_id': 'image_0003', 'class_index': 0, 'coordinates': [728.0, 155.0, 1159.0, 294.0]}\n",
            "{'image_id': 'image_0004', 'class_index': 0, 'coordinates': [784.0, 98.0, 1128.0, 211.0]}\n",
            "{'image_id': 'image_0005', 'class_index': 0, 'coordinates': [820.0, 38.0, 1097.0, 136.0]}\n",
            "\n",
            "Sample prediction boxes:\n",
            "{'image_id': 'FFAU2895947', 'class_index': 0, 'coordinates': [809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812]}\n",
            "{'image_id': 'MAGU5605323', 'class_index': 0, 'coordinates': [873.1626586914062, 366.3352355957031, 1194.9390869140625, 513.7098999023438]}\n",
            "{'image_id': 'SEKU5875349', 'class_index': 0, 'coordinates': [815.1351318359375, 22.03270721435547, 976.1596069335938, 112.34261322021484]}\n",
            "{'image_id': 'SEKU5877491', 'class_index': 0, 'coordinates': [872.0701293945312, 102.8860855102539, 1081.037109375, 234.52272033691406]}\n",
            "{'image_id': 'SEKU6026686', 'class_index': 0, 'coordinates': [0.0, 0.0, 0.0, 0.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 讀取預測框檔案\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "\n",
        "pred_boxes = {}\n",
        "true_boxes = {}\n",
        "\n",
        "with open(pred_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        img_name = parts[0]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        pred_boxes[img_name] = (x1, y1, w, h)\n",
        "\n",
        "with open(true_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        img_name = parts[0]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        true_boxes[img_name] = (x1, y1, w, h)\n",
        "\n",
        "# 定義 IoU 計算函數\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    x_left = max(x1, x2)\n",
        "    y_top = max(y1, y2)\n",
        "    x_right = min(x1 + w1, x2 + w2)\n",
        "    y_bottom = min(y1 + h1, y2 + h2)\n",
        "\n",
        "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        return 0\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# 讀取 image_0XXX 的預測框和真實框座標\n",
        "image_name = 'image_0719'\n",
        "pred_coordinates = pred_boxes.get(image_name, (0, 0, 0, 0))\n",
        "true_coordinates = true_boxes.get(image_name, (0, 0, 0, 0))\n",
        "\n",
        "# 計算 IoU\n",
        "iou = calculate_iou(pred_coordinates, true_coordinates)\n",
        "print(f\"{image_name} 的 IoU:\", iou)\n",
        "'''"
      ],
      "metadata": {
        "id": "7h03sd0o_F_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "2e412edd-2ab4-4f8a-8bd7-b9b48fcb3a66"
      },
      "id": "7h03sd0o_F_6",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 讀取預測框檔案\\npred_boxes_file = \\'nms_pred_boxes_for_iou.txt\\'\\ntrue_boxes_file = \\'true_boxes_for_iou.txt\\'\\n\\npred_boxes = {}\\ntrue_boxes = {}\\n\\nwith open(pred_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        img_name = parts[0]\\n        x1, y1, x2, y2 = map(float, parts[2:])\\n        w = x2 - x1\\n        h = y2 - y1\\n        pred_boxes[img_name] = (x1, y1, w, h)\\n\\nwith open(true_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        img_name = parts[0]\\n        x1, y1, x2, y2 = map(float, parts[2:])\\n        w = x2 - x1\\n        h = y2 - y1\\n        true_boxes[img_name] = (x1, y1, w, h)\\n\\n# 定義 IoU 計算函數\\ndef calculate_iou(box1, box2):\\n    x1, y1, w1, h1 = box1\\n    x2, y2, w2, h2 = box2\\n\\n    x_left = max(x1, x2)\\n    y_top = max(y1, y2)\\n    x_right = min(x1 + w1, x2 + w2)\\n    y_bottom = min(y1 + h1, y2 + h2)\\n\\n    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\\n    box1_area = w1 * h1\\n    box2_area = w2 * h2\\n    union_area = box1_area + box2_area - intersection_area\\n\\n    if union_area == 0:\\n        return 0\\n\\n    iou = intersection_area / union_area\\n    return iou\\n\\n# 讀取 image_0XXX 的預測框和真實框座標\\nimage_name = \\'image_0719\\'\\npred_coordinates = pred_boxes.get(image_name, (0, 0, 0, 0))\\ntrue_coordinates = true_boxes.get(image_name, (0, 0, 0, 0))\\n\\n# 計算 IoU\\niou = calculate_iou(pred_coordinates, true_coordinates)\\nprint(f\"{image_name} 的 IoU:\", iou)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 初始化統計變量\n",
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "total_iou = 0\n",
        "total_predictions = 0\n",
        "iou_threshold = 0.5  # IoU 大於 閾值 才算正樣本\n",
        "\n",
        "# 遍歷每個樣本\n",
        "for img_name in pred_boxes.keys():\n",
        "    # 取得每個樣本的預測框和真實框\n",
        "    pred_box = pred_boxes[img_name]\n",
        "    true_box = true_boxes[img_name]\n",
        "\n",
        "    # 取出預測框和真實框的坐標\n",
        "    pred_coordinates = pred_box\n",
        "    true_coordinates = true_box\n",
        "\n",
        "    # 計算 IoU\n",
        "    iou = calculate_iou(pred_coordinates, true_coordinates)\n",
        "\n",
        "    # 打印每个样本的 IoU\n",
        "    print(f\"IoU for {img_name}: {iou}\")\n",
        "\n",
        "    # 根據 IoU 值更新 TP、FP 和 FN\n",
        "\n",
        "    if iou >= iou_threshold:\n",
        "        TP += 1\n",
        "    else:\n",
        "        FN += 1\n",
        "\n",
        "\n",
        "    # 更新 total_iou\n",
        "    total_iou += iou\n",
        "\n",
        "# 計算 Precision、Recall、F1-score、mAP\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "mAP = total_iou / len(pred_boxes) if len(pred_boxes) > 0 else 0\n",
        "\n",
        "# 打印所有指標的值\n",
        "print(\"TP:\", TP)\n",
        "print(\"FP:\", FP)\n",
        "print(\"FN:\", FN)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"mAP:\", mAP)\n",
        "'''"
      ],
      "metadata": {
        "id": "X11r2imysA-k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c1d264b9-eabd-405a-fedf-a6ae7416e689"
      },
      "id": "X11r2imysA-k",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 初始化統計變量\\nTP = 0\\nFP = 0\\nFN = 0\\ntotal_iou = 0\\ntotal_predictions = 0\\niou_threshold = 0.5  # IoU 大於 閾值 才算正樣本\\n\\n# 遍歷每個樣本\\nfor img_name in pred_boxes.keys():\\n    # 取得每個樣本的預測框和真實框\\n    pred_box = pred_boxes[img_name]\\n    true_box = true_boxes[img_name]\\n\\n    # 取出預測框和真實框的坐標\\n    pred_coordinates = pred_box\\n    true_coordinates = true_box\\n\\n    # 計算 IoU\\n    iou = calculate_iou(pred_coordinates, true_coordinates)\\n\\n    # 打印每个样本的 IoU\\n    print(f\"IoU for {img_name}: {iou}\")\\n\\n    # 根據 IoU 值更新 TP、FP 和 FN\\n\\n    if iou >= iou_threshold:\\n        TP += 1\\n    else:\\n        FN += 1\\n\\n\\n    # 更新 total_iou\\n    total_iou += iou\\n\\n# 計算 Precision、Recall、F1-score、mAP\\nprecision = TP / (TP + FP) if (TP + FP) > 0 else 0\\nrecall = TP / (TP + FN) if (TP + FN) > 0 else 0\\nf1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\\nmAP = total_iou / len(pred_boxes) if len(pred_boxes) > 0 else 0\\n\\n# 打印所有指標的值\\nprint(\"TP:\", TP)\\nprint(\"FP:\", FP)\\nprint(\"FN:\", FN)\\nprint(\"Precision:\", precision)\\nprint(\"Recall:\", recall)\\nprint(\"F1 Score:\", f1_score)\\nprint(\"mAP:\", mAP)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文字辨識OCR"
      ],
      "metadata": {
        "id": "9tIqw9wjUjOh"
      },
      "id": "9tIqw9wjUjOh"
    },
    {
      "cell_type": "code",
      "source": [
        "# 遇到UTF-8錯誤\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "5xGBL_Ysjp0f"
      },
      "id": "5xGBL_Ysjp0f",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "!sudo apt-get install libtesseract-dev\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "4rucANDBSvfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04337e4e-b59b-4960-a72f-662e60565772"
      },
      "id": "4rucANDBSvfc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,732 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 2s (2,256 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121965 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 讀取預測框與預測後圖片檔\n",
        "def read_bounding_boxes(file_path):\n",
        "    bounding_boxes = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_name = parts[0]\n",
        "            bbox = list(map(float, parts[1:]))\n",
        "            bounding_boxes[image_name] = bbox\n",
        "    return bounding_boxes\n",
        "\n",
        "def check_filenames(bounding_boxes, image_folder):\n",
        "    for image_name in bounding_boxes.keys():\n",
        "        image_file_name = image_name + \".jpg\"  # 假設圖片副檔名是 .jpg，根據實際情況調整\n",
        "        image_path = os.path.join(image_folder, image_file_name)\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image {image_file_name} not found in {image_folder}\")\n",
        "        else:\n",
        "            print(f\"Image {image_file_name} found and verified\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 指定預測框資料檔的路徑\n",
        "    bbox_file_path = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "    # 指定預測後圖片的資料夾路徑 (需修改成預測後圖片路徑)\n",
        "    image_folder = '/content/hw3_M11221004/圖片準確率測試集'\n",
        "\n",
        "    # 讀取預測框資料\n",
        "    bounding_boxes = read_bounding_boxes(bbox_file_path)\n",
        "\n",
        "    # 檢查檔名對應\n",
        "    check_filenames(bounding_boxes, image_folder)\n"
      ],
      "metadata": {
        "id": "CkfidtV5Xof0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece260ab-14e7-41a2-ba3f-7ca8244c251d"
      },
      "id": "CkfidtV5Xof0",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image FFAU2895947.jpg found and verified\n",
            "Image MAGU5605323.jpg found and verified\n",
            "Image SEKU5875349.jpg found and verified\n",
            "Image SEKU5877491.jpg found and verified\n",
            "Image SEKU6026686.jpg found and verified\n",
            "Image TCNU6246126.jpg found and verified\n",
            "Image TLLU4080736.jpg found and verified\n",
            "Image TRHU8927462.jpg found and verified\n",
            "Image TSSU5017340.jpg found and verified\n",
            "Image TSSU5029819.jpg found and verified\n",
            "Image TSSU5042071.jpg found and verified\n",
            "Image TSSU5061615.jpg found and verified\n",
            "Image TSSU5099400.jpg found and verified\n",
            "Image TSSU5142300.jpg found and verified\n",
            "Image TSSU5160351.jpg found and verified\n",
            "Image WHLU5591798.jpg found and verified\n",
            "Image WHLU5842825.jpg found and verified\n",
            "Image WHSU2483178.jpg found and verified\n",
            "Image WHSU2615314.jpg found and verified\n",
            "Image WHSU2864765.jpg found and verified\n",
            "Image WHSU5295430.jpg found and verified\n",
            "Image WHSU5368199.jpg found and verified\n",
            "Image WHSU5563298.jpg found and verified\n",
            "Image WHSU5610492.jpg found and verified\n",
            "Image WHSU5628589.jpg found and verified\n",
            "Image WHSU5744465.jpg found and verified\n",
            "Image WHSU5991104.jpg found and verified\n",
            "Image WHSU5998393.jpg found and verified\n",
            "Image WHSU6010260.jpg found and verified\n",
            "Image WHSU6040178.jpg found and verified\n",
            "Image WHSU6052306.jpg found and verified\n",
            "Image WHSU6167120.jpg found and verified\n",
            "Image WHSU6557387.jpg found and verified\n",
            "Image WHSU6651665.jpg found and verified\n",
            "Image WHSU6856285.jpg found and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 裁切圖片並保存\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_image(image_path):\n",
        "    return Image.open(image_path)\n",
        "\n",
        "def crop_image_with_bbox(image_path, bbox, save_folder):\n",
        "    # 解析預測框\n",
        "    x1, y1, x2, y2 = bbox[1], bbox[2], bbox[3], bbox[4]\n",
        "\n",
        "    # 檢查預測框座標是否為0 0 0 0\n",
        "    if x1 == 0 and y1 == 0 and x2 == 0 and y2 == 0:\n",
        "        print(f\"Bounding box coordinates are all zeros for image {os.path.basename(image_path)}, saving original image...\")\n",
        "        # 直接保存原始圖片\n",
        "        save_path = os.path.join(save_folder, os.path.basename(image_path))\n",
        "        image = load_image(image_path)\n",
        "        image.save(save_path)\n",
        "        print(f\"Original image saved at {save_path}\")\n",
        "        return None\n",
        "\n",
        "    # 裁切圖片\n",
        "    image = load_image(image_path)\n",
        "    cropped_image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "    # 確保保存資料夾存在\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # 取得原始檔名\n",
        "    base_name = os.path.basename(image_path)\n",
        "\n",
        "    # 保存裁切後的圖片，使用原始檔名\n",
        "    cropped_image_path = os.path.join(save_folder, base_name)\n",
        "    cropped_image.save(cropped_image_path)\n",
        "    print(f\"Cropped image saved at {cropped_image_path}\")\n",
        "\n",
        "    return cropped_image_path\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 指定預測框資料檔的路徑\n",
        "    bbox_file_path = '/content/nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "    # 指定預測後圖片的資料夾路徑\n",
        "    image_folder = '/content/hw3_M11221004/圖片準確率測試集'\n",
        "\n",
        "    # 指定裁切後圖片的保存資料夾\n",
        "    cropped_image_folder = '/content/crop_images'\n",
        "\n",
        "    # 讀取預測框資料\n",
        "    bounding_boxes = read_bounding_boxes(bbox_file_path)\n",
        "\n",
        "    cropped_image_paths = []\n",
        "\n",
        "    # 檢查檔名對應並裁切圖片\n",
        "    for image_name in bounding_boxes.keys():\n",
        "        image_file_name = image_name + \".jpg\"  # 假設圖片副檔名是 .jpg，根據實際情況調整\n",
        "        image_path = os.path.join(image_folder, image_file_name)\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image {image_file_name} not found in {image_folder}\")\n",
        "        else:\n",
        "            print(f\"Image {image_file_name} found and verified\")\n",
        "\n",
        "            # 裁切圖片並保存\n",
        "            cropped_image_path = crop_image_with_bbox(image_path, bounding_boxes[image_name], cropped_image_folder)\n",
        "            if cropped_image_path:\n",
        "                cropped_image_paths.append(cropped_image_path)\n",
        "\n",
        "    # 列印裁切後的所有圖片路徑\n",
        "    print(\"Cropped image paths:\")\n",
        "    for path in cropped_image_paths:\n",
        "        print(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0tF56OTYVCD",
        "outputId": "54e47810-048c-4270-d4c9-d6e5c6389b4c"
      },
      "id": "v0tF56OTYVCD",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image FFAU2895947.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/FFAU2895947.jpg\n",
            "Image MAGU5605323.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/MAGU5605323.jpg\n",
            "Image SEKU5875349.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/SEKU5875349.jpg\n",
            "Image SEKU5877491.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/SEKU5877491.jpg\n",
            "Image SEKU6026686.jpg found and verified\n",
            "Bounding box coordinates are all zeros for image SEKU6026686.jpg, saving original image...\n",
            "Original image saved at /content/crop_images/SEKU6026686.jpg\n",
            "Image TCNU6246126.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TCNU6246126.jpg\n",
            "Image TLLU4080736.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TLLU4080736.jpg\n",
            "Image TRHU8927462.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TRHU8927462.jpg\n",
            "Image TSSU5017340.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5017340.jpg\n",
            "Image TSSU5029819.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5029819.jpg\n",
            "Image TSSU5042071.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5042071.jpg\n",
            "Image TSSU5061615.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5061615.jpg\n",
            "Image TSSU5099400.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5099400.jpg\n",
            "Image TSSU5142300.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5142300.jpg\n",
            "Image TSSU5160351.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5160351.jpg\n",
            "Image WHLU5591798.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHLU5591798.jpg\n",
            "Image WHLU5842825.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHLU5842825.jpg\n",
            "Image WHSU2483178.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2483178.jpg\n",
            "Image WHSU2615314.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2615314.jpg\n",
            "Image WHSU2864765.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2864765.jpg\n",
            "Image WHSU5295430.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5295430.jpg\n",
            "Image WHSU5368199.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5368199.jpg\n",
            "Image WHSU5563298.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5563298.jpg\n",
            "Image WHSU5610492.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5610492.jpg\n",
            "Image WHSU5628589.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5628589.jpg\n",
            "Image WHSU5744465.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5744465.jpg\n",
            "Image WHSU5991104.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5991104.jpg\n",
            "Image WHSU5998393.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5998393.jpg\n",
            "Image WHSU6010260.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6010260.jpg\n",
            "Image WHSU6040178.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6040178.jpg\n",
            "Image WHSU6052306.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6052306.jpg\n",
            "Image WHSU6167120.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6167120.jpg\n",
            "Image WHSU6557387.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6557387.jpg\n",
            "Image WHSU6651665.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6651665.jpg\n",
            "Image WHSU6856285.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6856285.jpg\n",
            "Cropped image paths:\n",
            "/content/crop_images/FFAU2895947.jpg\n",
            "/content/crop_images/MAGU5605323.jpg\n",
            "/content/crop_images/SEKU5875349.jpg\n",
            "/content/crop_images/SEKU5877491.jpg\n",
            "/content/crop_images/TCNU6246126.jpg\n",
            "/content/crop_images/TLLU4080736.jpg\n",
            "/content/crop_images/TRHU8927462.jpg\n",
            "/content/crop_images/TSSU5017340.jpg\n",
            "/content/crop_images/TSSU5029819.jpg\n",
            "/content/crop_images/TSSU5042071.jpg\n",
            "/content/crop_images/TSSU5061615.jpg\n",
            "/content/crop_images/TSSU5099400.jpg\n",
            "/content/crop_images/TSSU5142300.jpg\n",
            "/content/crop_images/TSSU5160351.jpg\n",
            "/content/crop_images/WHLU5591798.jpg\n",
            "/content/crop_images/WHLU5842825.jpg\n",
            "/content/crop_images/WHSU2483178.jpg\n",
            "/content/crop_images/WHSU2615314.jpg\n",
            "/content/crop_images/WHSU2864765.jpg\n",
            "/content/crop_images/WHSU5295430.jpg\n",
            "/content/crop_images/WHSU5368199.jpg\n",
            "/content/crop_images/WHSU5563298.jpg\n",
            "/content/crop_images/WHSU5610492.jpg\n",
            "/content/crop_images/WHSU5628589.jpg\n",
            "/content/crop_images/WHSU5744465.jpg\n",
            "/content/crop_images/WHSU5991104.jpg\n",
            "/content/crop_images/WHSU5998393.jpg\n",
            "/content/crop_images/WHSU6010260.jpg\n",
            "/content/crop_images/WHSU6040178.jpg\n",
            "/content/crop_images/WHSU6052306.jpg\n",
            "/content/crop_images/WHSU6167120.jpg\n",
            "/content/crop_images/WHSU6557387.jpg\n",
            "/content/crop_images/WHSU6651665.jpg\n",
            "/content/crop_images/WHSU6856285.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 使用大津法將圖片二值化\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def binarize_image(image_path, save_folder):\n",
        "    # 讀取圖片\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # 將圖片轉換為灰度模式\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 使用大津法計算閾值\n",
        "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # 反轉二值化圖片，將背景設置為白色，文字設置為黑色\n",
        "    inverted_image = cv2.bitwise_not(binary_image)\n",
        "\n",
        "    # 確保保存資料夾存在\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # 取得原始檔名\n",
        "    base_name = os.path.basename(image_path)\n",
        "\n",
        "    # 組合儲存路徑\n",
        "    adjusted_image_path = os.path.join(save_folder, base_name)\n",
        "\n",
        "    # 儲存調整後的圖片\n",
        "    cv2.imwrite(adjusted_image_path, inverted_image)\n",
        "    print(f\"Adjusted image saved at {adjusted_image_path}\")\n",
        "\n",
        "    return adjusted_image_path\n",
        "\n",
        "# 指定裁切後圖片的資料夾路徑\n",
        "cropped_image_folder = '/content/crop_images'\n",
        "\n",
        "# 指定調整後圖片的保存資料夾\n",
        "adjusted_image_folder = '/content/adjust_images'\n",
        "\n",
        "# 檢查裁切後的所有圖片\n",
        "for root, dirs, files in os.walk(cropped_image_folder):\n",
        "    for file in files:\n",
        "        # 裁切後圖片的完整路徑\n",
        "        cropped_image_path = os.path.join(root, file)\n",
        "\n",
        "        # 進行大津法計算閾值並反轉二值化處理並保存\n",
        "        adjusted_image_path = binarize_image(cropped_image_path, adjusted_image_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXZpE8aVc3xr",
        "outputId": "8b835623-cac3-494f-b2e1-ff289cf4fd0b"
      },
      "id": "FXZpE8aVc3xr",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted image saved at /content/adjust_images/WHSU5368199.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5160351.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5142300.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6040178.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6010260.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6052306.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5998393.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6557387.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2615314.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6651665.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5029819.jpg\n",
            "Adjusted image saved at /content/adjust_images/TLLU4080736.jpg\n",
            "Adjusted image saved at /content/adjust_images/FFAU2895947.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5017340.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5099400.jpg\n",
            "Adjusted image saved at /content/adjust_images/MAGU5605323.jpg\n",
            "Adjusted image saved at /content/adjust_images/TRHU8927462.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5563298.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6167120.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHLU5842825.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5295430.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHLU5591798.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5991104.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2483178.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5628589.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5744465.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU6026686.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU5877491.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6856285.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5042071.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2864765.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5061615.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU5875349.jpg\n",
            "Adjusted image saved at /content/adjust_images/TCNU6246126.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5610492.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# 圖片路徑\n",
        "image_path = \"/content/adjust_images\"\n",
        "\n",
        "# 取得路徑下所有圖片檔案名稱\n",
        "image_files = [f for f in os.listdir(image_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# 文字辨識函式\n",
        "def image_to_text(image_file):\n",
        "    try:\n",
        "        # 使用Pillow套件打開圖片\n",
        "        with Image.open(os.path.join(image_path, image_file)) as img:\n",
        "            # 將圖片轉換成文字\n",
        "            text = pytesseract.image_to_string(img, lang='eng')  # 設定辨識語言，這裡是英文\n",
        "\n",
        "            # 使用正則表達式過濾出英文字母和數字\n",
        "            filtered_text = re.sub(r'[^A-Za-z0-9]', '', text)\n",
        "\n",
        "            # 確保文字總長度為15，沒有的話補足空格\n",
        "            if len(filtered_text) < 15:\n",
        "                filtered_text = filtered_text.ljust(15, ' ')\n",
        "            elif len(filtered_text) > 15:\n",
        "                filtered_text = filtered_text[:15]\n",
        "\n",
        "            return filtered_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "# 計算準確率\n",
        "correct_count = 0\n",
        "total_count = len(image_files)\n",
        "\n",
        "for image_file in image_files:\n",
        "    text = image_to_text(image_file)\n",
        "    if text is not None:\n",
        "        filename_without_extension = os.path.splitext(image_file)[0]\n",
        "        # 檢查前11個字是否與檔名相同\n",
        "        if text[:11].lower() == filename_without_extension.lower():\n",
        "            correct_count += 1\n",
        "        print(f\"Filtered text result for {image_file}: {text}\")\n",
        "\n",
        "accuracy = correct_count / total_count if total_count > 0 else 0\n",
        "print(f\"Accuracy: {accuracy:.2%} (Correct: {correct_count}, Total: {total_count})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdmqlV6PrMGa",
        "outputId": "0435fa81-4646-4f6d-8d08-4f54c1fd2fce"
      },
      "id": "JdmqlV6PrMGa",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered text result for WHSU5368199.jpg: WHSU5368199AG  \n",
            "Filtered text result for TSSU5160351.jpg: TSSU516035Ji745\n",
            "Filtered text result for TSSU5142300.jpg: TSSU           \n",
            "Filtered text result for WHSU6040178.jpg: WHSU60401714561\n",
            "Filtered text result for WHSU6010260.jpg: WHSU601026A561 \n",
            "Filtered text result for WHSU6052306.jpg: WHSU60529456i  \n",
            "Filtered text result for WHSU5998393.jpg: WHSU59983934561\n",
            "Filtered text result for WHSU6557387.jpg: WHSU85573874661\n",
            "Filtered text result for WHSU2615314.jpg: WHSU26153142261\n",
            "Filtered text result for WHSU6651665.jpg: 6651664561     \n",
            "Filtered text result for TSSU5029819.jpg: TSSU5029814561 \n",
            "Filtered text result for TLLU4080736.jpg: TLLU408073456  \n",
            "Filtered text result for FFAU2895947.jpg: FAU2895947py456\n",
            "Filtered text result for TSSU5017340.jpg: iSSU501734561  \n",
            "Filtered text result for TSSU5099400.jpg: TSSU5099404561 \n",
            "Filtered text result for MAGU5605323.jpg:                \n",
            "Filtered text result for TRHU8927462.jpg: TRHU89274624561\n",
            "Filtered text result for WHSU5563298.jpg: NHSU5563294561 \n",
            "Filtered text result for WHSU6167120.jpg: WHSU6167124561 \n",
            "Filtered text result for WHLU5842825.jpg: WHLU5842824561 \n",
            "Filtered text result for WHSU5295430.jpg: WHSU529543ASGI \n",
            "Filtered text result for WHLU5591798.jpg: WHLUS5gfASG    \n",
            "Filtered text result for WHSU5991104.jpg: WHSU45991104456\n",
            "Filtered text result for WHSU2483178.jpg: WRSU2483178261 \n",
            "Filtered text result for WHSU5628589.jpg: WHSU5628889j45G\n",
            "Filtered text result for WHSU5744465.jpg: WHSU57444654561\n",
            "Filtered text result for SEKU6026686.jpg:                \n",
            "Filtered text result for SEKU5877491.jpg: SEKU58774561   \n",
            "Filtered text result for WHSU6856285.jpg: WHSU           \n",
            "Filtered text result for TSSU5042071.jpg: TSSU5042074561 \n",
            "Filtered text result for WHSU2864765.jpg: WHSU28647bet   \n",
            "Filtered text result for TSSU5061615.jpg: TSSU50616154561\n",
            "Filtered text result for SEKU5875349.jpg: SEKU5875344561 \n",
            "Filtered text result for TCNU6246126.jpg: TCNU6246124561 \n",
            "Filtered text result for WHSU5610492.jpg: WHSU56104924561\n",
            "Accuracy: 20.00% (Correct: 7, Total: 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**下載資料夾**"
      ],
      "metadata": {
        "id": "HHaV1XlVke6Q"
      },
      "id": "HHaV1XlVke6Q"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#壓縮成資料夾下載，前面是檔名.zip，後面是要被壓縮的東西\n",
        "!zip -r /content/crop_images.zip /content/crop_images\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/crop_images.zip\")\n",
        "'''"
      ],
      "metadata": {
        "id": "pttsIpiJtFwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1027072d-8794-42c2-ee3c-d7ba57bc276c"
      },
      "id": "pttsIpiJtFwc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#壓縮成資料夾下載，前面是檔名.zip，後面是要被壓縮的東西\\n!zip -r /content/crop_images.zip /content/crop_images\\n\\nfrom google.colab import files\\nfiles.download(\"/content/crop_images.zip\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 刪除資料夾\n",
        "import shutil\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    try:\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder {folder_path} and its contents deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Folder {folder_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# 指定要刪除的資料夾路徑\n",
        "folder_to_delete = '/content/adjust_images'\n",
        "\n",
        "# 呼叫函式來刪除資料夾\n",
        "delete_folder(folder_to_delete)\n",
        "'''"
      ],
      "metadata": {
        "id": "8Kl1DD908AMW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f9ac8879-46ef-4026-f290-fce66829ccd1"
      },
      "id": "8Kl1DD908AMW",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 刪除資料夾\\nimport shutil\\n\\ndef delete_folder(folder_path):\\n    try:\\n        shutil.rmtree(folder_path)\\n        print(f\"Folder {folder_path} and its contents deleted successfully.\")\\n    except FileNotFoundError:\\n        print(f\"Folder {folder_path} not found.\")\\n    except Exception as e:\\n        print(f\"An error occurred: {e}\")\\n\\n# 指定要刪除的資料夾路徑\\nfolder_to_delete = \\'/content/adjust_images\\'\\n\\n# 呼叫函式來刪除資料夾\\ndelete_folder(folder_to_delete)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}