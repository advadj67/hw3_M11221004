{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advadj67/hw3_M11221004/blob/main/HW03_YoloV8_Colab_%E6%96%B0%E6%B8%AC%E8%A9%A6%E9%9B%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b3ebe4f7",
      "metadata": {
        "id": "b3ebe4f7",
        "outputId": "0bb78218-644b-4ab4-a67f-7b5bf56224ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.19-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.19\n",
            "Cloning into 'hw3_M11221004'...\n",
            "remote: Enumerating objects: 13686, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 13686 (delta 48), reused 80 (delta 39), pack-reused 13594\u001b[K\n",
            "Receiving objects: 100% (13686/13686), 1.69 GiB | 43.66 MiB/s, done.\n",
            "Resolving deltas: 100% (3453/3453), done.\n",
            "Updating files: 100% (13714/13714), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!git clone https://github.com/advadj67/hw3_M11221004.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d283b530",
      "metadata": {
        "id": "d283b530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0d06a8dc-6b3a-45d7-b7e2-4089adbb3182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#å°‡.xmlè½‰æˆYoloæ‰€éœ€ .txtæª”æ¡ˆ\\nimport os\\nimport xml.etree.ElementTree as ET\\n\\ndef convert_coordinates(size, box):\\n    # è½‰æ›åæ¨™\\n    dw = 1.0 / size[0]\\n    dh = 1.0 / size[1]\\n    x = (box[0] + box[1]) / 2.0\\n    y = (box[2] + box[3]) / 2.0\\n    w = box[1] - box[0]\\n    h = box[3] - box[2]\\n    x = x * dw\\n    w = w * dw\\n    y = y * dh\\n    h = h * dh\\n    return (x, y, w, h)\\n\\ndef convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\\n    # è§£æXMLä¸¦è½‰æ›ç‚ºYOLOæ ¼å¼\\n    tree = ET.parse(xml_path)\\n    root = tree.getroot()\\n\\n    size = root.find(\\'size\\')\\n    w = int(size.find(\\'width\\').text)\\n    h = int(size.find(\\'height\\').text)\\n\\n    for output_folder in output_folders:\\n        folder_name = os.path.basename(output_folder)\\n        output_dir = os.path.join(output_root, folder_name)\\n        if not os.path.exists(output_dir):\\n            os.makedirs(output_dir)\\n\\n        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + \\'.txt\\')\\n        with open(output_file_path, \\'w\\') as f:\\n            for obj in root.findall(\\'object\\'):\\n                cls = obj.find(\\'name\\').text\\n                if cls not in class_dict:\\n                    continue\\n                cls_id = class_dict[cls]\\n                xml_box = obj.find(\\'bndbox\\')\\n                box = (float(xml_box.find(\\'xmin\\').text), float(xml_box.find(\\'xmax\\').text),\\n                       float(xml_box.find(\\'ymin\\').text), float(xml_box.find(\\'ymax\\').text))\\n                bb = convert_coordinates((w,h), box)\\n                f.write(f\"{cls_id} {\\' \\'.join([str(a) for a in bb])}\\n\")\\n\\n# è³‡æ–™å¤¾åˆ—è¡¨\\nfolders = [\"è¨“ç·´é›†_xml\", \"é©—è­‰é›†_xml\", \"æ¸¬è©¦é›†_xml\"]\\no_folders = [\"train\", \"val\", \"test\"]\\n\\n# åˆ†é¡å­—å…¸ï¼Œå°‡é¡åˆ¥åæ˜ å°„åˆ°æ•´æ•¸æ¨™ç±¤\\nclass_dict = {\"container\": 0}\\n\\n# è¼¸å‡ºæ ¹è³‡æ–™å¤¾è·¯å¾‘\\noutput_root = \"E:\\\\Downloads\\\\è²¨æ«ƒè³‡æ–™é›†\\\\labels\"\\n\\n# å¦‚æœè¼¸å‡ºæ ¹è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå‰‡å‰µå»º\\nif not os.path.exists(output_root):\\n    os.makedirs(output_root)\\n\\n# è¿´åœˆè™•ç†æ¯å€‹è³‡æ–™å¤¾\\nfor folder, o_folder in zip(folders, o_folders):\\n    folder_path = os.path.join(\"E:\\\\Downloads\\\\è²¨æ«ƒè³‡æ–™é›†\", folder)  # è³‡æ–™å¤¾è·¯å¾‘\\n    xml_files = [f for f in os.listdir(folder_path) if f.endswith(\\'.xml\\')]  # ç²å–æ‰€æœ‰XMLæª”æ¡ˆ\\n    output_folders = [os.path.join(output_root, o_folder)]  # è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘\\n    for xml_file in xml_files:\\n        xml_path = os.path.join(folder_path, xml_file)  # XMLæª”æ¡ˆè·¯å¾‘\\n        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\\n\\nprint(\"labelsè½‰æ›å®Œæˆ!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "'''\n",
        "#å°‡.xmlè½‰æˆYoloæ‰€éœ€ .txtæª”æ¡ˆ\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    # è½‰æ›åæ¨™\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    x = (box[0] + box[1]) / 2.0\n",
        "    y = (box[2] + box[3]) / 2.0\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "def convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders):\n",
        "    # è§£æXMLä¸¦è½‰æ›ç‚ºYOLOæ ¼å¼\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for output_folder in output_folders:\n",
        "        folder_name = os.path.basename(output_folder)\n",
        "        output_dir = os.path.join(output_root, folder_name)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        output_file_path = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + '.txt')\n",
        "        with open(output_file_path, 'w') as f:\n",
        "            for obj in root.findall('object'):\n",
        "                cls = obj.find('name').text\n",
        "                if cls not in class_dict:\n",
        "                    continue\n",
        "                cls_id = class_dict[cls]\n",
        "                xml_box = obj.find('bndbox')\n",
        "                box = (float(xml_box.find('xmin').text), float(xml_box.find('xmax').text),\n",
        "                       float(xml_box.find('ymin').text), float(xml_box.find('ymax').text))\n",
        "                bb = convert_coordinates((w,h), box)\n",
        "                f.write(f\"{cls_id} {' '.join([str(a) for a in bb])}\\n\")\n",
        "\n",
        "# è³‡æ–™å¤¾åˆ—è¡¨\n",
        "folders = [\"è¨“ç·´é›†_xml\", \"é©—è­‰é›†_xml\", \"æ¸¬è©¦é›†_xml\"]\n",
        "o_folders = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# åˆ†é¡å­—å…¸ï¼Œå°‡é¡åˆ¥åæ˜ å°„åˆ°æ•´æ•¸æ¨™ç±¤\n",
        "class_dict = {\"container\": 0}\n",
        "\n",
        "# è¼¸å‡ºæ ¹è³‡æ–™å¤¾è·¯å¾‘\n",
        "output_root = \"E:\\Downloads\\è²¨æ«ƒè³‡æ–™é›†\\labels\"\n",
        "\n",
        "# å¦‚æœè¼¸å‡ºæ ¹è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå‰‡å‰µå»º\n",
        "if not os.path.exists(output_root):\n",
        "    os.makedirs(output_root)\n",
        "\n",
        "# è¿´åœˆè™•ç†æ¯å€‹è³‡æ–™å¤¾\n",
        "for folder, o_folder in zip(folders, o_folders):\n",
        "    folder_path = os.path.join(\"E:\\Downloads\\è²¨æ«ƒè³‡æ–™é›†\", folder)  # è³‡æ–™å¤¾è·¯å¾‘\n",
        "    xml_files = [f for f in os.listdir(folder_path) if f.endswith('.xml')]  # ç²å–æ‰€æœ‰XMLæª”æ¡ˆ\n",
        "    output_folders = [os.path.join(output_root, o_folder)]  # è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘\n",
        "    for xml_file in xml_files:\n",
        "        xml_path = os.path.join(folder_path, xml_file)  # XMLæª”æ¡ˆè·¯å¾‘\n",
        "        convert_xml_to_yolo(xml_path, output_root, class_dict, output_folders)\n",
        "\n",
        "print(\"labelsè½‰æ›å®Œæˆ!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "91dad266",
      "metadata": {
        "id": "91dad266",
        "outputId": "bd68aa82-cd93-4215-dcc7-8fdae5eedb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom PIL import Image\\n\\n# è³‡æ–™å¤¾åˆ—è¡¨\\nfolder_path = \"E:/Downloads/è²¨æ«ƒè³‡æ–™é›†/\"\\nfolders = [folder_path + \"è¨“ç·´é›†\", folder_path + \"é©—è­‰é›†\", folder_path + \"æ¸¬è©¦é›†\"]\\n\\noutput_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\\n\\n\\n# å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾\\nfor output_folder in output_folders:\\n    os.makedirs(output_folder, exist_ok=True)\\n\\n# è½‰æ›å‡½æ•¸\\ndef resize_images(folder, output_folder):\\n    # ç²å–è³‡æ–™å¤¾ä¸­æ‰€æœ‰åœ–ç‰‡çš„æª”æ¡ˆåç¨±\\n    files = os.listdir(folder)\\n\\n    # è¿´åœˆè™•ç†æ¯å¼µåœ–ç‰‡\\n    for file in files:\\n        # æª”æ¡ˆè·¯å¾‘\\n        file_path = os.path.join(folder, file)\\n\\n        # å¦‚æœæ˜¯æª”æ¡ˆ\\n        if os.path.isfile(file_path):\\n            # æ‰“é–‹åœ–ç‰‡\\n            img = Image.open(file_path)\\n\\n            # é‡æ–°èª¿æ•´å¤§å°\\n            resized_img = img.resize((416, 416))\\n\\n            # å¦å­˜æ–°åœ–ç‰‡\\n            resized_img.save(os.path.join(output_folder, file))\\n\\n# å°æ¯å€‹è³‡æ–™å¤¾å’Œå°æ‡‰çš„è¼¸å‡ºè³‡æ–™å¤¾èª¿ç”¨resize_imageså‡½æ•¸\\nfor folder, output_folder in zip(folders, output_folders):\\n    resize_images(folder, output_folder)\\n\\nprint(\"imagesè½‰æ›å®Œæˆ!\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "from PIL import Image\n",
        "\n",
        "# è³‡æ–™å¤¾åˆ—è¡¨\n",
        "folder_path = \"E:/Downloads/è²¨æ«ƒè³‡æ–™é›†/\"\n",
        "folders = [folder_path + \"è¨“ç·´é›†\", folder_path + \"é©—è­‰é›†\", folder_path + \"æ¸¬è©¦é›†\"]\n",
        "\n",
        "output_folders = [folder_path + \"images/train\", folder_path + \"images/val\", folder_path + \"images/test\"]\n",
        "\n",
        "\n",
        "# å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾\n",
        "for output_folder in output_folders:\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# è½‰æ›å‡½æ•¸\n",
        "def resize_images(folder, output_folder):\n",
        "    # ç²å–è³‡æ–™å¤¾ä¸­æ‰€æœ‰åœ–ç‰‡çš„æª”æ¡ˆåç¨±\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    # è¿´åœˆè™•ç†æ¯å¼µåœ–ç‰‡\n",
        "    for file in files:\n",
        "        # æª”æ¡ˆè·¯å¾‘\n",
        "        file_path = os.path.join(folder, file)\n",
        "\n",
        "        # å¦‚æœæ˜¯æª”æ¡ˆ\n",
        "        if os.path.isfile(file_path):\n",
        "            # æ‰“é–‹åœ–ç‰‡\n",
        "            img = Image.open(file_path)\n",
        "\n",
        "            # é‡æ–°èª¿æ•´å¤§å°\n",
        "            resized_img = img.resize((416, 416))\n",
        "\n",
        "            # å¦å­˜æ–°åœ–ç‰‡\n",
        "            resized_img.save(os.path.join(output_folder, file))\n",
        "\n",
        "# å°æ¯å€‹è³‡æ–™å¤¾å’Œå°æ‡‰çš„è¼¸å‡ºè³‡æ–™å¤¾èª¿ç”¨resize_imageså‡½æ•¸\n",
        "for folder, output_folder in zip(folders, output_folders):\n",
        "    resize_images(folder, output_folder)\n",
        "\n",
        "print(\"imagesè½‰æ›å®Œæˆ!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/data.yaml', epochs=20, batch=8, imgsz=(416,416))\n",
        "\n",
        "model.val()  # It'll automatically evaluate the data you trained."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBYGJ6DUR9bK",
        "outputId": "6da41464-0ad3-4f16-f9de-62b6bfa377da",
        "collapsed": true
      },
      "id": "jBYGJ6DUR9bK",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 81.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.19 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=(416, 416), save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 20.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "WARNING âš ï¸ updating to 'imgsz=416'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/train... 2125 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [00:01<00:00, 1848.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/val... 536 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 536/536 [00:00<00:00, 1062.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/266 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       1/20     0.715G        1.2      1.783      1.038          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:41<00:00,  6.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.997      0.993      0.995      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20     0.652G     0.8641     0.7806     0.9145          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:39<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.978      0.983      0.994      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      0.65G     0.8141     0.6101      0.902          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:38<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1      0.998      0.995      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20     0.646G     0.8006      0.542     0.8998          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:37<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1      0.998      0.995      0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20     0.646G     0.7475     0.4866     0.8849          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:38<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20     0.654G     0.7141     0.4649     0.8816          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:37<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536      0.999          1      0.995      0.852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20     0.665G     0.7058      0.436     0.8768          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:38<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20     0.663G      0.706     0.4249     0.8799          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:37<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20     0.665G     0.6834      0.411     0.8713          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:38<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995       0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20     0.642G     0.6606     0.3944     0.8635          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:38<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20     0.663G     0.6402      0.364     0.8623          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:37<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20     0.665G     0.6146     0.3503     0.8566          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:37<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20     0.663G     0.6117     0.3402     0.8626          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      0.64G     0.5852     0.3305     0.8528          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20     0.663G     0.5858     0.3217     0.8515          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20     0.665G     0.5679     0.3061     0.8403          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20     0.663G     0.5559     0.2982      0.847          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:04<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20     0.642G     0.5363     0.2894     0.8339          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20     0.663G     0.5268     0.2818     0.8359          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20     0.665G     0.5188     0.2714     0.8337          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:36<00:00,  7.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.240 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.19 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:04<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.874\n",
            "Speed: 0.1ms preprocess, 2.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics YOLOv8.2.19 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/val.cache... 536 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 536/536 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        536        536          1          1      0.995      0.872\n",
            "Speed: 0.2ms preprocess, 4.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79dc34ff1120>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.89782,     0.89782,     0.95106,     0.96286,     0.97638,     0.98421,     0.98509,     0.98666,     0.98916,     0.98958,     0.99017,     0.99107,     0.99187,     0.99245,     0.99273,     0.99291,     0.99309,     0.99327,     0.99345,     0.99367,     0.99389,     0.99412,     0.99435,\n",
              "            0.99449,     0.99458,     0.99467,     0.99476,     0.99485,     0.99494,     0.99503,     0.99512,     0.99521,      0.9953,     0.99576,      0.9964,     0.99659,     0.99679,     0.99698,     0.99718,     0.99722,     0.99723,     0.99724,     0.99724,     0.99725,     0.99726,     0.99727,\n",
              "            0.99728,     0.99729,      0.9973,     0.99731,     0.99732,     0.99733,     0.99734,     0.99735,     0.99736,     0.99737,     0.99737,     0.99738,     0.99739,      0.9974,     0.99741,     0.99742,     0.99743,     0.99744,     0.99745,     0.99746,     0.99747,     0.99748,     0.99749,\n",
              "            0.99749,      0.9975,     0.99751,     0.99752,     0.99753,     0.99754,     0.99755,     0.99756,     0.99757,     0.99758,     0.99759,      0.9976,     0.99761,     0.99761,     0.99762,     0.99763,     0.99764,     0.99765,     0.99766,     0.99767,     0.99768,     0.99769,      0.9977,\n",
              "            0.99771,     0.99772,     0.99773,     0.99773,     0.99774,     0.99775,     0.99776,     0.99777,     0.99778,     0.99779,      0.9978,     0.99781,     0.99782,     0.99783,     0.99784,     0.99785,     0.99785,     0.99786,     0.99787,     0.99788,     0.99789,      0.9979,     0.99791,\n",
              "            0.99792,     0.99793,     0.99794,     0.99795,     0.99796,     0.99797,     0.99797,     0.99798,     0.99799,       0.998,     0.99801,     0.99802,     0.99803,     0.99804,     0.99805,     0.99806,     0.99807,     0.99808,     0.99809,     0.99809,      0.9981,     0.99811,     0.99812,\n",
              "            0.99813,     0.99814,     0.99814,     0.99815,     0.99815,     0.99815,     0.99816,     0.99816,     0.99816,     0.99817,     0.99817,     0.99817,     0.99818,     0.99818,     0.99819,     0.99819,     0.99819,      0.9982,      0.9982,      0.9982,     0.99821,     0.99821,     0.99821,\n",
              "            0.99822,     0.99822,     0.99822,     0.99823,     0.99823,     0.99823,     0.99824,     0.99824,     0.99825,     0.99825,     0.99825,     0.99826,     0.99826,     0.99826,     0.99827,     0.99827,     0.99827,     0.99828,     0.99828,     0.99828,     0.99829,     0.99829,     0.99829,\n",
              "             0.9983,      0.9983,     0.99831,     0.99831,     0.99831,     0.99832,     0.99832,     0.99832,     0.99833,     0.99833,     0.99833,     0.99834,     0.99834,     0.99834,     0.99835,     0.99835,     0.99836,     0.99836,     0.99836,     0.99837,     0.99837,     0.99837,     0.99838,\n",
              "            0.99838,     0.99838,     0.99839,     0.99839,     0.99839,      0.9984,      0.9984,      0.9984,     0.99841,     0.99841,     0.99842,     0.99842,     0.99842,     0.99843,     0.99843,     0.99843,     0.99844,     0.99844,     0.99844,     0.99845,     0.99845,     0.99845,     0.99846,\n",
              "            0.99846,     0.99847,     0.99847,     0.99847,     0.99848,     0.99848,     0.99848,     0.99849,     0.99849,     0.99849,      0.9985,      0.9985,      0.9985,     0.99851,     0.99851,     0.99851,     0.99852,     0.99852,     0.99853,     0.99853,     0.99853,     0.99854,     0.99854,\n",
              "            0.99854,     0.99855,     0.99855,     0.99855,     0.99856,     0.99856,     0.99856,     0.99857,     0.99857,     0.99858,     0.99858,     0.99858,     0.99859,     0.99859,     0.99859,      0.9986,      0.9986,      0.9986,     0.99861,     0.99861,     0.99861,     0.99862,     0.99862,\n",
              "            0.99862,     0.99863,     0.99863,     0.99864,     0.99864,     0.99864,     0.99865,     0.99865,     0.99865,     0.99866,     0.99866,     0.99866,     0.99867,     0.99867,     0.99867,     0.99868,     0.99868,     0.99868,     0.99869,     0.99869,      0.9987,      0.9987,      0.9987,\n",
              "            0.99871,     0.99871,     0.99871,     0.99872,     0.99872,     0.99872,     0.99873,     0.99873,     0.99873,     0.99874,     0.99874,     0.99875,     0.99875,     0.99875,     0.99876,     0.99876,     0.99876,     0.99877,     0.99877,     0.99877,     0.99878,     0.99878,     0.99878,\n",
              "            0.99879,     0.99879,     0.99879,      0.9988,      0.9988,     0.99881,     0.99881,     0.99881,     0.99882,     0.99882,     0.99882,     0.99883,     0.99883,     0.99883,     0.99884,     0.99884,     0.99884,     0.99885,     0.99885,     0.99886,     0.99886,     0.99886,     0.99887,\n",
              "            0.99887,     0.99887,     0.99888,     0.99888,     0.99888,     0.99889,     0.99889,     0.99889,      0.9989,      0.9989,      0.9989,     0.99891,     0.99891,     0.99892,     0.99892,     0.99892,     0.99893,     0.99893,     0.99893,     0.99894,     0.99894,     0.99894,     0.99895,\n",
              "            0.99895,     0.99895,     0.99896,     0.99896,     0.99896,     0.99897,     0.99897,     0.99898,     0.99898,     0.99898,     0.99899,     0.99899,     0.99899,       0.999,       0.999,       0.999,     0.99901,     0.99901,     0.99901,     0.99902,     0.99902,     0.99903,     0.99903,\n",
              "            0.99903,     0.99904,     0.99904,     0.99904,     0.99905,     0.99905,     0.99905,     0.99906,     0.99906,     0.99906,     0.99907,     0.99907,     0.99908,     0.99908,     0.99908,     0.99909,     0.99909,      0.9991,      0.9991,      0.9991,     0.99911,     0.99911,     0.99912,\n",
              "            0.99912,     0.99912,     0.99913,     0.99913,     0.99913,     0.99914,     0.99914,     0.99915,     0.99915,     0.99915,     0.99916,     0.99916,     0.99917,     0.99917,     0.99917,     0.99918,     0.99918,     0.99919,     0.99919,     0.99919,      0.9992,      0.9992,     0.99921,\n",
              "            0.99921,     0.99921,     0.99922,     0.99922,     0.99923,     0.99923,     0.99923,     0.99924,     0.99924,     0.99925,     0.99925,     0.99925,     0.99926,     0.99926,     0.99927,     0.99927,     0.99927,     0.99928,     0.99928,     0.99929,     0.99929,     0.99929,      0.9993,\n",
              "             0.9993,     0.99931,     0.99931,     0.99931,     0.99932,     0.99932,     0.99932,     0.99933,     0.99933,     0.99934,     0.99934,     0.99934,     0.99935,     0.99935,     0.99936,     0.99936,     0.99936,     0.99937,     0.99937,     0.99938,     0.99938,     0.99938,     0.99939,\n",
              "            0.99939,      0.9994,      0.9994,      0.9994,     0.99941,     0.99941,     0.99942,     0.99942,     0.99942,     0.99943,     0.99943,     0.99944,     0.99944,     0.99944,     0.99945,     0.99945,     0.99946,     0.99946,     0.99946,     0.99947,     0.99947,     0.99948,     0.99948,\n",
              "            0.99948,     0.99949,     0.99949,      0.9995,      0.9995,      0.9995,     0.99951,     0.99951,     0.99952,     0.99952,     0.99952,     0.99953,     0.99953,     0.99953,     0.99954,     0.99954,     0.99955,     0.99955,     0.99955,     0.99956,     0.99956,     0.99957,     0.99957,\n",
              "            0.99957,     0.99958,     0.99958,     0.99959,     0.99959,     0.99959,      0.9996,      0.9996,     0.99961,     0.99961,     0.99961,     0.99962,     0.99962,     0.99963,     0.99963,     0.99963,     0.99964,     0.99964,     0.99965,     0.99965,     0.99965,     0.99966,     0.99966,\n",
              "            0.99967,     0.99967,     0.99967,     0.99968,     0.99968,     0.99969,     0.99969,     0.99969,      0.9997,      0.9997,      0.9997,     0.99971,     0.99971,     0.99972,     0.99972,     0.99972,     0.99973,     0.99973,     0.99974,     0.99974,     0.99974,     0.99975,     0.99975,\n",
              "            0.99976,     0.99976,     0.99976,     0.99977,     0.99977,     0.99978,     0.99978,     0.99978,     0.99979,     0.99979,      0.9998,      0.9998,      0.9998,     0.99981,     0.99981,     0.99982,     0.99982,     0.99982,     0.99983,     0.99983,     0.99984,     0.99984,     0.99984,\n",
              "            0.99985,     0.99985,     0.99986,     0.99986,     0.99986,     0.99987,     0.99987,     0.99988,     0.99988,     0.99988,     0.99989,     0.99989,     0.99989,      0.9999,      0.9999,     0.99991,     0.99991,     0.99991,     0.99992,     0.99992,     0.99993,     0.99993,     0.99993,\n",
              "            0.99994,     0.99994,     0.99995,     0.99995,     0.99995,     0.99996,     0.99996,     0.99997,     0.99997,     0.99997,     0.99998,     0.99998,     0.99999,     0.99999,     0.99999,           1,     0.99997,     0.99989,     0.99982,     0.99975,     0.99967,      0.9996,     0.99953,\n",
              "            0.99945,     0.99938,     0.99931,     0.99923,     0.99916,     0.99908,     0.99904,       0.999,     0.99897,     0.99893,      0.9989,     0.99886,     0.99883,     0.99879,     0.99876,     0.99872,     0.99869,     0.99865,     0.99862,     0.99858,     0.99855,     0.99851,     0.99848,\n",
              "            0.99844,     0.99841,     0.99837,     0.99834,      0.9983,     0.99827,     0.99823,      0.9982,     0.99816,     0.99813,     0.99811,      0.9981,     0.99808,     0.99807,     0.99805,     0.99803,     0.99802,       0.998,     0.99799,     0.99797,     0.99795,     0.99794,     0.99792,\n",
              "            0.99791,     0.99789,     0.99787,     0.99786,     0.99784,     0.99783,     0.99781,     0.99779,     0.99778,     0.99776,     0.99775,     0.99773,     0.99771,      0.9977,     0.99768,     0.99767,     0.99765,     0.99763,     0.99762,      0.9976,     0.99759,     0.99757,     0.99755,\n",
              "            0.99754,     0.99752,     0.99751,     0.99749,     0.99747,     0.99746,     0.99744,     0.99743,     0.99741,     0.99739,     0.99738,     0.99736,     0.99735,     0.99733,     0.99731,      0.9973,     0.99728,     0.99727,     0.99725,     0.99723,     0.99722,      0.9972,     0.99718,\n",
              "            0.99715,     0.99711,     0.99708,     0.99705,     0.99702,     0.99698,     0.99695,     0.99692,     0.99689,     0.99685,     0.99682,     0.99679,     0.99676,     0.99672,     0.99669,     0.99666,     0.99662,     0.99659,     0.99656,     0.99653,     0.99649,     0.99646,     0.99643,\n",
              "             0.9964,     0.99636,     0.99633,      0.9963,     0.99627,     0.99623,     0.99619,     0.99615,     0.99611,     0.99607,     0.99603,       0.996,     0.99596,     0.99592,     0.99588,     0.99584,      0.9958,     0.99576,     0.99572,     0.99569,     0.99565,     0.99561,     0.99557,\n",
              "            0.99553,     0.99549,     0.99545,     0.99541,     0.99538,     0.99534,     0.99493,     0.99333,     0.99308,     0.99283,     0.99258,     0.99244,     0.99237,     0.99231,     0.99224,     0.99217,     0.99211,     0.99204,     0.99197,     0.99191,     0.99184,     0.99177,      0.9917,\n",
              "            0.99164,     0.99157,     0.99043,     0.99009,     0.98976,      0.9896,     0.98955,     0.98949,     0.98944,     0.98938,     0.98933,     0.98928,     0.98922,     0.98917,     0.98912,     0.98906,     0.98901,     0.98896,      0.9889,     0.98885,      0.9888,     0.98874,     0.98869,\n",
              "            0.98765,     0.98757,     0.98748,      0.9874,     0.98731,     0.98722,     0.98714,     0.98705,     0.98696,     0.98688,     0.98679,     0.98571,     0.98537,     0.98502,     0.98362,     0.98179,     0.98101,     0.97972,      0.9794,     0.97909,      0.9774,     0.97616,     0.97479,\n",
              "            0.97294,     0.97224,     0.97151,     0.96848,     0.96747,      0.9649,     0.96253,     0.95754,     0.95148,     0.94761,      0.9434,     0.93917,     0.93279,      0.9295,     0.92607,     0.91796,     0.91176,      0.9048,     0.90153,     0.89214,     0.88458,     0.87829,     0.86904,\n",
              "            0.86611,     0.85742,     0.85112,      0.8449,     0.83122,     0.81574,     0.80707,     0.79845,      0.7697,     0.75013,     0.73635,     0.72391,      0.6985,     0.68512,     0.65611,      0.6285,     0.59479,     0.55341,     0.51767,     0.47652,     0.45164,     0.41019,     0.38225,\n",
              "            0.34789,     0.31323,       0.296,     0.25602,     0.23421,     0.21426,     0.17767,     0.15024,     0.12896,     0.11851,     0.10827,    0.090737,    0.081332,     0.07359,    0.062732,     0.05346,    0.042292,    0.039769,    0.038449,    0.037128,    0.034011,    0.031002,     0.02761,\n",
              "            0.02229,    0.018979,    0.011606,   0.0073925,   0.0069215,   0.0064502,   0.0059787,    0.005507,   0.0050351,   0.0045629,   0.0040906,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.81459,     0.81459,     0.90668,     0.92838,     0.95385,      0.9689,     0.97061,     0.97366,     0.97855,     0.97938,     0.98054,     0.98229,     0.98388,     0.98502,     0.98557,     0.98592,     0.98628,     0.98664,     0.98699,     0.98741,     0.98786,     0.98831,     0.98876,\n",
              "            0.98904,     0.98922,      0.9894,     0.98957,     0.98975,     0.98993,     0.99011,     0.99028,     0.99046,     0.99064,     0.99155,     0.99282,     0.99321,      0.9936,     0.99399,     0.99438,     0.99445,     0.99447,     0.99449,      0.9945,     0.99452,     0.99454,     0.99456,\n",
              "            0.99458,      0.9946,     0.99462,     0.99463,     0.99465,     0.99467,     0.99469,     0.99471,     0.99473,     0.99474,     0.99476,     0.99478,      0.9948,     0.99482,     0.99484,     0.99485,     0.99487,     0.99489,     0.99491,     0.99493,     0.99495,     0.99496,     0.99498,\n",
              "              0.995,     0.99502,     0.99504,     0.99506,     0.99507,     0.99509,     0.99511,     0.99513,     0.99515,     0.99517,     0.99519,      0.9952,     0.99522,     0.99524,     0.99526,     0.99528,      0.9953,     0.99531,     0.99533,     0.99535,     0.99537,     0.99539,     0.99541,\n",
              "            0.99542,     0.99544,     0.99546,     0.99548,      0.9955,     0.99552,     0.99553,     0.99555,     0.99557,     0.99559,     0.99561,     0.99563,     0.99564,     0.99566,     0.99568,      0.9957,     0.99572,     0.99574,     0.99576,     0.99577,     0.99579,     0.99581,     0.99583,\n",
              "            0.99585,     0.99587,     0.99588,      0.9959,     0.99592,     0.99594,     0.99596,     0.99598,     0.99599,     0.99601,     0.99603,     0.99605,     0.99607,     0.99609,      0.9961,     0.99612,     0.99614,     0.99616,     0.99618,      0.9962,     0.99621,     0.99623,     0.99625,\n",
              "            0.99627,     0.99628,     0.99629,      0.9963,     0.99631,     0.99631,     0.99632,     0.99633,     0.99633,     0.99634,     0.99635,     0.99636,     0.99636,     0.99637,     0.99638,     0.99638,     0.99639,      0.9964,      0.9964,     0.99641,     0.99642,     0.99643,     0.99643,\n",
              "            0.99644,     0.99645,     0.99645,     0.99646,     0.99647,     0.99648,     0.99648,     0.99649,      0.9965,      0.9965,     0.99651,     0.99652,     0.99653,     0.99653,     0.99654,     0.99655,     0.99655,     0.99656,     0.99657,     0.99657,     0.99658,     0.99659,      0.9966,\n",
              "             0.9966,     0.99661,     0.99662,     0.99662,     0.99663,     0.99664,     0.99665,     0.99665,     0.99666,     0.99667,     0.99667,     0.99668,     0.99669,     0.99669,      0.9967,     0.99671,     0.99672,     0.99672,     0.99673,     0.99674,     0.99674,     0.99675,     0.99676,\n",
              "            0.99677,     0.99677,     0.99678,     0.99679,     0.99679,      0.9968,     0.99681,     0.99681,     0.99682,     0.99683,     0.99684,     0.99684,     0.99685,     0.99686,     0.99686,     0.99687,     0.99688,     0.99689,     0.99689,      0.9969,     0.99691,     0.99691,     0.99692,\n",
              "            0.99693,     0.99694,     0.99694,     0.99695,     0.99696,     0.99696,     0.99697,     0.99698,     0.99698,     0.99699,       0.997,     0.99701,     0.99701,     0.99702,     0.99703,     0.99703,     0.99704,     0.99705,     0.99706,     0.99706,     0.99707,     0.99708,     0.99708,\n",
              "            0.99709,      0.9971,      0.9971,     0.99711,     0.99712,     0.99713,     0.99713,     0.99714,     0.99715,     0.99715,     0.99716,     0.99717,     0.99718,     0.99718,     0.99719,      0.9972,      0.9972,     0.99721,     0.99722,     0.99722,     0.99723,     0.99724,     0.99725,\n",
              "            0.99725,     0.99726,     0.99727,     0.99727,     0.99728,     0.99729,      0.9973,      0.9973,     0.99731,     0.99732,     0.99732,     0.99733,     0.99734,     0.99735,     0.99735,     0.99736,     0.99737,     0.99737,     0.99738,     0.99739,     0.99739,      0.9974,     0.99741,\n",
              "            0.99742,     0.99742,     0.99743,     0.99744,     0.99744,     0.99745,     0.99746,     0.99747,     0.99747,     0.99748,     0.99749,     0.99749,      0.9975,     0.99751,     0.99751,     0.99752,     0.99753,     0.99754,     0.99754,     0.99755,     0.99756,     0.99756,     0.99757,\n",
              "            0.99758,     0.99759,     0.99759,      0.9976,     0.99761,     0.99761,     0.99762,     0.99763,     0.99763,     0.99764,     0.99765,     0.99766,     0.99766,     0.99767,     0.99768,     0.99768,     0.99769,      0.9977,     0.99771,     0.99771,     0.99772,     0.99773,     0.99773,\n",
              "            0.99774,     0.99775,     0.99776,     0.99776,     0.99777,     0.99778,     0.99778,     0.99779,      0.9978,      0.9978,     0.99781,     0.99782,     0.99783,     0.99783,     0.99784,     0.99785,     0.99785,     0.99786,     0.99787,     0.99788,     0.99788,     0.99789,      0.9979,\n",
              "             0.9979,     0.99791,     0.99792,     0.99792,     0.99793,     0.99794,     0.99795,     0.99795,     0.99796,     0.99797,     0.99797,     0.99798,     0.99799,       0.998,       0.998,     0.99801,     0.99802,     0.99802,     0.99803,     0.99804,     0.99804,     0.99805,     0.99806,\n",
              "            0.99807,     0.99807,     0.99808,     0.99809,     0.99809,      0.9981,     0.99811,     0.99812,     0.99812,     0.99813,     0.99814,     0.99814,     0.99815,     0.99816,     0.99817,     0.99818,     0.99818,     0.99819,      0.9982,     0.99821,     0.99822,     0.99822,     0.99823,\n",
              "            0.99824,     0.99825,     0.99826,     0.99826,     0.99827,     0.99828,     0.99829,     0.99829,      0.9983,     0.99831,     0.99832,     0.99833,     0.99833,     0.99834,     0.99835,     0.99836,     0.99837,     0.99837,     0.99838,     0.99839,      0.9984,     0.99841,     0.99841,\n",
              "            0.99842,     0.99843,     0.99844,     0.99845,     0.99845,     0.99846,     0.99847,     0.99848,     0.99848,     0.99849,      0.9985,     0.99851,     0.99852,     0.99852,     0.99853,     0.99854,     0.99855,     0.99856,     0.99856,     0.99857,     0.99858,     0.99859,      0.9986,\n",
              "             0.9986,     0.99861,     0.99862,     0.99863,     0.99864,     0.99864,     0.99865,     0.99866,     0.99867,     0.99867,     0.99868,     0.99869,      0.9987,     0.99871,     0.99871,     0.99872,     0.99873,     0.99874,     0.99875,     0.99875,     0.99876,     0.99877,     0.99878,\n",
              "            0.99879,     0.99879,      0.9988,     0.99881,     0.99882,     0.99882,     0.99883,     0.99884,     0.99885,     0.99886,     0.99886,     0.99887,     0.99888,     0.99889,      0.9989,      0.9989,     0.99891,     0.99892,     0.99893,     0.99894,     0.99894,     0.99895,     0.99896,\n",
              "            0.99897,     0.99898,     0.99898,     0.99899,       0.999,     0.99901,     0.99901,     0.99902,     0.99903,     0.99904,     0.99905,     0.99905,     0.99906,     0.99907,     0.99908,     0.99909,     0.99909,      0.9991,     0.99911,     0.99912,     0.99913,     0.99913,     0.99914,\n",
              "            0.99915,     0.99916,     0.99916,     0.99917,     0.99918,     0.99919,      0.9992,      0.9992,     0.99921,     0.99922,     0.99923,     0.99924,     0.99924,     0.99925,     0.99926,     0.99927,     0.99928,     0.99928,     0.99929,      0.9993,     0.99931,     0.99932,     0.99932,\n",
              "            0.99933,     0.99934,     0.99935,     0.99935,     0.99936,     0.99937,     0.99938,     0.99939,     0.99939,      0.9994,     0.99941,     0.99942,     0.99943,     0.99943,     0.99944,     0.99945,     0.99946,     0.99947,     0.99947,     0.99948,     0.99949,      0.9995,     0.99951,\n",
              "            0.99951,     0.99952,     0.99953,     0.99954,     0.99954,     0.99955,     0.99956,     0.99957,     0.99958,     0.99958,     0.99959,      0.9996,     0.99961,     0.99962,     0.99962,     0.99963,     0.99964,     0.99965,     0.99966,     0.99966,     0.99967,     0.99968,     0.99969,\n",
              "            0.99969,      0.9997,     0.99971,     0.99972,     0.99973,     0.99973,     0.99974,     0.99975,     0.99976,     0.99977,     0.99977,     0.99978,     0.99979,      0.9998,     0.99981,     0.99981,     0.99982,     0.99983,     0.99984,     0.99985,     0.99985,     0.99986,     0.99987,\n",
              "            0.99988,     0.99988,     0.99989,      0.9999,     0.99991,     0.99992,     0.99992,     0.99993,     0.99994,     0.99995,     0.99996,     0.99996,     0.99997,     0.99998,     0.99999,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99994,     0.99979,     0.99964,     0.99949,     0.99935,      0.9992,     0.99905,\n",
              "            0.99891,     0.99876,     0.99861,     0.99846,     0.99832,     0.99817,     0.99808,     0.99801,     0.99794,     0.99787,      0.9978,     0.99773,     0.99766,     0.99759,     0.99752,     0.99745,     0.99738,     0.99731,     0.99724,     0.99717,      0.9971,     0.99703,     0.99696,\n",
              "            0.99689,     0.99682,     0.99675,     0.99668,     0.99661,     0.99654,     0.99647,      0.9964,     0.99633,     0.99627,     0.99623,      0.9962,     0.99617,     0.99614,     0.99611,     0.99608,     0.99604,     0.99601,     0.99598,     0.99595,     0.99592,     0.99588,     0.99585,\n",
              "            0.99582,     0.99579,     0.99576,     0.99573,     0.99569,     0.99566,     0.99563,      0.9956,     0.99557,     0.99553,      0.9955,     0.99547,     0.99544,     0.99541,     0.99538,     0.99534,     0.99531,     0.99528,     0.99525,     0.99522,     0.99518,     0.99515,     0.99512,\n",
              "            0.99509,     0.99506,     0.99503,     0.99499,     0.99496,     0.99493,      0.9949,     0.99487,     0.99483,      0.9948,     0.99477,     0.99474,     0.99471,     0.99468,     0.99464,     0.99461,     0.99458,     0.99455,     0.99452,     0.99448,     0.99445,     0.99442,     0.99437,\n",
              "            0.99431,     0.99425,     0.99418,     0.99412,     0.99405,     0.99399,     0.99392,     0.99386,     0.99379,     0.99373,     0.99366,      0.9936,     0.99353,     0.99347,      0.9934,     0.99334,     0.99327,     0.99321,     0.99314,     0.99308,     0.99301,     0.99295,     0.99288,\n",
              "            0.99282,     0.99275,     0.99269,     0.99262,     0.99256,     0.99249,     0.99241,     0.99233,     0.99225,     0.99218,      0.9921,     0.99202,     0.99195,     0.99187,     0.99179,     0.99172,     0.99164,     0.99156,     0.99149,     0.99141,     0.99133,     0.99125,     0.99118,\n",
              "             0.9911,     0.99102,     0.99095,     0.99087,     0.99079,     0.99072,     0.98991,     0.98675,     0.98626,     0.98577,     0.98527,       0.985,     0.98486,     0.98473,      0.9846,     0.98447,     0.98434,      0.9842,     0.98407,     0.98394,     0.98381,     0.98368,     0.98354,\n",
              "            0.98341,     0.98328,     0.98104,     0.98038,     0.97972,     0.97941,     0.97931,      0.9792,      0.9791,     0.97899,     0.97889,     0.97878,     0.97868,     0.97857,     0.97847,     0.97836,     0.97826,     0.97816,     0.97805,     0.97795,     0.97784,     0.97774,     0.97763,\n",
              "            0.97561,     0.97544,     0.97527,      0.9751,     0.97494,     0.97477,      0.9746,     0.97443,     0.97426,     0.97409,     0.97392,     0.97183,     0.97116,     0.97049,     0.96776,     0.96423,     0.96272,     0.96024,     0.95964,     0.95904,      0.9558,     0.95343,     0.95082,\n",
              "            0.94731,     0.94598,      0.9446,     0.93888,     0.93699,     0.93218,     0.92776,     0.91854,     0.90745,     0.90043,     0.89286,     0.88531,     0.87405,     0.86828,     0.86232,     0.84837,     0.83783,     0.82616,     0.82072,     0.80528,     0.79304,     0.78299,     0.76842,\n",
              "            0.76383,     0.75042,     0.74082,     0.73144,     0.71119,     0.68882,     0.67654,     0.66452,     0.62562,     0.60016,     0.58271,     0.56729,     0.53669,     0.52105,     0.48822,     0.45825,     0.42328,     0.38256,     0.34923,     0.31279,     0.29169,     0.25801,     0.23628,\n",
              "            0.21058,      0.1857,     0.17371,      0.1468,     0.13264,     0.11998,    0.097499,    0.081219,    0.068924,    0.062987,    0.057234,    0.047525,     0.04239,    0.038201,    0.032382,    0.027464,    0.021603,    0.020288,    0.019602,    0.018915,      0.0173,    0.015745,    0.013998,\n",
              "           0.011271,   0.0095803,   0.0058371,     0.00371,   0.0034728,   0.0032355,   0.0029983,   0.0027611,   0.0025239,   0.0022867,   0.0020495,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.8843484617858368\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.87205])\n",
              "names: {0: 'container number'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9996395541173523, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8720538464287075, 'fitness': 0.8843484617858368}\n",
              "save_dir: PosixPath('runs/detect/train2')\n",
              "speed: {'preprocess': 0.22094196348047968, 'inference': 4.340280347795629, 'loss': 0.0020955035935586955, 'postprocess': 2.1041938618047915}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å°‡é æ¸¬æ¡†å­˜æˆtxtæª”\n",
        "\n",
        "import os\n",
        "\n",
        "# å®šç¾©åœ–ç‰‡æª”æ¡ˆç›®éŒ„è·¯å¾‘\n",
        "source_directory = '/content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†'\n",
        "\n",
        "# é æ¸¬æ•´å€‹ç›®éŒ„\n",
        "results = model.predict(source=source_directory, save=True)\n",
        "\n",
        "# è½‰æ›é æ¸¬æ¡†æ ¼å¼\n",
        "pred_boxes_for_iou = []\n",
        "for result in results:\n",
        "    # è·å– Result å¯¹è±¡çš„è·¯å¾„å±æ€§\n",
        "    image_path = result.path\n",
        "    image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    if len(result.boxes) == 0:  # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°ç‰©ä»¶\n",
        "        pred_boxes_for_iou.append({'image_id': image_id, 'boxes': [{'class_index': 0, 'coordinates': [0, 0, 0, 0]}]})\n",
        "    else:\n",
        "        boxes = [{'class_index': int(box.cls.item()), 'coordinates': [box.xyxy[0], box.xyxy[1], box.xyxy[2], box.xyxy[3]] if len(box.xyxy) == 4 else [box.xyxy[0][0], box.xyxy[0][1], box.xyxy[0][2], box.xyxy[0][3]]} for box in result.boxes]\n",
        "        pred_boxes_for_iou.append({'image_id': image_id, 'boxes': boxes})\n",
        "\n",
        "\n",
        "# å°†é¢„æµ‹ç»“æœä¿å­˜åˆ° TXT æ–‡ä»¶\n",
        "with open('pred_boxes_for_iou.txt', 'w') as txtfile:\n",
        "    for prediction in pred_boxes_for_iou:\n",
        "        image_id = prediction['image_id']\n",
        "        for box in prediction['boxes']:\n",
        "            class_index = box['class_index']\n",
        "            x_min, y_min, x_max, y_max = box['coordinates']\n",
        "            txtfile.write(f\"{image_id} {class_index} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
        "\n",
        "print(\"é æ¸¬æ¡†å·²ä¿å­˜åˆ°æ–‡ä»¶ä¸­\")\n"
      ],
      "metadata": {
        "id": "Cv6cB8jj9GN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380a62f5-e094-4f3d-9de5-00cb502e1743"
      },
      "id": "Cv6cB8jj9GN6",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/FFAU2895947.jpg: 256x416 1 container number, 56.9ms\n",
            "image 2/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/MAGU5605323.jpg: 256x416 1 container number, 6.7ms\n",
            "image 3/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/SEKU5875349.jpg: 256x416 1 container number, 7.0ms\n",
            "image 4/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/SEKU5877491.jpg: 256x416 2 container numbers, 6.9ms\n",
            "image 5/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/SEKU6026686.jpg: 256x416 (no detections), 6.9ms\n",
            "image 6/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TCNU6246126.jpg: 256x416 1 container number, 6.8ms\n",
            "image 7/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TLLU4080736.jpg: 256x416 1 container number, 6.3ms\n",
            "image 8/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TRHU8927462.jpg: 256x416 1 container number, 6.4ms\n",
            "image 9/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5017340.jpg: 256x416 1 container number, 6.7ms\n",
            "image 10/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5029819.jpg: 256x416 1 container number, 6.4ms\n",
            "image 11/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5042071.jpg: 256x416 1 container number, 6.5ms\n",
            "image 12/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5061615.jpg: 256x416 1 container number, 6.7ms\n",
            "image 13/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5099400.jpg: 256x416 1 container number, 9.1ms\n",
            "image 14/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5142300.jpg: 256x416 1 container number, 10.0ms\n",
            "image 15/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/TSSU5160351.jpg: 256x416 1 container number, 13.6ms\n",
            "image 16/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHLU5591798.jpg: 256x416 1 container number, 7.9ms\n",
            "image 17/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHLU5842825.jpg: 256x416 1 container number, 6.9ms\n",
            "image 18/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU2483178.jpg: 256x416 1 container number, 6.1ms\n",
            "image 19/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU2615314.jpg: 256x416 1 container number, 6.2ms\n",
            "image 20/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU2864765.jpg: 256x416 1 container number, 7.5ms\n",
            "image 21/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5295430.jpg: 256x416 1 container number, 7.5ms\n",
            "image 22/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5368199.jpg: 256x416 1 container number, 7.3ms\n",
            "image 23/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5563298.jpg: 256x416 1 container number, 6.8ms\n",
            "image 24/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5610492.jpg: 256x416 1 container number, 6.5ms\n",
            "image 25/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5628589.jpg: 256x416 1 container number, 6.7ms\n",
            "image 26/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5744465.jpg: 256x416 1 container number, 7.0ms\n",
            "image 27/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5991104.jpg: 256x416 1 container number, 6.0ms\n",
            "image 28/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU5998393.jpg: 256x416 1 container number, 6.2ms\n",
            "image 29/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6010260.jpg: 256x416 1 container number, 6.3ms\n",
            "image 30/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6040178.jpg: 256x416 1 container number, 12.1ms\n",
            "image 31/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6052306.jpg: 256x416 1 container number, 10.1ms\n",
            "image 32/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6167120.jpg: 256x416 1 container number, 7.9ms\n",
            "image 33/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6557387.jpg: 256x416 1 container number, 6.7ms\n",
            "image 34/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6651665.jpg: 256x416 1 container number, 6.4ms\n",
            "image 35/35 /content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†/WHSU6856285.jpg: 256x416 2 container numbers, 7.3ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "é æ¸¬æ¡†å·²ä¿å­˜åˆ°æ–‡ä»¶ä¸­\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å°‡é‡è¤‡é æ¸¬æ¡†ä½¿ç”¨NMSå»é™¤\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# è®€å–é æ¸¬æ¡†\n",
        "def read_prediction_boxes_from_txt(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    boxes_by_image = {}\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 6:\n",
        "            continue  # å¿½ç•¥ä¸å®Œæ•´çš„è¡Œ\n",
        "        img_name = parts[0]\n",
        "        class_name = parts[1]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        if img_name not in boxes_by_image:\n",
        "            boxes_by_image[img_name] = []\n",
        "        boxes_by_image[img_name].append((class_name, x1, y1, x2, y2))\n",
        "    return boxes_by_image\n",
        "\n",
        "\n",
        "def save_boxes_to_txt_with_nms(boxes_by_image, file_path, iou_threshold=0.5):\n",
        "    print(\"Saving boxes to:\", file_path)  # æ·»åŠ è¿™è¡Œä»¥æ‰“å°ä¿å­˜çš„æ–‡ä»¶è·¯å¾„\n",
        "    with open(file_path, 'w') as f:\n",
        "        for img_name, img_boxes in boxes_by_image.items():\n",
        "            # å¯¹æ¯å¼ å›¾ç‰‡çš„é¢„æµ‹æ¡†è¿›è¡ŒNMSå¤„ç†\n",
        "            nms_boxes = apply_nms(img_boxes, iou_threshold)\n",
        "            for box in nms_boxes:\n",
        "                img_class, x1, y1, x2, y2 = box\n",
        "                f.write(f\"{img_name} {img_class} {x1} {y1} {x2} {y2}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def apply_nms(boxes, iou_threshold):\n",
        "    if not boxes:\n",
        "        return []\n",
        "\n",
        "    # Sort boxes based on confidence scores (assuming confidence score is not present)\n",
        "    sorted_boxes = sorted(boxes, key=lambda x: x[1])  # Sort based on class_name\n",
        "\n",
        "    nms_boxes = []\n",
        "    while sorted_boxes:\n",
        "        current_box = sorted_boxes.pop(0)\n",
        "        nms_boxes.append(current_box)\n",
        "        # Remove other boxes with IoU greater than threshold with the current box\n",
        "        sorted_boxes = [box for box in sorted_boxes if calculate_iou(box, current_box) < iou_threshold]\n",
        "\n",
        "    print(\"NMS Boxes:\", nms_boxes)  # æ·»åŠ è¿™è¡Œä»¥æ‰“å°ç­›é€‰åçš„æ¡†\n",
        "\n",
        "    return nms_boxes\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1[1], box1[2], box1[3], box1[4]\n",
        "    x3, y3, x4, y4 = box2[1], box2[2], box2[3], box2[4]\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    x_intersection1 = max(x1, x3)\n",
        "    y_intersection1 = max(y1, y3)\n",
        "    x_intersection2 = min(x2, x4)\n",
        "    y_intersection2 = min(y2, y4)\n",
        "\n",
        "    # Calculate intersection area\n",
        "    intersection_width = max(0, x_intersection2 - x_intersection1 + 1)\n",
        "    intersection_height = max(0, y_intersection2 - y_intersection1 + 1)\n",
        "    intersection_area = intersection_width * intersection_height\n",
        "\n",
        "    # Calculate area for each box\n",
        "    area_box1 = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    area_box2 = (x4 - x3 + 1) * (y4 - y3 + 1)\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection_area / float(area_box1 + area_box2 - intersection_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "# è®€å–é æ¸¬æ¡†\n",
        "boxes = read_prediction_boxes_from_txt('pred_boxes_for_iou.txt')\n",
        "# å°‡é æ¸¬æ¡†é€²è¡ŒNMSè™•ç†ä¸¦ä¿å­˜åˆ°æ–‡ä»¶ä¸­\n",
        "save_boxes_to_txt_with_nms(boxes, 'nms_pred_boxes_for_iou.txt', iou_threshold=0.1)\n"
      ],
      "metadata": {
        "id": "qtwi-RwCNZjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24cb54d-6625-48eb-f29f-6ac71be131bd"
      },
      "id": "qtwi-RwCNZjv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving boxes to: nms_pred_boxes_for_iou.txt\n",
            "NMS Boxes: [('0', 809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812)]\n",
            "NMS Boxes: [('0', 873.1626586914062, 366.3352355957031, 1194.9390869140625, 513.7098999023438)]\n",
            "NMS Boxes: [('0', 815.1351318359375, 22.03270721435547, 976.1596069335938, 112.34261322021484)]\n",
            "NMS Boxes: [('0', 872.0701293945312, 102.8860855102539, 1081.037109375, 234.52272033691406)]\n",
            "NMS Boxes: [('0', 0.0, 0.0, 0.0, 0.0)]\n",
            "NMS Boxes: [('0', 799.1828002929688, 109.80933380126953, 1114.87548828125, 247.7976837158203)]\n",
            "NMS Boxes: [('0', 888.181640625, 321.4427185058594, 1181.986328125, 455.28314208984375)]\n",
            "NMS Boxes: [('0', 557.2132568359375, 68.03431701660156, 739.69970703125, 148.6082305908203)]\n",
            "NMS Boxes: [('0', 494.95428466796875, 99.1235122680664, 718.9732055664062, 197.6240692138672)]\n",
            "NMS Boxes: [('0', 454.249267578125, 18.463581085205078, 611.65087890625, 91.51872253417969)]\n",
            "NMS Boxes: [('0', 847.5410766601562, 15.187524795532227, 1027.642333984375, 113.15298461914062)]\n",
            "NMS Boxes: [('0', 493.5251159667969, 35.32341766357422, 646.107177734375, 112.31429290771484)]\n",
            "NMS Boxes: [('0', 618.1014404296875, 96.71002960205078, 875.7691650390625, 224.2683563232422)]\n",
            "NMS Boxes: [('0', 736.9159545898438, 258.1374816894531, 1149.952392578125, 439.09625244140625)]\n",
            "NMS Boxes: [('0', 550.4066162109375, 62.59148406982422, 736.8045043945312, 150.60739135742188)]\n",
            "NMS Boxes: [('0', 917.1697998046875, 274.5277099609375, 1171.8109130859375, 376.395263671875)]\n",
            "NMS Boxes: [('0', 913.8927001953125, 241.12359619140625, 1158.686279296875, 359.35205078125)]\n",
            "NMS Boxes: [('0', 965.2523193359375, 148.31394958496094, 1076.2281494140625, 212.6099853515625)]\n",
            "NMS Boxes: [('0', 875.1309814453125, 69.6878433227539, 1113.4210205078125, 179.50296020507812)]\n",
            "NMS Boxes: [('0', 868.640380859375, 371.1065368652344, 1172.1561279296875, 501.86468505859375)]\n",
            "NMS Boxes: [('0', 795.5057983398438, 81.56464385986328, 1081.2857666015625, 203.8123321533203)]\n",
            "NMS Boxes: [('0', 751.9009399414062, 99.50450897216797, 1053.5714111328125, 230.80950927734375)]\n",
            "NMS Boxes: [('0', 706.3908081054688, 265.4079895019531, 956.8006591796875, 375.4702453613281)]\n",
            "NMS Boxes: [('0', 951.4073486328125, 613.934326171875, 1537.2320556640625, 848.4097290039062)]\n",
            "NMS Boxes: [('0', 750.6513671875, 91.65377807617188, 1043.9061279296875, 221.6487274169922)]\n",
            "NMS Boxes: [('0', 945.4542236328125, 454.7745361328125, 1385.9649658203125, 640.6891479492188)]\n",
            "NMS Boxes: [('0', 509.62591552734375, 78.08295440673828, 723.62158203125, 170.82151794433594)]\n",
            "NMS Boxes: [('0', 550.8336791992188, 45.75040054321289, 726.7974243164062, 124.10578918457031)]\n",
            "NMS Boxes: [('0', 784.210693359375, 423.94403076171875, 1210.7906494140625, 599.2708129882812)]\n",
            "NMS Boxes: [('0', 565.2068481445312, 282.5029602050781, 825.3998413085938, 392.9221496582031)]\n",
            "NMS Boxes: [('0', 906.256591796875, 243.07191467285156, 1150.995849609375, 359.837646484375)]\n",
            "NMS Boxes: [('0', 688.3995971679688, 352.52264404296875, 1014.1488647460938, 499.03643798828125)]\n",
            "NMS Boxes: [('0', 550.02978515625, 9.468994140625, 707.154541015625, 79.60198211669922)]\n",
            "NMS Boxes: [('0', 758.2356567382812, 103.15608978271484, 1097.291748046875, 240.33180236816406)]\n",
            "NMS Boxes: [('0', 702.3404541015625, 254.8941192626953, 1160.6143798828125, 440.1466979980469)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æª¢æŸ¥æ¯å€‹åœ–ç‰‡æ˜¯å¦åªæœ‰ä¸€å€‹é æ¸¬æ¡†\n",
        "import os\n",
        "\n",
        "# è®€å–é æ¸¬æ¡†\n",
        "def read_prediction_boxes_from_txt(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 6:\n",
        "            continue  # å¿½ç•¥ä¸å®Œæ•´çš„è¡Œ\n",
        "        img_name = parts[0]\n",
        "        score = float(parts[-1])\n",
        "        x1, y1, x2, y2 = map(float, parts[-5:-1])\n",
        "        boxes.append((img_name, x1, y1, x2, y2, score))\n",
        "    return boxes\n",
        "\n",
        "# ç¢ºä¿æ¯å€‹åœ–ç‰‡åªæœ‰ä¸€å€‹é æ¸¬æ¡†\n",
        "def ensure_single_prediction_per_image(prediction_boxes):\n",
        "    unique_image_names = set()\n",
        "    single_prediction_boxes = []\n",
        "    for box in prediction_boxes:\n",
        "        img_name = box[0]\n",
        "        if img_name not in unique_image_names:\n",
        "            single_prediction_boxes.append(box)\n",
        "            unique_image_names.add(img_name)\n",
        "    return single_prediction_boxes\n",
        "\n",
        "# è®€å–é æ¸¬æ¡†\n",
        "prediction_boxes = read_prediction_boxes_from_txt('nms_pred_boxes_for_iou.txt')\n",
        "\n",
        "# ç¢ºä¿æ¯å€‹åœ–ç‰‡åªæœ‰ä¸€å€‹é æ¸¬æ¡†\n",
        "single_prediction_boxes = ensure_single_prediction_per_image(prediction_boxes)\n",
        "\n",
        "# æ‰“å°çµæœ\n",
        "print(f\"åŸå§‹é æ¸¬æ¡†æ•¸é‡: {len(prediction_boxes)}\")\n",
        "print(f\"ç¢ºä¿æ¯å€‹åœ–ç‰‡åªæœ‰ä¸€å€‹é æ¸¬æ¡†å¾Œçš„é æ¸¬æ¡†æ•¸é‡: {len(single_prediction_boxes)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O7B6-gHjCSV",
        "outputId": "dff3f261-a9f9-47cc-c611-14d237346816"
      },
      "id": "5O7B6-gHjCSV",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "åŸå§‹é æ¸¬æ¡†æ•¸é‡: 35\n",
            "ç¢ºä¿æ¯å€‹åœ–ç‰‡åªæœ‰ä¸€å€‹é æ¸¬æ¡†å¾Œçš„é æ¸¬æ¡†æ•¸é‡: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è¼‰å…¥çœŸå¯¦æ¡†\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def get_image_resolution(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size  # è¿”å› (width, height)\n",
        "\n",
        "def read_true_boxes(labels_directory, images_directory):\n",
        "    true_boxes = {}\n",
        "    for label_file in os.listdir(labels_directory):\n",
        "        if label_file.endswith('.txt'):\n",
        "            image_id = os.path.splitext(label_file)[0]\n",
        "            image_path = os.path.join(images_directory, image_id + \".jpg\")  # å‡è¨­å½±åƒæ–‡ä»¶æ ¼å¼ç‚º.jpg\n",
        "\n",
        "            # ç¡®ä¿å¯¹åº”çš„å½±åƒæ–‡ä»¶å­˜åœ¨\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image file {image_path} does not exist. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            with open(os.path.join(labels_directory, label_file), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            boxes = []\n",
        "            image_width, image_height = get_image_resolution(image_path)\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:  # ç¡®ä¿æ¯è¡Œæœ‰5ä¸ªéƒ¨åˆ†\n",
        "                    class_index = int(parts[0])\n",
        "                    x_center = float(parts[1])\n",
        "                    y_center = float(parts[2])\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    # è®¡ç®—å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡\n",
        "                    x1 = int((x_center - width / 2) * image_width)\n",
        "                    y1 = int((y_center - height / 2) * image_height)\n",
        "                    x2 = int((x_center + width / 2) * image_width)\n",
        "                    y2 = int((y_center + height / 2) * image_height)\n",
        "                    boxes.append({'class_index': class_index, 'coordinates': [x1, y1, x2, y2]})\n",
        "            true_boxes[image_id] = boxes\n",
        "    return true_boxes\n",
        "\n",
        "# çœŸå¯¦æ¡†çš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "labels_directory = '/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/labels/test'\n",
        "# å½±åƒçš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "images_directory = '/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/æ¸¬è©¦é›†'\n",
        "\n",
        "# è®€å–çœŸå¯¦æ¡†\n",
        "true_boxes = read_true_boxes(labels_directory, images_directory)\n",
        "\n",
        "# å°‡çœŸå¯¦æ¡†è½‰æ›æˆæ˜“æ–¼è¨ˆç®— IoU çš„æ ¼å¼\n",
        "true_boxes_for_iou = [{'image_id': image_id, 'boxes': boxes} for image_id, boxes in true_boxes.items()]\n",
        "\n",
        "# æŒ‰ç…§å½±åƒåºè™Ÿæ’åºçœŸå¯¦æ¡†\n",
        "true_boxes_for_iou.sort(key=lambda x: int(x['image_id'].split('_')[-1]))\n",
        "\n",
        "# å°‡çœŸå¯¦æ¡†ä¿å­˜åˆ° TXT æ–‡ä»¶\n",
        "output_path = '/content/true_boxes_for_iou.txt'  # ç¢ºä¿è·¯å¾‘æ­£ç¢º\n",
        "with open(output_path, 'w') as txtfile:\n",
        "    for true_box in true_boxes_for_iou:\n",
        "        image_id = true_box['image_id']\n",
        "        for box in true_box['boxes']:\n",
        "            class_index = box['class_index']\n",
        "            x_min, y_min, x_max, y_max = box['coordinates']\n",
        "            txtfile.write(f\"{image_id} {class_index} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
        "\n",
        "print(\"çœŸå¯¦æ¡†è½‰æ›å®Œæˆ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ab-m4DuTjLd",
        "outputId": "90736d4b-a558-4fe9-dfd6-acfc637417c8"
      },
      "id": "6Ab-m4DuTjLd",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "çœŸå¯¦æ¡†è½‰æ›å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ç›®è¦–æª¢æŸ¥çœŸå¯¦æ¡†æ˜¯å¦æœ‰å°æ‡‰åˆ°å¯¦éš›åœ–ç‰‡\n",
        "'''\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def draw_boxes_on_image(image_path, boxes, output_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        for box in boxes:\n",
        "            class_index = box['class_index']\n",
        "            x1, y1, x2, y2 = box['coordinates']\n",
        "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
        "            draw.text((x1, y1), str(class_index), fill=\"red\")\n",
        "        img.save(output_path)\n",
        "\n",
        "# çœŸå¯¦æ¡†çš„æ–‡ä»¶è·¯å¾‘\n",
        "true_boxes_file = '/content/true_boxes_for_iou.txt'\n",
        "# å½±åƒçš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "images_directory = '/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/æ¸¬è©¦é›†'\n",
        "# ç¹ªè£½çµæœçš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "draw_directory = '/content/draw'\n",
        "\n",
        "# ç¢ºä¿ç¹ªè£½çµæœçš„è³‡æ–™å¤¾å­˜åœ¨\n",
        "os.makedirs(draw_directory, exist_ok=True)\n",
        "\n",
        "# è®€å–çœŸå¯¦æ¡†æ•¸æ“š\n",
        "true_boxes = {}\n",
        "with open(true_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        image_id = parts[0]\n",
        "        class_index = int(parts[1])\n",
        "        x_min = int(parts[2])\n",
        "        y_min = int(parts[3])\n",
        "        x_max = int(parts[4])\n",
        "        y_max = int(parts[5])\n",
        "        box = {'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]}\n",
        "        if image_id not in true_boxes:\n",
        "            true_boxes[image_id] = []\n",
        "        true_boxes[image_id].append(box)\n",
        "\n",
        "# ç¹ªè£½ä¸¦ä¿å­˜å½±åƒ\n",
        "for image_id, boxes in true_boxes.items():\n",
        "    image_path = os.path.join(images_directory, image_id + \".jpg\")\n",
        "    output_image_path = os.path.join(draw_directory, image_id + \".jpg\")\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Image file {image_path} does not exist. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    draw_boxes_on_image(image_path, boxes, output_image_path)\n",
        "\n",
        "print(\"æ‰€æœ‰å½±åƒå·²ç¹ªè£½ä¸¦ä¿å­˜å®Œæˆ\")\n",
        "'''"
      ],
      "metadata": {
        "id": "0Y0XkCiHHdha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f09a69d9-0791-4b10-9b02-cdd65fc40d10"
      },
      "id": "0Y0XkCiHHdha",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom PIL import Image, ImageDraw\\n\\ndef draw_boxes_on_image(image_path, boxes, output_path):\\n    with Image.open(image_path) as img:\\n        draw = ImageDraw.Draw(img)\\n        for box in boxes:\\n            class_index = box[\\'class_index\\']\\n            x1, y1, x2, y2 = box[\\'coordinates\\']\\n            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\\n            draw.text((x1, y1), str(class_index), fill=\"red\")\\n        img.save(output_path)\\n\\n# çœŸå¯¦æ¡†çš„æ–‡ä»¶è·¯å¾‘\\ntrue_boxes_file = \\'/content/true_boxes_for_iou.txt\\'\\n# å½±åƒçš„è³‡æ–™å¤¾è·¯å¾‘\\nimages_directory = \\'/content/hw3_M11221004/è²¨æ«ƒè³‡æ–™é›†/æ¸¬è©¦é›†\\'\\n# ç¹ªè£½çµæœçš„è³‡æ–™å¤¾è·¯å¾‘\\ndraw_directory = \\'/content/draw\\'\\n\\n# ç¢ºä¿ç¹ªè£½çµæœçš„è³‡æ–™å¤¾å­˜åœ¨\\nos.makedirs(draw_directory, exist_ok=True)\\n\\n# è®€å–çœŸå¯¦æ¡†æ•¸æ“š\\ntrue_boxes = {}\\nwith open(true_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        image_id = parts[0]\\n        class_index = int(parts[1])\\n        x_min = int(parts[2])\\n        y_min = int(parts[3])\\n        x_max = int(parts[4])\\n        y_max = int(parts[5])\\n        box = {\\'class_index\\': class_index, \\'coordinates\\': [x_min, y_min, x_max, y_max]}\\n        if image_id not in true_boxes:\\n            true_boxes[image_id] = []\\n        true_boxes[image_id].append(box)\\n\\n# ç¹ªè£½ä¸¦ä¿å­˜å½±åƒ\\nfor image_id, boxes in true_boxes.items():\\n    image_path = os.path.join(images_directory, image_id + \".jpg\")\\n    output_image_path = os.path.join(draw_directory, image_id + \".jpg\")\\n\\n    if not os.path.exists(image_path):\\n        print(f\"Image file {image_path} does not exist. Skipping.\")\\n        continue\\n\\n    draw_boxes_on_image(image_path, boxes, output_image_path)\\n\\nprint(\"æ‰€æœ‰å½±åƒå·²ç¹ªè£½ä¸¦ä¿å­˜å®Œæˆ\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å®šç¾©è®€å–å‡½æ•¸ä¾†è®€å–æ¡†çš„åº§æ¨™\n",
        "\n",
        "import os\n",
        "\n",
        "# å®šç¾©è§£æå‡½æ•¸\n",
        "def read_boxes_from_txt(file_path):\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_id = parts[0]\n",
        "            class_index = int(float(parts[1]))  # è½‰æ›ç‚ºæ•´æ•¸\n",
        "            x_min = float(parts[2])\n",
        "            y_min = float(parts[3])\n",
        "            x_max = float(parts[4])\n",
        "            y_max = float(parts[5])\n",
        "            boxes.append({'image_id': image_id, 'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]})\n",
        "    return boxes\n",
        "\n",
        "# è®€å–çœŸå¯¦æ¡†å’Œé æ¸¬æ¡†çš„æ–‡ä»¶è·¯å¾‘\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "# è®€å–çœŸå¯¦æ¡†å’Œé æ¸¬æ¡†\n",
        "true_boxes = read_boxes_from_txt(true_boxes_file)\n",
        "pred_boxes = read_boxes_from_txt(pred_boxes_file)\n",
        "\n",
        "# åˆ—å°ç¬¬ä¸€å€‹çœŸå¯¦æ¡†å’Œé æ¸¬æ¡†ä¾†ç¢ºèªæ ¼å¼æ˜¯å¦æ­£ç¢º\n",
        "if true_boxes:\n",
        "    print(\"ç¬¬ä¸€å€‹çœŸå¯¦æ¡†:\", true_boxes[0])\n",
        "if pred_boxes:\n",
        "    print(\"ç¬¬ä¸€å€‹é æ¸¬æ¡†:\", pred_boxes[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaPr3UdmEKxC",
        "outputId": "ea683584-09c4-4f96-f340-aac35d484c07"
      },
      "id": "QaPr3UdmEKxC",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¬¬ä¸€å€‹çœŸå¯¦æ¡†: {'image_id': 'image_0001', 'class_index': 0, 'coordinates': [743.0, 114.0, 1110.0, 238.0]}\n",
            "ç¬¬ä¸€å€‹é æ¸¬æ¡†: {'image_id': 'FFAU2895947', 'class_index': 0, 'coordinates': [809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è¨ˆç®—IoU èˆ‡ è®€å–çœŸå¯¦æ¡†ã€é æ¸¬æ¡†åº§æ¨™æ–‡ä»¶\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1_min, y1_min, x1_max, y1_max = box1\n",
        "    x2_min, y2_min, x2_max, y2_max = box2\n",
        "\n",
        "    inter_x_min = max(x1_min, x2_min)\n",
        "    inter_y_min = max(y1_min, y2_min)\n",
        "    inter_x_max = min(x1_max, x2_max)\n",
        "    inter_y_max = min(y1_max, y2_max)\n",
        "\n",
        "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
        "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area != 0 else 0\n",
        "\n",
        "\n",
        "# è®€å–é æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†çš„æ–‡ä»¶\n",
        "def read_boxes_from_txt(file_path):\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_id = parts[0]\n",
        "            class_index = int(float(parts[1]))  # è½‰æ›ç‚ºæ•´æ•¸\n",
        "            x_min = float(parts[2])\n",
        "            y_min = float(parts[3])\n",
        "            x_max = float(parts[4])\n",
        "            y_max = float(parts[5])\n",
        "            boxes.append({'image_id': image_id, 'class_index': class_index, 'coordinates': [x_min, y_min, x_max, y_max]})\n",
        "    return boxes\n",
        "\n",
        "# è®€å–çœŸå¯¦æ¡†å’Œé æ¸¬æ¡†\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "true_boxes = read_boxes_from_txt(true_boxes_file)\n",
        "pred_boxes = read_boxes_from_txt(pred_boxes_file)\n",
        "\n",
        "# æ‰“å°ä¸€äº›æ ·æœ¬æ•°æ®è¿›è¡Œæ£€æŸ¥\n",
        "print(\"Sample true boxes:\")\n",
        "for i in range(5):\n",
        "    print(true_boxes[i])\n",
        "\n",
        "print(\"\\nSample prediction boxes:\")\n",
        "for i in range(5):\n",
        "    print(pred_boxes[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zIk5uHh8Z3M",
        "outputId": "83d1a5da-fc30-4a88-e4ce-dbee96e11580"
      },
      "id": "5zIk5uHh8Z3M",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample true boxes:\n",
            "{'image_id': 'image_0001', 'class_index': 0, 'coordinates': [743.0, 114.0, 1110.0, 238.0]}\n",
            "{'image_id': 'image_0002', 'class_index': 0, 'coordinates': [739.0, 158.0, 1160.0, 302.0]}\n",
            "{'image_id': 'image_0003', 'class_index': 0, 'coordinates': [728.0, 155.0, 1159.0, 294.0]}\n",
            "{'image_id': 'image_0004', 'class_index': 0, 'coordinates': [784.0, 98.0, 1128.0, 211.0]}\n",
            "{'image_id': 'image_0005', 'class_index': 0, 'coordinates': [820.0, 38.0, 1097.0, 136.0]}\n",
            "\n",
            "Sample prediction boxes:\n",
            "{'image_id': 'FFAU2895947', 'class_index': 0, 'coordinates': [809.9198608398438, 67.23347473144531, 1057.36181640625, 192.47659301757812]}\n",
            "{'image_id': 'MAGU5605323', 'class_index': 0, 'coordinates': [873.1626586914062, 366.3352355957031, 1194.9390869140625, 513.7098999023438]}\n",
            "{'image_id': 'SEKU5875349', 'class_index': 0, 'coordinates': [815.1351318359375, 22.03270721435547, 976.1596069335938, 112.34261322021484]}\n",
            "{'image_id': 'SEKU5877491', 'class_index': 0, 'coordinates': [872.0701293945312, 102.8860855102539, 1081.037109375, 234.52272033691406]}\n",
            "{'image_id': 'SEKU6026686', 'class_index': 0, 'coordinates': [0.0, 0.0, 0.0, 0.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# è®€å–é æ¸¬æ¡†æª”æ¡ˆ\n",
        "pred_boxes_file = 'nms_pred_boxes_for_iou.txt'\n",
        "true_boxes_file = 'true_boxes_for_iou.txt'\n",
        "\n",
        "pred_boxes = {}\n",
        "true_boxes = {}\n",
        "\n",
        "with open(pred_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        img_name = parts[0]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        pred_boxes[img_name] = (x1, y1, w, h)\n",
        "\n",
        "with open(true_boxes_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        img_name = parts[0]\n",
        "        x1, y1, x2, y2 = map(float, parts[2:])\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        true_boxes[img_name] = (x1, y1, w, h)\n",
        "\n",
        "# å®šç¾© IoU è¨ˆç®—å‡½æ•¸\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    x_left = max(x1, x2)\n",
        "    y_top = max(y1, y2)\n",
        "    x_right = min(x1 + w1, x2 + w2)\n",
        "    y_bottom = min(y1 + h1, y2 + h2)\n",
        "\n",
        "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        return 0\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# è®€å– image_0XXX çš„é æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†åº§æ¨™\n",
        "image_name = 'image_0719'\n",
        "pred_coordinates = pred_boxes.get(image_name, (0, 0, 0, 0))\n",
        "true_coordinates = true_boxes.get(image_name, (0, 0, 0, 0))\n",
        "\n",
        "# è¨ˆç®— IoU\n",
        "iou = calculate_iou(pred_coordinates, true_coordinates)\n",
        "print(f\"{image_name} çš„ IoU:\", iou)\n",
        "'''"
      ],
      "metadata": {
        "id": "7h03sd0o_F_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "2e412edd-2ab4-4f8a-8bd7-b9b48fcb3a66"
      },
      "id": "7h03sd0o_F_6",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# è®€å–é æ¸¬æ¡†æª”æ¡ˆ\\npred_boxes_file = \\'nms_pred_boxes_for_iou.txt\\'\\ntrue_boxes_file = \\'true_boxes_for_iou.txt\\'\\n\\npred_boxes = {}\\ntrue_boxes = {}\\n\\nwith open(pred_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        img_name = parts[0]\\n        x1, y1, x2, y2 = map(float, parts[2:])\\n        w = x2 - x1\\n        h = y2 - y1\\n        pred_boxes[img_name] = (x1, y1, w, h)\\n\\nwith open(true_boxes_file, \\'r\\') as f:\\n    lines = f.readlines()\\n    for line in lines:\\n        parts = line.strip().split()\\n        img_name = parts[0]\\n        x1, y1, x2, y2 = map(float, parts[2:])\\n        w = x2 - x1\\n        h = y2 - y1\\n        true_boxes[img_name] = (x1, y1, w, h)\\n\\n# å®šç¾© IoU è¨ˆç®—å‡½æ•¸\\ndef calculate_iou(box1, box2):\\n    x1, y1, w1, h1 = box1\\n    x2, y2, w2, h2 = box2\\n\\n    x_left = max(x1, x2)\\n    y_top = max(y1, y2)\\n    x_right = min(x1 + w1, x2 + w2)\\n    y_bottom = min(y1 + h1, y2 + h2)\\n\\n    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\\n    box1_area = w1 * h1\\n    box2_area = w2 * h2\\n    union_area = box1_area + box2_area - intersection_area\\n\\n    if union_area == 0:\\n        return 0\\n\\n    iou = intersection_area / union_area\\n    return iou\\n\\n# è®€å– image_0XXX çš„é æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†åº§æ¨™\\nimage_name = \\'image_0719\\'\\npred_coordinates = pred_boxes.get(image_name, (0, 0, 0, 0))\\ntrue_coordinates = true_boxes.get(image_name, (0, 0, 0, 0))\\n\\n# è¨ˆç®— IoU\\niou = calculate_iou(pred_coordinates, true_coordinates)\\nprint(f\"{image_name} çš„ IoU:\", iou)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# åˆå§‹åŒ–çµ±è¨ˆè®Šé‡\n",
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "total_iou = 0\n",
        "total_predictions = 0\n",
        "iou_threshold = 0.5  # IoU å¤§æ–¼ é–¾å€¼ æ‰ç®—æ­£æ¨£æœ¬\n",
        "\n",
        "# éæ­·æ¯å€‹æ¨£æœ¬\n",
        "for img_name in pred_boxes.keys():\n",
        "    # å–å¾—æ¯å€‹æ¨£æœ¬çš„é æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†\n",
        "    pred_box = pred_boxes[img_name]\n",
        "    true_box = true_boxes[img_name]\n",
        "\n",
        "    # å–å‡ºé æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†çš„åæ¨™\n",
        "    pred_coordinates = pred_box\n",
        "    true_coordinates = true_box\n",
        "\n",
        "    # è¨ˆç®— IoU\n",
        "    iou = calculate_iou(pred_coordinates, true_coordinates)\n",
        "\n",
        "    # æ‰“å°æ¯ä¸ªæ ·æœ¬çš„ IoU\n",
        "    print(f\"IoU for {img_name}: {iou}\")\n",
        "\n",
        "    # æ ¹æ“š IoU å€¼æ›´æ–° TPã€FP å’Œ FN\n",
        "\n",
        "    if iou >= iou_threshold:\n",
        "        TP += 1\n",
        "    else:\n",
        "        FN += 1\n",
        "\n",
        "\n",
        "    # æ›´æ–° total_iou\n",
        "    total_iou += iou\n",
        "\n",
        "# è¨ˆç®— Precisionã€Recallã€F1-scoreã€mAP\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "mAP = total_iou / len(pred_boxes) if len(pred_boxes) > 0 else 0\n",
        "\n",
        "# æ‰“å°æ‰€æœ‰æŒ‡æ¨™çš„å€¼\n",
        "print(\"TP:\", TP)\n",
        "print(\"FP:\", FP)\n",
        "print(\"FN:\", FN)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"mAP:\", mAP)\n",
        "'''"
      ],
      "metadata": {
        "id": "X11r2imysA-k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c1d264b9-eabd-405a-fedf-a6ae7416e689"
      },
      "id": "X11r2imysA-k",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# åˆå§‹åŒ–çµ±è¨ˆè®Šé‡\\nTP = 0\\nFP = 0\\nFN = 0\\ntotal_iou = 0\\ntotal_predictions = 0\\niou_threshold = 0.5  # IoU å¤§æ–¼ é–¾å€¼ æ‰ç®—æ­£æ¨£æœ¬\\n\\n# éæ­·æ¯å€‹æ¨£æœ¬\\nfor img_name in pred_boxes.keys():\\n    # å–å¾—æ¯å€‹æ¨£æœ¬çš„é æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†\\n    pred_box = pred_boxes[img_name]\\n    true_box = true_boxes[img_name]\\n\\n    # å–å‡ºé æ¸¬æ¡†å’ŒçœŸå¯¦æ¡†çš„åæ¨™\\n    pred_coordinates = pred_box\\n    true_coordinates = true_box\\n\\n    # è¨ˆç®— IoU\\n    iou = calculate_iou(pred_coordinates, true_coordinates)\\n\\n    # æ‰“å°æ¯ä¸ªæ ·æœ¬çš„ IoU\\n    print(f\"IoU for {img_name}: {iou}\")\\n\\n    # æ ¹æ“š IoU å€¼æ›´æ–° TPã€FP å’Œ FN\\n\\n    if iou >= iou_threshold:\\n        TP += 1\\n    else:\\n        FN += 1\\n\\n\\n    # æ›´æ–° total_iou\\n    total_iou += iou\\n\\n# è¨ˆç®— Precisionã€Recallã€F1-scoreã€mAP\\nprecision = TP / (TP + FP) if (TP + FP) > 0 else 0\\nrecall = TP / (TP + FN) if (TP + FN) > 0 else 0\\nf1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\\nmAP = total_iou / len(pred_boxes) if len(pred_boxes) > 0 else 0\\n\\n# æ‰“å°æ‰€æœ‰æŒ‡æ¨™çš„å€¼\\nprint(\"TP:\", TP)\\nprint(\"FP:\", FP)\\nprint(\"FN:\", FN)\\nprint(\"Precision:\", precision)\\nprint(\"Recall:\", recall)\\nprint(\"F1 Score:\", f1_score)\\nprint(\"mAP:\", mAP)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ–‡å­—è¾¨è­˜OCR"
      ],
      "metadata": {
        "id": "9tIqw9wjUjOh"
      },
      "id": "9tIqw9wjUjOh"
    },
    {
      "cell_type": "code",
      "source": [
        "# é‡åˆ°UTF-8éŒ¯èª¤\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "5xGBL_Ysjp0f"
      },
      "id": "5xGBL_Ysjp0f",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "!sudo apt-get install libtesseract-dev\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "4rucANDBSvfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04337e4e-b59b-4960-a72f-662e60565772"
      },
      "id": "4rucANDBSvfc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,732 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 2s (2,256 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121965 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è®€å–é æ¸¬æ¡†èˆ‡é æ¸¬å¾Œåœ–ç‰‡æª”\n",
        "def read_bounding_boxes(file_path):\n",
        "    bounding_boxes = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            image_name = parts[0]\n",
        "            bbox = list(map(float, parts[1:]))\n",
        "            bounding_boxes[image_name] = bbox\n",
        "    return bounding_boxes\n",
        "\n",
        "def check_filenames(bounding_boxes, image_folder):\n",
        "    for image_name in bounding_boxes.keys():\n",
        "        image_file_name = image_name + \".jpg\"  # å‡è¨­åœ–ç‰‡å‰¯æª”åæ˜¯ .jpgï¼Œæ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´\n",
        "        image_path = os.path.join(image_folder, image_file_name)\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image {image_file_name} not found in {image_folder}\")\n",
        "        else:\n",
        "            print(f\"Image {image_file_name} found and verified\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # æŒ‡å®šé æ¸¬æ¡†è³‡æ–™æª”çš„è·¯å¾‘\n",
        "    bbox_file_path = 'nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "    # æŒ‡å®šé æ¸¬å¾Œåœ–ç‰‡çš„è³‡æ–™å¤¾è·¯å¾‘ (éœ€ä¿®æ”¹æˆé æ¸¬å¾Œåœ–ç‰‡è·¯å¾‘)\n",
        "    image_folder = '/content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†'\n",
        "\n",
        "    # è®€å–é æ¸¬æ¡†è³‡æ–™\n",
        "    bounding_boxes = read_bounding_boxes(bbox_file_path)\n",
        "\n",
        "    # æª¢æŸ¥æª”åå°æ‡‰\n",
        "    check_filenames(bounding_boxes, image_folder)\n"
      ],
      "metadata": {
        "id": "CkfidtV5Xof0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece260ab-14e7-41a2-ba3f-7ca8244c251d"
      },
      "id": "CkfidtV5Xof0",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image FFAU2895947.jpg found and verified\n",
            "Image MAGU5605323.jpg found and verified\n",
            "Image SEKU5875349.jpg found and verified\n",
            "Image SEKU5877491.jpg found and verified\n",
            "Image SEKU6026686.jpg found and verified\n",
            "Image TCNU6246126.jpg found and verified\n",
            "Image TLLU4080736.jpg found and verified\n",
            "Image TRHU8927462.jpg found and verified\n",
            "Image TSSU5017340.jpg found and verified\n",
            "Image TSSU5029819.jpg found and verified\n",
            "Image TSSU5042071.jpg found and verified\n",
            "Image TSSU5061615.jpg found and verified\n",
            "Image TSSU5099400.jpg found and verified\n",
            "Image TSSU5142300.jpg found and verified\n",
            "Image TSSU5160351.jpg found and verified\n",
            "Image WHLU5591798.jpg found and verified\n",
            "Image WHLU5842825.jpg found and verified\n",
            "Image WHSU2483178.jpg found and verified\n",
            "Image WHSU2615314.jpg found and verified\n",
            "Image WHSU2864765.jpg found and verified\n",
            "Image WHSU5295430.jpg found and verified\n",
            "Image WHSU5368199.jpg found and verified\n",
            "Image WHSU5563298.jpg found and verified\n",
            "Image WHSU5610492.jpg found and verified\n",
            "Image WHSU5628589.jpg found and verified\n",
            "Image WHSU5744465.jpg found and verified\n",
            "Image WHSU5991104.jpg found and verified\n",
            "Image WHSU5998393.jpg found and verified\n",
            "Image WHSU6010260.jpg found and verified\n",
            "Image WHSU6040178.jpg found and verified\n",
            "Image WHSU6052306.jpg found and verified\n",
            "Image WHSU6167120.jpg found and verified\n",
            "Image WHSU6557387.jpg found and verified\n",
            "Image WHSU6651665.jpg found and verified\n",
            "Image WHSU6856285.jpg found and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è£åˆ‡åœ–ç‰‡ä¸¦ä¿å­˜\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_image(image_path):\n",
        "    return Image.open(image_path)\n",
        "\n",
        "def crop_image_with_bbox(image_path, bbox, save_folder):\n",
        "    # è§£æé æ¸¬æ¡†\n",
        "    x1, y1, x2, y2 = bbox[1], bbox[2], bbox[3], bbox[4]\n",
        "\n",
        "    # æª¢æŸ¥é æ¸¬æ¡†åº§æ¨™æ˜¯å¦ç‚º0 0 0 0\n",
        "    if x1 == 0 and y1 == 0 and x2 == 0 and y2 == 0:\n",
        "        print(f\"Bounding box coordinates are all zeros for image {os.path.basename(image_path)}, saving original image...\")\n",
        "        # ç›´æ¥ä¿å­˜åŸå§‹åœ–ç‰‡\n",
        "        save_path = os.path.join(save_folder, os.path.basename(image_path))\n",
        "        image = load_image(image_path)\n",
        "        image.save(save_path)\n",
        "        print(f\"Original image saved at {save_path}\")\n",
        "        return None\n",
        "\n",
        "    # è£åˆ‡åœ–ç‰‡\n",
        "    image = load_image(image_path)\n",
        "    cropped_image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "    # ç¢ºä¿ä¿å­˜è³‡æ–™å¤¾å­˜åœ¨\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # å–å¾—åŸå§‹æª”å\n",
        "    base_name = os.path.basename(image_path)\n",
        "\n",
        "    # ä¿å­˜è£åˆ‡å¾Œçš„åœ–ç‰‡ï¼Œä½¿ç”¨åŸå§‹æª”å\n",
        "    cropped_image_path = os.path.join(save_folder, base_name)\n",
        "    cropped_image.save(cropped_image_path)\n",
        "    print(f\"Cropped image saved at {cropped_image_path}\")\n",
        "\n",
        "    return cropped_image_path\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # æŒ‡å®šé æ¸¬æ¡†è³‡æ–™æª”çš„è·¯å¾‘\n",
        "    bbox_file_path = '/content/nms_pred_boxes_for_iou.txt'\n",
        "\n",
        "    # æŒ‡å®šé æ¸¬å¾Œåœ–ç‰‡çš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "    image_folder = '/content/hw3_M11221004/åœ–ç‰‡æº–ç¢ºç‡æ¸¬è©¦é›†'\n",
        "\n",
        "    # æŒ‡å®šè£åˆ‡å¾Œåœ–ç‰‡çš„ä¿å­˜è³‡æ–™å¤¾\n",
        "    cropped_image_folder = '/content/crop_images'\n",
        "\n",
        "    # è®€å–é æ¸¬æ¡†è³‡æ–™\n",
        "    bounding_boxes = read_bounding_boxes(bbox_file_path)\n",
        "\n",
        "    cropped_image_paths = []\n",
        "\n",
        "    # æª¢æŸ¥æª”åå°æ‡‰ä¸¦è£åˆ‡åœ–ç‰‡\n",
        "    for image_name in bounding_boxes.keys():\n",
        "        image_file_name = image_name + \".jpg\"  # å‡è¨­åœ–ç‰‡å‰¯æª”åæ˜¯ .jpgï¼Œæ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´\n",
        "        image_path = os.path.join(image_folder, image_file_name)\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image {image_file_name} not found in {image_folder}\")\n",
        "        else:\n",
        "            print(f\"Image {image_file_name} found and verified\")\n",
        "\n",
        "            # è£åˆ‡åœ–ç‰‡ä¸¦ä¿å­˜\n",
        "            cropped_image_path = crop_image_with_bbox(image_path, bounding_boxes[image_name], cropped_image_folder)\n",
        "            if cropped_image_path:\n",
        "                cropped_image_paths.append(cropped_image_path)\n",
        "\n",
        "    # åˆ—å°è£åˆ‡å¾Œçš„æ‰€æœ‰åœ–ç‰‡è·¯å¾‘\n",
        "    print(\"Cropped image paths:\")\n",
        "    for path in cropped_image_paths:\n",
        "        print(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0tF56OTYVCD",
        "outputId": "54e47810-048c-4270-d4c9-d6e5c6389b4c"
      },
      "id": "v0tF56OTYVCD",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image FFAU2895947.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/FFAU2895947.jpg\n",
            "Image MAGU5605323.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/MAGU5605323.jpg\n",
            "Image SEKU5875349.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/SEKU5875349.jpg\n",
            "Image SEKU5877491.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/SEKU5877491.jpg\n",
            "Image SEKU6026686.jpg found and verified\n",
            "Bounding box coordinates are all zeros for image SEKU6026686.jpg, saving original image...\n",
            "Original image saved at /content/crop_images/SEKU6026686.jpg\n",
            "Image TCNU6246126.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TCNU6246126.jpg\n",
            "Image TLLU4080736.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TLLU4080736.jpg\n",
            "Image TRHU8927462.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TRHU8927462.jpg\n",
            "Image TSSU5017340.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5017340.jpg\n",
            "Image TSSU5029819.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5029819.jpg\n",
            "Image TSSU5042071.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5042071.jpg\n",
            "Image TSSU5061615.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5061615.jpg\n",
            "Image TSSU5099400.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5099400.jpg\n",
            "Image TSSU5142300.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5142300.jpg\n",
            "Image TSSU5160351.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/TSSU5160351.jpg\n",
            "Image WHLU5591798.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHLU5591798.jpg\n",
            "Image WHLU5842825.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHLU5842825.jpg\n",
            "Image WHSU2483178.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2483178.jpg\n",
            "Image WHSU2615314.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2615314.jpg\n",
            "Image WHSU2864765.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU2864765.jpg\n",
            "Image WHSU5295430.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5295430.jpg\n",
            "Image WHSU5368199.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5368199.jpg\n",
            "Image WHSU5563298.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5563298.jpg\n",
            "Image WHSU5610492.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5610492.jpg\n",
            "Image WHSU5628589.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5628589.jpg\n",
            "Image WHSU5744465.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5744465.jpg\n",
            "Image WHSU5991104.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5991104.jpg\n",
            "Image WHSU5998393.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU5998393.jpg\n",
            "Image WHSU6010260.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6010260.jpg\n",
            "Image WHSU6040178.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6040178.jpg\n",
            "Image WHSU6052306.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6052306.jpg\n",
            "Image WHSU6167120.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6167120.jpg\n",
            "Image WHSU6557387.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6557387.jpg\n",
            "Image WHSU6651665.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6651665.jpg\n",
            "Image WHSU6856285.jpg found and verified\n",
            "Cropped image saved at /content/crop_images/WHSU6856285.jpg\n",
            "Cropped image paths:\n",
            "/content/crop_images/FFAU2895947.jpg\n",
            "/content/crop_images/MAGU5605323.jpg\n",
            "/content/crop_images/SEKU5875349.jpg\n",
            "/content/crop_images/SEKU5877491.jpg\n",
            "/content/crop_images/TCNU6246126.jpg\n",
            "/content/crop_images/TLLU4080736.jpg\n",
            "/content/crop_images/TRHU8927462.jpg\n",
            "/content/crop_images/TSSU5017340.jpg\n",
            "/content/crop_images/TSSU5029819.jpg\n",
            "/content/crop_images/TSSU5042071.jpg\n",
            "/content/crop_images/TSSU5061615.jpg\n",
            "/content/crop_images/TSSU5099400.jpg\n",
            "/content/crop_images/TSSU5142300.jpg\n",
            "/content/crop_images/TSSU5160351.jpg\n",
            "/content/crop_images/WHLU5591798.jpg\n",
            "/content/crop_images/WHLU5842825.jpg\n",
            "/content/crop_images/WHSU2483178.jpg\n",
            "/content/crop_images/WHSU2615314.jpg\n",
            "/content/crop_images/WHSU2864765.jpg\n",
            "/content/crop_images/WHSU5295430.jpg\n",
            "/content/crop_images/WHSU5368199.jpg\n",
            "/content/crop_images/WHSU5563298.jpg\n",
            "/content/crop_images/WHSU5610492.jpg\n",
            "/content/crop_images/WHSU5628589.jpg\n",
            "/content/crop_images/WHSU5744465.jpg\n",
            "/content/crop_images/WHSU5991104.jpg\n",
            "/content/crop_images/WHSU5998393.jpg\n",
            "/content/crop_images/WHSU6010260.jpg\n",
            "/content/crop_images/WHSU6040178.jpg\n",
            "/content/crop_images/WHSU6052306.jpg\n",
            "/content/crop_images/WHSU6167120.jpg\n",
            "/content/crop_images/WHSU6557387.jpg\n",
            "/content/crop_images/WHSU6651665.jpg\n",
            "/content/crop_images/WHSU6856285.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ä½¿ç”¨å¤§æ´¥æ³•å°‡åœ–ç‰‡äºŒå€¼åŒ–\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def binarize_image(image_path, save_folder):\n",
        "    # è®€å–åœ–ç‰‡\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # å°‡åœ–ç‰‡è½‰æ›ç‚ºç°åº¦æ¨¡å¼\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # ä½¿ç”¨å¤§æ´¥æ³•è¨ˆç®—é–¾å€¼\n",
        "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # åè½‰äºŒå€¼åŒ–åœ–ç‰‡ï¼Œå°‡èƒŒæ™¯è¨­ç½®ç‚ºç™½è‰²ï¼Œæ–‡å­—è¨­ç½®ç‚ºé»‘è‰²\n",
        "    inverted_image = cv2.bitwise_not(binary_image)\n",
        "\n",
        "    # ç¢ºä¿ä¿å­˜è³‡æ–™å¤¾å­˜åœ¨\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # å–å¾—åŸå§‹æª”å\n",
        "    base_name = os.path.basename(image_path)\n",
        "\n",
        "    # çµ„åˆå„²å­˜è·¯å¾‘\n",
        "    adjusted_image_path = os.path.join(save_folder, base_name)\n",
        "\n",
        "    # å„²å­˜èª¿æ•´å¾Œçš„åœ–ç‰‡\n",
        "    cv2.imwrite(adjusted_image_path, inverted_image)\n",
        "    print(f\"Adjusted image saved at {adjusted_image_path}\")\n",
        "\n",
        "    return adjusted_image_path\n",
        "\n",
        "# æŒ‡å®šè£åˆ‡å¾Œåœ–ç‰‡çš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "cropped_image_folder = '/content/crop_images'\n",
        "\n",
        "# æŒ‡å®šèª¿æ•´å¾Œåœ–ç‰‡çš„ä¿å­˜è³‡æ–™å¤¾\n",
        "adjusted_image_folder = '/content/adjust_images'\n",
        "\n",
        "# æª¢æŸ¥è£åˆ‡å¾Œçš„æ‰€æœ‰åœ–ç‰‡\n",
        "for root, dirs, files in os.walk(cropped_image_folder):\n",
        "    for file in files:\n",
        "        # è£åˆ‡å¾Œåœ–ç‰‡çš„å®Œæ•´è·¯å¾‘\n",
        "        cropped_image_path = os.path.join(root, file)\n",
        "\n",
        "        # é€²è¡Œå¤§æ´¥æ³•è¨ˆç®—é–¾å€¼ä¸¦åè½‰äºŒå€¼åŒ–è™•ç†ä¸¦ä¿å­˜\n",
        "        adjusted_image_path = binarize_image(cropped_image_path, adjusted_image_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXZpE8aVc3xr",
        "outputId": "8b835623-cac3-494f-b2e1-ff289cf4fd0b"
      },
      "id": "FXZpE8aVc3xr",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted image saved at /content/adjust_images/WHSU5368199.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5160351.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5142300.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6040178.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6010260.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6052306.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5998393.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6557387.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2615314.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6651665.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5029819.jpg\n",
            "Adjusted image saved at /content/adjust_images/TLLU4080736.jpg\n",
            "Adjusted image saved at /content/adjust_images/FFAU2895947.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5017340.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5099400.jpg\n",
            "Adjusted image saved at /content/adjust_images/MAGU5605323.jpg\n",
            "Adjusted image saved at /content/adjust_images/TRHU8927462.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5563298.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6167120.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHLU5842825.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5295430.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHLU5591798.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5991104.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2483178.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5628589.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5744465.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU6026686.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU5877491.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU6856285.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5042071.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU2864765.jpg\n",
            "Adjusted image saved at /content/adjust_images/TSSU5061615.jpg\n",
            "Adjusted image saved at /content/adjust_images/SEKU5875349.jpg\n",
            "Adjusted image saved at /content/adjust_images/TCNU6246126.jpg\n",
            "Adjusted image saved at /content/adjust_images/WHSU5610492.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# åœ–ç‰‡è·¯å¾‘\n",
        "image_path = \"/content/adjust_images\"\n",
        "\n",
        "# å–å¾—è·¯å¾‘ä¸‹æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆåç¨±\n",
        "image_files = [f for f in os.listdir(image_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# æ–‡å­—è¾¨è­˜å‡½å¼\n",
        "def image_to_text(image_file):\n",
        "    try:\n",
        "        # ä½¿ç”¨Pillowå¥—ä»¶æ‰“é–‹åœ–ç‰‡\n",
        "        with Image.open(os.path.join(image_path, image_file)) as img:\n",
        "            # å°‡åœ–ç‰‡è½‰æ›æˆæ–‡å­—\n",
        "            text = pytesseract.image_to_string(img, lang='eng')  # è¨­å®šè¾¨è­˜èªè¨€ï¼Œé€™è£¡æ˜¯è‹±æ–‡\n",
        "\n",
        "            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼éæ¿¾å‡ºè‹±æ–‡å­—æ¯å’Œæ•¸å­—\n",
        "            filtered_text = re.sub(r'[^A-Za-z0-9]', '', text)\n",
        "\n",
        "            # ç¢ºä¿æ–‡å­—ç¸½é•·åº¦ç‚º15ï¼Œæ²’æœ‰çš„è©±è£œè¶³ç©ºæ ¼\n",
        "            if len(filtered_text) < 15:\n",
        "                filtered_text = filtered_text.ljust(15, ' ')\n",
        "            elif len(filtered_text) > 15:\n",
        "                filtered_text = filtered_text[:15]\n",
        "\n",
        "            return filtered_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "# è¨ˆç®—æº–ç¢ºç‡\n",
        "correct_count = 0\n",
        "total_count = len(image_files)\n",
        "\n",
        "for image_file in image_files:\n",
        "    text = image_to_text(image_file)\n",
        "    if text is not None:\n",
        "        filename_without_extension = os.path.splitext(image_file)[0]\n",
        "        # æª¢æŸ¥å‰11å€‹å­—æ˜¯å¦èˆ‡æª”åç›¸åŒ\n",
        "        if text[:11].lower() == filename_without_extension.lower():\n",
        "            correct_count += 1\n",
        "        print(f\"Filtered text result for {image_file}: {text}\")\n",
        "\n",
        "accuracy = correct_count / total_count if total_count > 0 else 0\n",
        "print(f\"Accuracy: {accuracy:.2%} (Correct: {correct_count}, Total: {total_count})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdmqlV6PrMGa",
        "outputId": "0435fa81-4646-4f6d-8d08-4f54c1fd2fce"
      },
      "id": "JdmqlV6PrMGa",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered text result for WHSU5368199.jpg: WHSU5368199AG  \n",
            "Filtered text result for TSSU5160351.jpg: TSSU516035Ji745\n",
            "Filtered text result for TSSU5142300.jpg: TSSU           \n",
            "Filtered text result for WHSU6040178.jpg: WHSU60401714561\n",
            "Filtered text result for WHSU6010260.jpg: WHSU601026A561 \n",
            "Filtered text result for WHSU6052306.jpg: WHSU60529456i  \n",
            "Filtered text result for WHSU5998393.jpg: WHSU59983934561\n",
            "Filtered text result for WHSU6557387.jpg: WHSU85573874661\n",
            "Filtered text result for WHSU2615314.jpg: WHSU26153142261\n",
            "Filtered text result for WHSU6651665.jpg: 6651664561     \n",
            "Filtered text result for TSSU5029819.jpg: TSSU5029814561 \n",
            "Filtered text result for TLLU4080736.jpg: TLLU408073456  \n",
            "Filtered text result for FFAU2895947.jpg: FAU2895947py456\n",
            "Filtered text result for TSSU5017340.jpg: iSSU501734561  \n",
            "Filtered text result for TSSU5099400.jpg: TSSU5099404561 \n",
            "Filtered text result for MAGU5605323.jpg:                \n",
            "Filtered text result for TRHU8927462.jpg: TRHU89274624561\n",
            "Filtered text result for WHSU5563298.jpg: NHSU5563294561 \n",
            "Filtered text result for WHSU6167120.jpg: WHSU6167124561 \n",
            "Filtered text result for WHLU5842825.jpg: WHLU5842824561 \n",
            "Filtered text result for WHSU5295430.jpg: WHSU529543ASGI \n",
            "Filtered text result for WHLU5591798.jpg: WHLUS5gfASG    \n",
            "Filtered text result for WHSU5991104.jpg: WHSU45991104456\n",
            "Filtered text result for WHSU2483178.jpg: WRSU2483178261 \n",
            "Filtered text result for WHSU5628589.jpg: WHSU5628889j45G\n",
            "Filtered text result for WHSU5744465.jpg: WHSU57444654561\n",
            "Filtered text result for SEKU6026686.jpg:                \n",
            "Filtered text result for SEKU5877491.jpg: SEKU58774561   \n",
            "Filtered text result for WHSU6856285.jpg: WHSU           \n",
            "Filtered text result for TSSU5042071.jpg: TSSU5042074561 \n",
            "Filtered text result for WHSU2864765.jpg: WHSU28647bet   \n",
            "Filtered text result for TSSU5061615.jpg: TSSU50616154561\n",
            "Filtered text result for SEKU5875349.jpg: SEKU5875344561 \n",
            "Filtered text result for TCNU6246126.jpg: TCNU6246124561 \n",
            "Filtered text result for WHSU5610492.jpg: WHSU56104924561\n",
            "Accuracy: 20.00% (Correct: 7, Total: 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ä¸‹è¼‰è³‡æ–™å¤¾**"
      ],
      "metadata": {
        "id": "HHaV1XlVke6Q"
      },
      "id": "HHaV1XlVke6Q"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#å£“ç¸®æˆè³‡æ–™å¤¾ä¸‹è¼‰ï¼Œå‰é¢æ˜¯æª”å.zipï¼Œå¾Œé¢æ˜¯è¦è¢«å£“ç¸®çš„æ±è¥¿\n",
        "!zip -r /content/crop_images.zip /content/crop_images\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/crop_images.zip\")\n",
        "'''"
      ],
      "metadata": {
        "id": "pttsIpiJtFwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1027072d-8794-42c2-ee3c-d7ba57bc276c"
      },
      "id": "pttsIpiJtFwc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#å£“ç¸®æˆè³‡æ–™å¤¾ä¸‹è¼‰ï¼Œå‰é¢æ˜¯æª”å.zipï¼Œå¾Œé¢æ˜¯è¦è¢«å£“ç¸®çš„æ±è¥¿\\n!zip -r /content/crop_images.zip /content/crop_images\\n\\nfrom google.colab import files\\nfiles.download(\"/content/crop_images.zip\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# åˆªé™¤è³‡æ–™å¤¾\n",
        "import shutil\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    try:\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder {folder_path} and its contents deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Folder {folder_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# æŒ‡å®šè¦åˆªé™¤çš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "folder_to_delete = '/content/adjust_images'\n",
        "\n",
        "# å‘¼å«å‡½å¼ä¾†åˆªé™¤è³‡æ–™å¤¾\n",
        "delete_folder(folder_to_delete)\n",
        "'''"
      ],
      "metadata": {
        "id": "8Kl1DD908AMW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f9ac8879-46ef-4026-f290-fce66829ccd1"
      },
      "id": "8Kl1DD908AMW",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# åˆªé™¤è³‡æ–™å¤¾\\nimport shutil\\n\\ndef delete_folder(folder_path):\\n    try:\\n        shutil.rmtree(folder_path)\\n        print(f\"Folder {folder_path} and its contents deleted successfully.\")\\n    except FileNotFoundError:\\n        print(f\"Folder {folder_path} not found.\")\\n    except Exception as e:\\n        print(f\"An error occurred: {e}\")\\n\\n# æŒ‡å®šè¦åˆªé™¤çš„è³‡æ–™å¤¾è·¯å¾‘\\nfolder_to_delete = \\'/content/adjust_images\\'\\n\\n# å‘¼å«å‡½å¼ä¾†åˆªé™¤è³‡æ–™å¤¾\\ndelete_folder(folder_to_delete)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}